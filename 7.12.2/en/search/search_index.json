{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Leonardo Services","text":"<p>Leonardo provides and manages various services divided into service families. From a logical-functional perspective, these services can be divided into the following four macro-categories:</p> <ul> <li>Infrastructure as a Service (IaaS) </li> <li>Container as a Service (CaaS)</li> <li>Platform as a Service (PaaS)</li> <li>Hybrid Services</li> </ul> <p>Below are listed the services for each macro category.</p>"},{"location":"#infrastructure-as-a-service-iaas","title":"Infrastructure as a Service (IaaS)","text":"<p>Below is a list of services included in this category. For details on each service, please see the dedicated section. </p> FAMILY LIST OF SERVICES Compute Confidental Private IaaS Compute Confidential Shared-IaaS (VMs) List of families and related IaaS services"},{"location":"#container-as-a-service-caas","title":"Container as a Service (CaaS)","text":"<p>Below is a list of services included in this category. For details on each service, please see the dedicated section. </p> FAMILY LIST OF SERVICES Compute Kubernetes Confidential Computing List of families and related CaaS services"},{"location":"#platform-as-a-service-paas","title":"Platform as a Service (PaaS)","text":"<p>Below is a list of services included in this category. For details on each service, please see the dedicated section. </p> FAMILY LIST OF SERVICES Security Identity &amp; Access Management (IAM) Service Security Key Vault as a Service - Standard Security Endpoint Protection Security NGFW Platform Security PAM (Privileged Access Management) Security Intrusion Prevention System (IPS) Security PaaS Web Application Firewall (WAF) Middleware PaaS API Management Middleware Functions As A Service (FAAS) Middleware Jboss as a Service Middleware Spring boot as a Service Middleware PaaS Business Process as a Service Middleware PaaS CMS as a Service Middleware Semantic Knowledge Search Data Protection Backup Platform Infra &amp; Ops Platform Multicloud Management Platform Infra &amp; Ops Platform IT infrastructure Service Operations (Logging &amp; Monitoring) Infra &amp; Ops Platform PaaS Ticket Management Service Infra &amp; Ops Platform PaaS Operations Management DevSecOps Configuration Manager DevSecOps Test Automation DevSecOps Quality Code Analysis DevSecOps DevSecOps As A Service DevSecOps Qualizer DevSecOps Big Data Data Lake Big Data Business Intelligence Platform Big Data PaaS ETL Batch/Real time Processing Big Data Event Message Big Data Data Governance Artificial Intelligence (AI) Speech to Text Artificial Intelligence (AI) PaaS - AI Audio &amp; Video Analytics Artificial Intelligence (AI) OCR Artificial Intelligence (AI) Text Analytics/NLP Artificial Intelligence (AI) Translation Artificial Intelligence (AI) AI Search - RAG Artificial Intelligence (AI) AI Platform Artificial Intelligence (AI) AI SLM/LLM Collaboration Instant Messaging Database PaaS SQL - PostgreSQL Database PaaS SQL - MariaDB Database PaaS SQL - MS SQL Server EE Database PaaS SQL - MS SQL Server EE (BYOL) Database PaaS GraphDB Database PaaS NoSQL - MongoDB Database PaaS In Memory - Redis Networking PaaS CDN (Content Delivery Network) Networking PaaS Domain Name System (DNS) Networking Single public IP Networking L7 Load Balancer (regional) Networking Cloud interconnect Gold SW (10 Gbps max throughput) Networking Managed VPN Access Service Networking PaaS Client/Forward Proxy Networking PaaS Reverse Proxy Storage Block Storage (1000 GB) - High Density Storage Archive Storage (1000 GB) List of families and related PaaS services"},{"location":"#hybrid-services","title":"Hybrid Services","text":"<p>Below is a list of services included in this category. For details on each service, please see the dedicated section. </p> FAMILY LIST OF SERVICES Hybrid Edge Location - Pool Small (Confidential) Hybrid Bulk Data Transfer List of families and related Hybrid services"},{"location":"CaaS/","title":"Container as a Service (CaaS)","text":"<p>The following table lists the services included in the Container as a Service (CaaS) category.</p> FAMILY LIST OF SERVICES Compute Kubernetes Confidential Computing List of families and related CaaS services"},{"location":"CaaS/#compute-family","title":"Compute Family","text":"<p>Below is the list of services belonging to the Compute family:</p> <ul> <li>Kubernetes Confidential Computing</li> </ul> <p></p>"},{"location":"CaaS/#kubernetes-confidential-computing-service","title":"Kubernetes Confidential Computing Service","text":"<p> Kubernetes Confidential Computing Overview </p>"},{"location":"CaaS/#service-description","title":"Service Description","text":"<p>This service, deveoloped by Leonardo, provides an automated Kubernetes platform for orchestrating private and secure containers, designed to manage containerized applications in highly regulated environments or with confidentiality requirements. The platform ensures automation of node scaling, monitoring, and high availability management, without requiring any operational activities on the customer's part. The cluster capacity can be increased or decreased through automated scaling mechanisms based on predefined node block increments, in line with the proposed SKU sizing. This approach ensures architectural consistency, predictable performance, and alignment with the design constraints of the underlying infrastructure.</p> Type Contained Elements Kubernetes cluster 15 node workers with 8 GB RAM for each unit Contained Elements for the Kubernetes Confidential Computing Service"},{"location":"CaaS/#features-and-advantages","title":"Features and Advantages","text":"<p>Implementation requires a combination of hardware certified for Confidential Computing, a private, security-hardened Kubernetes infrastructure, and a suite of observability and governance tools to maintain complete control over the container lifecycle.</p> <p>Features included:</p> <ul> <li>Data protection \u2192 The operating system is configured to ensure protection at all stages: data in memory, through full disk encryption; data in transit, using secure and encrypted communication protocols; and data in use, adopting Confidential Computing practices and secure execution environments.</li> <li>Secure enclaves \u2192 Enforces isolation and encryption, ensuring that only authorized parties can access data.</li> <li>Trusted execution environments (TEEs) \u2192 Adds a secure computing environment, protecting data from external threats.</li> <li>As a managed Kubernetes solution, the customer does not have to worry about managing the infrastructure and its complexity, as the infrastructure layer is managed by Leonardo throughout the service lifecycle.</li> </ul> <p>The service includes a comprehensive set of security tools and services designed to ensure the secure usage of containers running on the Managed Service for Containers. It implements a multilayered infrastructure security model that safeguards the entire container lifecycle\u2014from image creation to runtime execution\u2014ensuring platform integrity, operational compliance, and consistent protection of containerized workloads. </p> <p>Platform security:</p> <ul> <li>Real-time security monitoring and vulnerability scanning are implemented through the use of StackRox, providing continuous assessment of container images and runtime workloads. The platform enables automated detection of CVEs, policy violations, and security threats ensuring a secure, compliant, and monitored environment without operational intervention.</li> <li>Host-level malware and virus detection to secure container nodes with EDR provided by Bitdefender</li> <li>Kernel-level hardening and enforcement of mandatory security profiles to isolate workloads (by design)</li> </ul> <p>Access Security:</p> <ul> <li>Identity-based access controls (RBAC) and integration with centralized identity management systems.</li> </ul> <p>Compliance, Monitoring, and Auditing:</p> <ul> <li>Centralized logging and security-related events are forwarded directly to the SOC team SIEM, enabling correlation, alerting, and continuous security monitoring.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Security and confidentiality of containerized applications \u2192 end-to-end encryption, confidential computing for workloads, container isolation on dedicated nodes with hardware-based protection, integrated security policies, and advanced RBAC.</li> <li>Centralized cluster control and governance.</li> <li>Scalability and flexibility.</li> <li>Integration with multicloud and legacy environments.</li> </ul>"},{"location":"Certifications/","title":"Certifications","text":"<p>This section lists the certifications and security compliances of the services described.</p> <ul> <li>ISO 9001 certification</li> <li>ISO 27001 certification</li> <li>ISO 27017 and 27018 certifications</li> <li>ISO 22301 certification - Business Continuity</li> <li>ISO/IEC 20000 certification - Service Management</li> </ul>"},{"location":"DC/","title":"Data Centers Description","text":""},{"location":"DC/#general-architecture","title":"General architecture","text":"<p>The Cloud Services described in the relevant categories are hosted within 9 Data Centers distributed throughout Italy and spread across 3 Regions (A, B, and C), each redundant with three highly reliable Availability Zones.</p> <p> Data Center Architecture and Interconnection </p> <p>The infrastructure configuration is fully redundant thanks to the division of each of the three Regions, whose maximum distance exceeds 400 km. Each Region is composed of three Availability Zones (AZs), three Data Centers configured for business continuity, separated as the crow flies by tens of kilometers.</p> <p>Specifically, the following table shows the DC association for each region:</p> Region List of Data Centers Region A DC MI 1 Bergamo Region A DC MI 2 Basiglio Region A DC MI 3 Siziano Region B DC GE 1 Fiumara Region B DC GE 2 Puccini Region B DC GE 3 Region C DC RM 1 Rome Region C DC RM 2 Acilia Region C DC RM 3 Pomezia Nomenclature of DCs for each Region <p>Below are the distances between each Region and between the DCs of each Region.</p> <ul> <li>Region A - Region B: distance more than 100 km</li> <li>Region A - Region C: distance more than 400 km</li> <li> <p>Region B - Region C: distance more than 500 km</p> </li> <li> <p>DC MI 1 Bergamo - DC MI 2 Basiglio: approximate distance 53 km</p> </li> <li>DC MI 1 Bergamo - DC MI 3 Siziano: approximate distance 54 km</li> <li> <p>DC MI 2 Basiglio - DC MI 3 Siziano: approximate distance 10 km</p> </li> <li> <p>DC GE 1 Fiumara - DC GE 2 Puccini: approximate distance 10 Km</p> </li> <li>DC GE 1 Fiumara - DC GE 3: approximate distance 15 Km</li> <li> <p>DC GE 2 Puccini - DC GE 3: approximate distance 15 Km</p> </li> <li> <p>DC RM 1 Rome - DC RM 2 Acilia: approximate distance 30 km</p> </li> <li>DC RM 1 Rome - DC RM 3 Pomezia: approximate distance 30 km</li> <li>DC RM 2 Acilia - DC RM 3 Pomezia: approximate distance 15 km</li> </ul> <p>All data centers are equipped with all the technical and technological infrastructure necessary to ensure the highest quality standards in terms of reliability, availability, and physical security.</p> <p>The three Availability Zones are interconnected via a dedicated regional backbone, which guarantees complete redundancy, negligible latency, and priority connectivity, logically characterizing the Regions as a single virtual Data Center (Software Defined Data Center).</p> <p>The Regions are also interconnected via dedicated and reserved interregional backbones with IP/MPLS network transmission, enabling a flexible, software-defined logical network architecture, ensuring the mobility of application loads and the inherent high reliability of Cloud solutions. Within an Availability Zone, workloads are transparently distributed, and the HA (High Availability) configuration enables infrastructure service continuity (Business Continuity) between the three Data Centers in the same Region.</p> <p>Thanks to this basic configuration, the Cloud platform will also provide data distribution between the three zones of each Region. This configuration is possible thanks to the distribution of storage space (identified with the best Storage Array technologies available on the IT market) within the three AZs and, therefore, thanks to the continuous replication of data for the service chosen by each individual organization. Therefore, if an individual organization decides to leverage the full redundancy of its infrastructure (physical or virtual), it can leverage the Cloud platform's HA configuration and create DR/BC solutions.  </p> <p>The unique nature of the Cloud platform, thanks to the backbone interconnecting the three AZs that make up each Region, will enable synchronous and asynchronous data replication between the Storage Array systems that make up the Storage Tier. In this operational context, the individual organization will benefit from the Cloud platform's inherent ability to reactivate workloads within one of the three AZs or in a different Region. Restarting workloads protected by the activated DR/BC solution will therefore allow the individual organization to independently manage the restart of each application, based on its own DR or BC plans.</p>"},{"location":"DC/#network-description","title":"Network description","text":"<p>The network is structured around three main components: Data Center Interconnection, Wide Area Network, and Local Area Network.</p>"},{"location":"DC/#data-center-interconnection-dci","title":"Data Center Interconnection (DCI)","text":"<p>Interconnection between the Data Centers relies on a high-capacity transport infrastructure built to ensure minimal latency, fault tolerance, and uninterrupted service. Key elements include:</p> <ul> <li>IP/MPLS backbone, fully redundant and optimized for reliable, resilient routing.</li> <li>DWDM (Dense Wavelength Division Multiplexing) technology supporting high-capacity optical transmission with very low latency.</li> <li>VLAN-based segmentation, ensuring logical isolation of traffic domains and multi-tenant environments for different Organizations.</li> <li>Traffic management policies to regulate routing, priorities, and bandwidth allocation.  </li> </ul> <p>The DCI enables operation in a multi-region configuration with three Availability Zones, essential for high availability, synchronous/asynchronous replication, and business continuity.</p>"},{"location":"DC/#wide-area-network-wan","title":"Wide Area Network (WAN)","text":"<p>The WAN provides secure, high-performance connectivity to external networks, supporting access to the services. It includes:</p> <ul> <li>Shared Internet connectivity, offering controlled access to the services.</li> <li>Traffic profiling tools for bandwidth management, flow optimization, and congestion prevention.</li> <li>IDS and APM systems, ensuring threat detection and performance monitoring.</li> <li> <p>Additional services, such as:</p> <ul> <li>Dedicated line aggregation.</li> <li>VPN connectivity.</li> <li>Special-purpose links for data migration.</li> <li>Hosting of termination routers directly within the facilities.</li> </ul> </li> </ul> <p>The WAN ensures each Organization has isolated, secure channels for interacting with the infrastructure while maintaining high security and reliability.</p>"},{"location":"DC/#local-area-network-lan","title":"Local Area Network (LAN)","text":"<p>Our cloud platform integrates a Software-Defined Networking (SDN) solution that allows customers to design and manage virtual networks directly from the management console. Clients can define complex topologies, segment traffic, and configure IP addressing without interacting with physical infrastructure.</p> <p>Technical Features:</p> <ul> <li>Virtual network creation \u2192 create virtual bridges and dedicated network segments to isolate environments (e.g., production, testing) and ensure traffic separation.</li> <li>Dual-stack IPv4/IPv6 support \u2192 each network can be configured with IPv4 and IPv6 addresses, with options to set dedicated gateways and custom subnets.<ul> <li>IPv4: static or DHCP configuration.</li> <li>IPv6: support for static addresses and DHCPv6.</li> </ul> </li> <li>IP and routing management \u2192 the console enables you to define IP ranges, gateways, and internal routing rules between subnets, without address translation functions.</li> <li>Advanced segmentation \u2192 support for VLAN tagging and isolated networks to ensure security and compliance.<ul> <li>Configurable VLAN IDs for each bridge.</li> <li>Options for private and public networks.</li> </ul> </li> <li>Scalability and performance \u2192 architecture optimized for low latency and high throughput, with the ability to add new networks and nodes without downtime.</li> </ul> <p>Example Scenario</p> <p>A customer can: 1.  Create a private network with IPv4 (e.g., 10.0.0.0/24) and IPv6 (e.g., fd00::/64). 2.  Connect multiple VMs and containers to the network via virtual bridges. 3.  Define internal routing rules between subnets. 4.  Add a VLAN to separate test traffic from production traffic.</p> <p>Benefits:</p> <ul> <li>Self-Service: Everything managed from the console, no manual intervention.</li> <li>Flexibility: Custom configurations for each project.</li> <li>Compatibility: Full IPv4/IPv6 support.</li> <li>Integrated Security</li> </ul>"},{"location":"DC/#data-centers-characteristics-and-technical-specification","title":"Data Centers characteristics and technical specification","text":"<p>This section lists the general characteristics and technical specifications of the Data Center.</p>"},{"location":"DC/#general-requirements-and-site-criteria","title":"General requirements and site criteria","text":"<p>The architecture is designed to meet high standards for security, resilience, and sustainability, aligned with TIER III certifications and current regulatory requirements. The Data Centers are selected and designed to reduce environmental and external risks:</p> <ul> <li>Located in seismic zones classified as zone \u22653.</li> <li>Sited away from coasts, major rivers, and heavily trafficked areas.</li> <li>Positioned near metropolitan zones while maintaining low risk.</li> <li>Equipped with independent power feeds, not derived from the same medium/high-voltage substation.</li> </ul> <p>Compliance with key regulations is ensured.</p>"},{"location":"DC/#technical-specifications","title":"Technical specifications","text":"<p>This section lists the technical specifications for each Data Center.</p>"},{"location":"DC/#the-region-a-data-centers","title":"The Region A Data Centers","text":""},{"location":"DC/#dc-mi-1-bergamo","title":"DC MI 1 Bergamo","text":"<p>General specifications</p> <ul> <li>Total surface area: 17.600 m2 </li> <li>Data hall surface area: 8.050 m2  </li> <li>Number of independent data rooms: 10</li> <li>Secure location in terms of earthquakes</li> <li>Secure location in terms of hydro-geological risks</li> </ul> <p>Building </p> <ul> <li>Height of the data hall: 3,5 m </li> <li>Height of upper plenum: 2,5 m </li> <li>Height of lower plenum: 2 m </li> <li>Load capacity of the floating floor : 2.000kg/m\u00b2(distributed load) 1.000 kg/m\u00b2 (concentrated load in one place) </li> <li>External firewalls: REI 240 </li> <li> <p>Internal firewalls: REI 120</p> <ul> <li>Double insulation with defrost system </li> <li>Double loading bay</li> </ul> </li> </ul> <p>Certifications and compliance </p> <ul> <li>ANSI/TIA 942-B-2017 Rating 4 (formerly Tier 4)</li> <li>GO - Guarantee of Energy Origin</li> <li>Code of Conduct for Data Center Energy Efficiency </li> <li>ISO 9001 - Quality of services offered </li> <li>ISO 14001 - Environmental management system</li> <li>ISO 22237 - Data centre facilities and infrastructure</li> <li>ISO 27001 - IT security </li> <li>ISO 50001 - Energy management system</li> <li>ISO/IEC 27017 \u2013 Cloud security controls</li> <li>ISO/IEC 27018 \u2013 Managing personal data on the Cloud</li> <li>ISO/IEC 27035 \u2013 Managing security incidents and events</li> </ul> <p>Connectivity </p> <ul> <li>Point of entrance: 4 </li> <li>Entrance Room: 2 </li> <li> <p>Main Distribution Area (MDA): 2</p> <ul> <li>Carrier neutral data center</li> <li>Provision of managed connectivity</li> <li>Dual transmission system to Milan Internet eXchange (MIX)</li> </ul> </li> </ul> <p>Energy </p> <ul> <li>Connection points to utilities: 2 </li> <li>Total power: 12 MW IT 2N (redundant) </li> <li>UPS redundancy: 2N+1 </li> <li>UPS type: double conversion static </li> <li>Individual UPS power: 500kVA </li> <li>UPS run time: 15 minutes at full power on single module in emergency conditions - 40 minutes in standard conditions </li> <li>Generator redundancy: 2N </li> <li>Generator type: diesel generator units </li> <li>Full load run time: 26h in emergency conditions, 52h in standard conditions</li> </ul> <p>Cooling </p> <ul> <li>Cooling type: Chilled water - - water to water - water to air system </li> <li>Normal mode: Ground water cooling system </li> <li>Redundancy of heat exchangers: 2N </li> <li>Groundwater extraction wells: 5 </li> <li>Emergency mode: air/water chiller </li> <li>CRAH redundancy: 2N</li> </ul> <p>Security </p> <ul> <li>CCTV</li> <li>24/7/365 security</li> <li>Separate parking for employees/visitors</li> <li>Vehicle bollards</li> <li>Separate entrance gates for visitors/goods</li> <li>Mantrap for visitors and goods with anti-tailgating and antipiggybacking systems</li> <li>Network Operations Center (NOC)</li> <li>Security Operations Center (SOC)</li> <li>Facility Operations Center (FOC)</li> <li>Building Management System (BMS)</li> </ul> <p>Fire prevention system </p> <ul> <li>Air replacement: 2vol/h </li> <li>Extinguishing system: inert gas </li> <li>Extinguishing gas: IG-541 </li> <li>Redundancy of extinguishing cylinders: 2N</li> <li>Highly sensitive smoke detection system</li> <li>Liquid loss detection system</li> <li>Fire detection and extinguishing system in each single module</li> <li>Standalone system on every generator unit</li> </ul> <p></p>"},{"location":"DC/#dc-mi-2-basiglio","title":"DC MI 2 Basiglio","text":"<p>General specifications</p> <ul> <li>Colocation Space: 2.380 m\u00b2. </li> <li>Global uptime average of &gt;99,999%</li> <li>Energy: covered by 100% renewable energy</li> </ul> <p>Building </p> <ul> <li>Building type: 4-floor concrete structure</li> <li>Floor type: Raised floor</li> <li>Floor load capacity: 1.500 kg/m\u00b2 </li> <li>Parking: Adjacent to building (free)</li> <li>Seismic design: low seismic category. </li> <li>Flood zone: not applicable</li> </ul> <p>Certifications and compliance </p> <p>ISO Standards: - ISO 9001 - ISO 22301 - ISO 27001 - ISO 45001 - ISO 14001 - ISO 50001</p> <p>Other Certifications: - Cyber Essentials - PCI DSS - SOC 1 Type II - SOC 2 Type II - EU Code of Conduct</p> <p>Connectivity </p> <ul> <li>Access to 30+ carriers across the Milan metro ecosystem </li> <li>Direct peering through Equinix Internet Exchange\u2122. </li> <li>Direct connectivity via Equinix Fabric\u00ae to distributed digital infrastructure</li> <li>Access to MIX, TOP-IX and other interconnections at Via Caldera, Milan</li> </ul> <p>Energy </p> <ul> <li>Utility feeders: 1 \u00d7 3 MVA electrical feed</li> <li>PS configuration: N+N</li> <li>UPS redundancy: N+1</li> <li> <p>Standby power configuration:</p> <ul> <li>2 \u00d7 1,900 kVA diesel generators (mechanical load)</li> <li>4 \u00d7 1,400 kVA diesel generators (IT load)</li> </ul> </li> <li> <p>Standby power redundancy: N+N. </p> </li> <li>Power density: 1.0\u20137.0 kVA per cabinet</li> </ul> <p>Cooling </p> <ul> <li>Cooling configuration: Chilled water system</li> <li>Cooling redundancy: N+1</li> </ul> <p>Security </p> <p>Physical Security:</p> <ul> <li>Mantrap entry</li> <li>Proximity access card + PIN</li> </ul> <p>Human Security:</p> <ul> <li>24/7 on-site security officers</li> </ul> <p>Electronic Security:</p> <ul> <li>PIN and card readers</li> <li>Optional biometric readers for customer cages</li> <li>CCTV with 7-day video retention</li> <li>Motion detection</li> </ul> <p>Fire prevention system </p> <p>Detection:</p> <ul> <li>VESDA</li> <li>HSSD (High Sensitivity Smoke Detection)</li> <li>Visual and audio alarms</li> <li>Double-knock activation</li> </ul> <p>Suppression agents:</p> <ul> <li>Novec</li> <li>FM200</li> <li>Argon</li> </ul> <p></p>"},{"location":"DC/#dc-mi-3-siziano","title":"DC MI 3 Siziano","text":"<p>General specifications</p> <ul> <li>The campus in Siziano (PV) hosts all hosting and cloud infrastructure used by CoreTech</li> <li>Designed according to Tier IV multi-tenant data center standards offering unmatched connectivity</li> <li>Located within a 100.000 m\u00b2 campus, hosting Italy\u2019s largest and most advanced data center</li> <li>Building footprint is 42.000 m\u00b2</li> <li>Designed for 100% Power &amp; Cooling guaranteed uptime</li> <li>Highly focused on energy efficiency, using advanced cooling and climatization technologies.</li> </ul> <p>Building </p> <ul> <li>Constructed according to NTC anti-seismic regulations (D.M. 14/01/2008)</li> <li>Double roof resistant to winds up to 280 km/h</li> <li>Intumescent-coated metal structure for fire resistance</li> <li>Perimeter walls of the technical area built to REI120 standards </li> <li> <p>Flood-mitigation measures:</p> <ul> <li>3 m-high perimeter wall, waterproofed up to 1,5 m</li> <li>Building elevation +1 m above primary urban level</li> <li>Rain-water balance basin for extreme weather events</li> <li>No water pipes inside the DC (air-based cooling)</li> </ul> </li> <li> <p>Infrastructure benefits from 218 patented technologies (granted or pending)</p> </li> </ul> <p>Certifications and compliance </p> <ul> <li>ISO 9001:2015 \u2013 Quality Management</li> <li>ISO 14001:2015 \u2013 Environmental Management</li> <li>OHSAS 18001 \u2013 Health &amp; Safety Management</li> <li>ISO 27001:2013 \u2013 Information Security Management</li> <li>ISO 50001:2011 \u2013 Energy Management</li> <li>ANSI/TIA-942-B:2017 \u2013 Rating 4 (Tier IV)</li> </ul> <p>Connectivity </p> <ul> <li>100 fiber pairs with diversified routes in multi-carrier configuration provide connectivity to each data hall</li> <li>All structured cabling (fiber, copper, electrical) runs through dedicated overhead trays</li> </ul> <p>Energy </p> <ul> <li>Campus powered by a redundant 132 kV high-voltage line, supporting up to 40 MW at full capacity </li> <li>Tri-redundant UPS system ensuring 100% availability</li> <li> <p>Electrical system engineered for Tier IV \u201csystem + system\u201d (2N+1) requirements</p> <ul> <li>Two completely independent electrical systems</li> <li>Each capable of supporting the full facility load</li> <li>Includes independent UPS, Bypass Modules, PDUs, RPPs</li> </ul> </li> <li> <p>Racks receive dual power feeds (Feed A + Feed B), each from separate electrical systems.</p> </li> </ul> <p>Cooling </p> <ul> <li>Cooling system based on modular AHUs (Air Handling Units)</li> <li>Utilizes indirect evaporative cooling, with air-to-air heat exchangers cooled by external water systems</li> <li>Designed to achieve PUE &lt; 1.4 (estimated)</li> <li>Steel infrastructure under the T-SCIF serves as a thermal flywheel to increase resilience</li> </ul> <p>Security </p> <p>Physical Security:</p> <ul> <li>Multilevel badge + numeric code access control</li> <li>24/7/365 security personnel and anti-intrusion systems. </li> <li>CCTV video surveillance with digital archiving (privacy-compliant)</li> </ul> <p>Data Hall Security:</p> <ul> <li>4 data halls (expandable to 6), up to 1,056 racks per hall </li> <li> <p>Racks organized into T-SCIF islands (Thermal Separate Compartment in Facility)</p> <ul> <li>Complete separation of hot and cold airflows</li> <li>Cage-protected</li> <li>Maximizes density and thermal efficien</li> </ul> </li> </ul> <p>Fire prevention system </p> <ul> <li>Intumescent paint on metal structures</li> <li>REI120 fire-resistant perimeter walls around technical areas </li> <li>Part of the electrical and environmental risk-mitigation strategy includes fire-resistant compartmentalization</li> </ul>"},{"location":"DC/#the-region-b-data-centers","title":"The Region B Data Centers","text":""},{"location":"DC/#dc-ge-1-fiumara","title":"DC GE 1 Fiumara","text":"<p>Building </p> <p>Tier II classification.</p> <p>Certifications and compliance </p> <p>ISO 27001.</p> <p>Connectivity </p> <p>Two redundant Dark fiber link 100 + 100 GB between GE1 and GE2.</p> <p>Energy</p> <p>The Data Center has two power supply branches, A and B, that reach the same substation, capable of delivering up to 1 MW (500 kW + 500 kW). The substation is served by:</p> <ul> <li>3 x 1600 kVA transformers</li> <li>1 medium voltage main switchboard.</li> <li>2 low voltage switchboards.</li> <li>An 824 kW generator.</li> <li>A 320 kW UPS.</li> </ul> <p>The work to bring the DC system into TIER III standards will be completed in 2026.</p> <p>Cooling </p> <p>It features an air cooling type cooling system composed of 7 CDZ with Water technology (with the use of Chilled) + Liquid cooling.</p> <p>Security </p> <p>Security levels implemented:</p> <ul> <li>Perimeter walls</li> <li>Reception</li> <li>Internal VDS system at the data center</li> <li>Fingerprint or badge access</li> <li>Internal armed surveillance system, 24/7.</li> </ul> <p>Fire prevention system </p> <p>Gas and NOVEC 1230 primer.</p> <p></p>"},{"location":"DC/#dc-ge-2-puccini","title":"DC GE 2 Puccini","text":"<p>Building </p> <p>It was built on TIER III logic.</p> <p>Certifications and compliance </p> <p>ISO 27001.</p> <p>Connectivity </p> <p>Two redundant Dark fiber link 100 + 100 GB between GE1 and GE2.</p> <p>Energy</p> <p>It has two certification branches, A and B. Currently, depending on the air conditioning units installed, the DC can accommodate a maximum of 340 kW of IT computing power. The characteristics of the two branches are as follows:</p> <ul> <li> <p>Branch A characteristics:</p> <ul> <li>DATA CENTER BRANCH \"A\" Distribution Cabinet</li> <li>1 1000 kW transformer</li> <li>1 LV main panel</li> <li>Equivalent earthing system connected to the main earthing system.</li> <li>1 576 kW Milantractor generator.</li> <li>1 UPS sized as follows:</li> <li>1 Piller 500 kW rotary unit each.</li> </ul> </li> <li> <p>Branch B characteristics:</p> <ul> <li>DATA CENTER BRANCH \"B\" Distribution Cabinet</li> <li>1 1000 kW transformer</li> <li>1 LV main panel</li> <li>Equivalent earthing system connected to the main earthing system.</li> <li>One 500 kW Perkins generator.</li> <li>One 576 kW Spark generator for air conditioning only.</li> <li>One UPS sized as follows:</li> <li>One 500 kW Piller rotary generator.</li> </ul> </li> </ul> <p>Cooling </p> <p>It has an Air cooling system composed of 6 CDZs with mixed Water (with the use of Chilled) and Gas technology.</p> <p>Security </p> <p>Security levels implemented:</p> <ul> <li>Perimeter walls</li> <li>Reception</li> <li>Internal VDS system at the data center</li> <li>Fingerprint or badge access</li> <li>Internal armed surveillance system, 24/7.</li> </ul> <p>Fire prevention system</p> <p>Water mist.</p> <p></p>"},{"location":"DC/#dc-ge-3","title":"DC GE 3","text":"<p>General specifications</p> <p>Landing of Blue &amp; Raman submarine cables. BlueMed system with branches between Italy, Africa, Europe, and the Middle East. Infrastructure designed to support up to six new submarine cables in the future via the Genoa Landing Platform.</p> <p>Certifications and compliance </p> <ul> <li>Multiple ISO certifications, including: ISO 9001, ISO 14001, ISO 45001, and ISO 27001</li> </ul> <p>Connectivity </p> <p>The data center has an active IP node for IP transit services. The IP node is integrated with Sparkle's global Tier-1 Seabone backbone. Submarine cables: the facility supports or plans to support multiple undersea cable systems, including BlueMed, Blue &amp; Raman, and Unitirreno. Interconnection / IX: The landing hub provides access to local IX ecosystems and supports peering; it is aligned with the local Ge-DIX Internet Exchange.</p> <p>Energy</p> <p>The data center is designed with environmental sustainability in mind.  Total installed power of 4.7 MW.</p> <p>Cooling </p> <p>Use of advanced cooling systems (including \"green\" techniques) and lithium-ion batteries.</p> <p>Security</p> <ul> <li>Digital security: Sparkle\u2019s corporate commitment includes security management aligned with ISO 27001.</li> <li>Services offered (security layer): the site supports DDoS protection and virtual NAP capabilities.</li> </ul>"},{"location":"DC/#the-region-c-data-centers","title":"The Region C Data Centers","text":""},{"location":"DC/#dc-rm-1-rome","title":"DC RM 1 Rome","text":"<p>General specifications</p> <ul> <li>Total surface area: 10.730 m\u00b2 </li> <li>Data hall surface area: 3.120 m\u00b2 </li> <li>Number of independent data rooms: 6 </li> <li>Floors on which the server rooms are distributed: 3</li> <li>Secure location in terms of earthquakes</li> <li>Secure location in terms of hydro-geological risks</li> </ul> <p>Building </p> <ul> <li>Height of the data hall: 3,5 m </li> <li>Height of upper plenum: 1,4 m </li> <li>Height of lower plenum:  1,95 m </li> <li>Load capacity of the floating floor: 2.000 kg/m\u00b2 (distributed load) - 1.000 kg/m\u00b2 (concentrated load in one place) </li> <li>External firewalls:  REI 240 </li> <li>Internal firewalls: REI 120</li> <li>Double insulation with defrost system</li> <li>Double loading bay</li> </ul> <p>Certifications and compliance </p> <ul> <li>ANSI/TIA 942-C-2024 Rating 4 (formerly Tier 4)</li> <li>ISO 9001 - Quality of services offered</li> <li>ISO 14001 - Environmental management system </li> <li>ISO 22237 - Data Center Lifecycle Management</li> <li>ISO 27001 - IT security </li> <li>ISO 45001- Workplace health and safety management system</li> <li>ISO 22301 - Business Continuity management system</li> <li>ISO 20000-1 - IT services management</li> </ul> <p>Connectivity </p> <ul> <li>Point of entrance: 6 </li> <li>Entrance Room: 2 </li> <li> <p>Main Distribution Area (MDA): 2 </p> <ul> <li>Carrier neutral data center</li> <li>Provision of managed connectivity</li> </ul> </li> </ul> <p>Energy </p> <ul> <li>Total power: 6 MW IT 2N (redundant) </li> <li>UPS redundancy: 2N+1 </li> <li>UPS type: double conversion static </li> <li>Individual UPS power: 500 kVA </li> <li>UPS run time: 15 minutes at full power on single module in emergency conditions - 30 minutes in standard conditions </li> <li>Generator redundancy: 2N </li> <li>Generator type: diesel generator units  </li> <li>Full load run time: 24h in emergency conditions,  48h in standard conditions, refill within 12h</li> </ul> <p>Cooling </p> <ul> <li>Cooling type: Chilled water  - water to air system </li> <li>Normal mode: air/water chiller to indirect free cooling </li> <li>Chiller redundancy: 2N </li> <li>CRAH redundancy: 2N</li> </ul> <p>Security </p> <ul> <li>CCTV</li> <li>24/7/365 security</li> <li>Separate parking for employees/visitors</li> <li>Vehicle bollards</li> <li>Separate entrance gates for visitors/goods</li> <li>Mantrap for visitors and goods with anti-tailgating</li> <li>Network Operations Center (NOC) 24/7/365</li> <li>Security Operations Center (SOC) 24/7/365</li> <li>Facility Operations Center (FOC) 24/7/365</li> <li>Building Management System (BMS)</li> </ul> <p>Fire prevention system </p> <ul> <li>Air exchange: 2vol/h </li> <li>Extinguishing system: inert gas  Extinguishing gas: IG-541 </li> <li> <p>Redundancy of extinguishing cylinders: 2N </p> <ul> <li>Highly sensitive smoke detection system</li> <li>Underfloor liquid loss detection system</li> <li>Fire detection and extinguishing system in each single module</li> <li>Standalone system on every generator unit</li> </ul> </li> </ul> <p></p>"},{"location":"DC/#dc-rm-2-acilia","title":"DC RM 2 Acilia","text":"<p>General specifications</p> <ul> <li>Total surface area: 8.000 m\u00b2</li> <li>Powered by two separate medium-voltage lines, each coming from distinct ACEA substations, ensuring electrical redundance</li> </ul> <p>Certifications and compliance </p> <ul> <li>Certified at Tier IV level, the highest standard for redundancy and uptime</li> <li>It holds ANSI/TIA-942 Rating 4 for facility design</li> <li> <p>Management and operations standards include:</p> <ul> <li>ISO 50001 (energy management) </li> <li>ISO 14001 (environmental management) </li> <li>ISO 27001 (information security) </li> <li>ISO 20000-1 (IT service management) and ISO 22301 (business continuity) </li> <li>ISO 9001 (quality management) </li> </ul> </li> <li> <p>The facility adheres to the European Data Center Code of Conduct for energy efficiency.</p> </li> </ul> <p>Connectivity </p> <ul> <li>It uses dual-ring fiber connectivity via two distinct Points of Entry (POEs), connecting to an optical backbone through POPs both located in Rome. </li> <li>The internal campus distribution ensures physically separate fiber paths between POEs and the meet-me rooms / data halls. </li> <li>The three AZs in Region A are interconnected via DWDM (Dense Wavelength Division Multiplexing) links, at high capacity, with a proprietary backbone for redundancy and low-latency.</li> </ul> <p>Energy </p> <ul> <li>It is powered with 100% renewable energy, aligning with TIM\u2019s sustainability targets. </li> <li>An onsite photovoltaic installation providing up to 75,000 W (75 kW) capacity. </li> <li>Energy management systems are real-time: the infrastructure monitors electrical and thermal parameters to drive predictive maintenance and efficiency optimizations.</li> </ul> <p>Cooling </p> <ul> <li>The cooling architecture uses air delivered via raised floor systems, with return air collected in alternating ceiling plenums. </li> <li>It includes free-cooling, using external air when conditions allow, to reduce the energy used by mechanical refrigeration. </li> <li>Geothermal heat exchangers (ground-based dispersers) are used for heat rejection from chillers when needed. </li> <li>A Building Management System (BMS) monitors temperature, humidity, and airflow to optimize when and how cooling is deployed</li> </ul> <p>Security </p> <ul> <li>External and internal fencing, with anti-climb perimeter protection. </li> <li>Armed security guard presence. </li> <li>Video surveillance (CCTV) throughout the site. </li> <li>Pedestrian access is controlled by security mantraps / turnstiles. </li> <li>Intrusion detection systems (perimeter alarms) and corner / glass protection: the windows are blast-resistant / reinforced. </li> <li>Internal security patrols / rounds. </li> <li>Access to critical system rooms (data halls) is through security airlocks (bussole) and requires badge-based dual authentication. </li> <li>Cybersecurity: the infrastructure is monitored by a Security Operation Center (SOC), providing continuous threat detection. </li> <li>The facility complies with the PSN\u2019s Technical Security Measures (MTMS), which define guidelines for logical segmentation, risk management, and protection</li> </ul> <p>Fire prevention system </p> <ul> <li>The Data Center is equipped with Very Early Smoke Detection Apparatus (VESDA) or similarly sensitive smoke detection systems to detect fire in its early stages</li> <li>The fire suppression uses 3M Novec 1230 as the extinguishing agent: it's electrically non-conductive, volume-expanding, and designed to absorb heat to inhibit the combustion reaction. </li> <li>The fire suppression system has redundancy to provide 2N (fully redundant) coverage and ensure reliability in case of activation</li> </ul> <p></p>"},{"location":"DC/#dc-rm-3-pomezia","title":"DC RM 3 Pomezia","text":"<p>General specifications</p> <ul> <li>The campus comprises a total area of ~51.000 m\u00b2, with 13 system-rooms and 6 telecom rooms</li> </ul> <p>Building </p> <ul> <li>The PISP building within Pomezia is elevated and built with a 0.9 m raised floor, offering enhanced protection in case of flooding</li> <li>Power is provided via two separate 20 kV medium-voltage lines from an ACEA substation, giving high reliability and redundancy</li> <li>The primary electrical distribution is designed with redundancy: primary distribution uses an N+1 logic, while secondary distribution is a+b (or N+1) with dual radial path</li> </ul> <p>Certifications and compliance </p> <ul> <li>The data center meets Uptime Institute Tier III standard</li> <li>It has ANSI/TIA-942 Rating 3 certification for facility design</li> <li>The system is compliant with multiple ISO standards: ISO 50001 (energy management), ISO 14001 (environmental management), ISO 9001 (quality), ISO 27001 (information security), ISO 22301 (business continuity)</li> </ul> <p>Connectivity </p> <ul> <li>Connected via a dual-fiber ring: two independent paths link it to main ISP'score network via the POPs both located in Rome</li> <li>The internal campus network ensures physically separate fiber routes between Points of Entry (POEs), meet-me rooms, and system rooms for redundancy</li> </ul> <p>Energy </p> <ul> <li>The electrical supply uses redundant medium-voltage (20 kV) lines, ensuring high availability</li> <li>It uses two diesel generators plus two DRUPS (UPS + generator combo) for backup power</li> <li>Fuel storage: there are two 15,000-litre double-walled diesel tanks with leak detection, strictly for emergency use</li> <li>It aims for sustainability: adhere to green energy standards.</li> </ul> <p>Cooling </p> <ul> <li>The cooling system is built with dual-loop refrigerant circulation (two independent loops) to remove heat efficiently across the campus</li> <li>On the rooftop, there are redundant chillers (N+1), ensuring that if one fails, thermal rejection can continue without service interruption</li> <li>Inside the system rooms, there are approximately 120 air-conditioning units to manage local heat load</li> </ul> <p>Security </p> <ul> <li>Physical security is multilayered: perimeter protection, intrusion detection, surveillance, and access control</li> <li>Access to sensitive rooms is controlled through security airlocks (\u201cmantraps\u201d) and requires badge-based authentication</li> <li>Cybersecurity is managed through a Security Operation Center (SOC), with continuous monitoring, threat detection, and incident response</li> </ul> <p>Fire prevention system </p> <ul> <li>The security manual (MTMS) mandates very early smoke detection systems to detect fire risk promptly</li> <li>Fire suppression likely uses inert, clean agents suitable for data centers, to avoid damaging sensitive IT gear</li> <li>The fire protection architecture is designed with redundancy, according to high-availability and resilience standards</li> </ul>"},{"location":"Faq/","title":"Frequently Asked Questions (FAQ)","text":""},{"location":"Faq/#1-infrastructure-as-a-service-iaas","title":"1. Infrastructure as a Service (IaaS)","text":"<p>1.1 What does Leonardo\u2019s IaaS offer? Leonardo provides compute, storage, and network resources suitable for cloud and hybrid environments. You can consult the list of services in the dedicated section Infrastructure as a Service (IaaS).</p> <p>1.2 What is \u201cConfidential Private IaaS\u201d? A highly secure environment that uses confidential computing to isolate and protect virtual machines. You can consult the details here Confidental Private IaaS.</p> <p>1.3 Does the IaaS support hybrid scenarios? Yes, resources can be distributed across cloud and Edge Location nodes. You can consult the details here Edge Location - Pool Small (Confidential).</p>"},{"location":"Faq/#2-container-as-a-service-caas","title":"2. Container as a Service (CaaS)","text":"<p>2.1 Which orchestration platform is used? A fully managed Kubernetes environment. You can consult the details here Kubernetes Confidential Computing.</p> <p>2.2 Is confidential computing supported for containers? Yes, workloads can run in isolated and secure environments.</p>"},{"location":"Faq/#3-platform-as-a-service-paas","title":"3. Platform as a Service (PaaS)","text":"<p>3.1 Which database services are available? PostgreSQL, MariaDB, MS SQL Server, MongoDB, GraphDB, Redis in-memory. You can consult the complete list here Platform as a Service (PaaS).</p> <p>3.2 What does the Middleware PaaS include? API management, CMS, workflow orchestration, and application integration. You can consult the complete list here Platform as a Service (PaaS).</p> <p>3.3 Are ETL or Data Lake services available? Yes, Data Lakes, ETL Pipelines, and governance tools are included. You can consult the details here Platform as a Service (PaaS).</p>"},{"location":"Faq/#4-artificial-intelligence-machine-learning","title":"4. Artificial Intelligence &amp; Machine Learning","text":"<p>4.1 Which AI services are available? OCR, NLP, translation, speech-to-text, vector search, LLMs, workflow AI. You can consult the complete list here Platform as a Service (PaaS).</p> <p>4.2 Can I integrate custom models? Yes, depending on the specific service selected.</p> <p>4.3 Are AI document-processing services available? Yes \u2014 including OCR, text extraction, and semantic analysis. You can consult the complete list here Platform as a Service (PaaS).</p>"},{"location":"Faq/#5-security-services","title":"5. Security Services","text":"<p>5.1 Which security services are offered?  You can consult the complete list here Platform as a Service (PaaS).</p> <p>5.2 Is IAM included? Yes, Identity and Access Management as a Service is included. You can consult the details here Identity &amp; Access Management (IAM) Service.</p> <p>5.3 Can security testing be automated? Yes, with automated vulnerability scans and assessments.</p>"},{"location":"Faq/#6-networking","title":"6. Networking","text":"<p>6.1 Which network features are included? IP, DNS, load balancers, CDN, advanced connectivity are some network services available. You can consult the complete list here Platform as a Service (PaaS).</p> <p>6.2 Is centralized traffic management supported? Yes, via load balancing and DNS services. You can consult the complete list here Platform as a Service (PaaS).</p> <p>6.3 Are hybrid and edge scenarios supported? Yes, with integration across cloud, edge, and data centers.</p>"},{"location":"Faq/#7-storage-data-protection","title":"7. Storage &amp; Data Protection","text":"<p>7.1 What storage options are available? Block storage, high-performance storage, archiving are some storage services available. You can consult the complete list here Platform as a Service (PaaS).</p> <p>7.2 Is a native backup service available? Yes, Data Protection provides managed backups.</p> <p>7.3 Can backup integrate with IaaS and PaaS? Yes, it is compatible with all service families.</p>"},{"location":"Faq/#8-big-data","title":"8. Big Data","text":"<p>8.1 Which Big Data services are provided? Data Lakes, ETL Pipelines, Data Governance, catalogs, analytics are some Big Data services available. You can consult the complete list here Platform as a Service (PaaS).</p> <p>8.2 Can external data be imported? Yes, via ETL pipelines supporting multiple sources.</p> <p>8.3 Is metadata management included? Yes, through a built-in data catalog.</p>"},{"location":"Faq/#9-devsecops","title":"9. DevSecOps","text":"<p>9.1 What does the DevSecOps offering include? CI/CD, automated testing, code analysis, configuration management are some DevSecOps services available. You can consult the complete list here Platform as a Service (PaaS).</p> <p>9.2 Can configurations be centrally managed? Yes, through Configuration Management services.</p> <p>9.3 Are code quality and security scans available? Yes, tools for scanning and verifying code are provided.</p>"},{"location":"Faq/#10-collaboration-services","title":"10. Collaboration Services","text":"<p>10.1 Which collaboration tools are included? Cloud-based instant messaging and enterprise communication features. You can consult the details here Instant Messaging.</p>"},{"location":"Faq/#11-hybrid-edge-services","title":"11. Hybrid &amp; Edge Services","text":"<p>11.1 What are Edge Services? Edge nodes (\u201cEdge Location \u2013 Pool Small\u201d) offering localized cloud capabilities. You can consult the details here Instant Messaging.</p> <p>11.2 When are edge services useful? Low-latency needs, distributed facilities, industrial sites, defense use cases. You can consult the details here Edge Location - Pool Small (Confidential)</p>"},{"location":"Faq/#12-service-management-sla-ticketing-monitoring","title":"12. Service Management (SLA, Ticketing, Monitoring)","text":"<p>12.1 Where can I find the SLAs? You can find it on the Service Level Agreement (SLA) section of the documentation.</p> <p>12.2 How do I activate a new service? By following instructions in the Service Provisioning section.</p> <p>12.3 Is a test account available? Yes \u2014 under Test Account Management with access here Test Account Management.</p> <p>12.4 How can I open a support ticket? Via the Ticket Management interface. You can consult the process here Service Management.</p>"},{"location":"Faq/#13-data-center-description","title":"13. Data Center Description","text":"<p>13.1 Where are Leonardo\u2019s Data Centers located? In secure, redundant, protected facilities. You can consult all details and specifications here Data Center Description.</p> <p>13.2 Which security standards are applied? Physical and logical protections, monitoring, redundancy, fire suppression, controlled access. You can consult all security details here Data Center Description.</p> <p>13.3 What availability level is ensured? High availability through infrastructure redundancy. You can consult all details here Data Center Description.</p> <p>13.4 Are multiple geographic areas supported? Yes, including Data Centers and Edge nodes. You can consult all Data Center architecture and interconnectionhere Data Center Description.</p> <p>13.5 What networking capabilities are included? Advanced routing, segmentation, load balancing, perimeter security. You can consult all details here Data Center Description.</p>"},{"location":"Faq/#14-provisioning","title":"14. Provisioning","text":"<p>14.1 How do I request service activation? By following steps in the Service Provisioning section. By following instructions in the Service Provisioning section.</p> <p>14.2 Is manual approval required? Yes, for selected services.</p> <p>14.3 How long does provisioning take? From minutes/hours (IaaS/CaaS) to longer deployments (AI, Big Data). By following instructions in the Service Provisioning section.</p> <p>14.4 Can provisioning be automated? Yes, via APIs, pipelines, and scripts. By following instructions in the Service Provisioning section.</p> <p>14.5 Where can I check request status? In the Service Management dashboard.</p>"},{"location":"Faq/#15-certifications","title":"15. Certifications","text":"<p>15.1. What certifications does Leonardo have for its services? You can consult all the certifications in the dedicated section Certifications</p> <p>15.2. What does the ISO/IEC 20000 certification mean for customers? This certification ensures that Leonardo\u2019s IT Service Management processes follow strict international quality standards\u2014providing higher reliability, structured support processes, and strong governance over delivered cloud services.</p> <p>15.3. Does Leonardo hold certifications related to information security? Yes. Leonardo invests heavily in information security and aligns its practices with global standards. The Cyber &amp; Security division continuously monitors systems and ensures compliance with internationally recognized frameworks.</p> <p>15.4. Does Leonardo have its own CERT? Yes. Leonardo operates the LDO-CERT (Leonardo Cyber Defence), which functions as both a Security Operation Center (SOC) and a Cyber Emergency Readiness Team, offering threat monitoring, detection, and incident response services.</p> <p>15.5. How does Leonardo ensure quality and regulatory compliance in Cyber &amp; Security activities? Leonardo implements strict governance policies, risk assessments, continuous audits, and monitoring of critical security processes. Certifications and the presence of an internal CERT reinforce Leonardo\u2019s ability to deliver proactive cybersecurity.</p> <p>15.6 Is Leonardo compliant with national or international regulatory requirements? Yes. Through Leonardo\u2019s certifications and robust security frameworks, the platform is aligned with key international standards and is designed for regulated sectors such as defense, public administration, and critical infrastructures.</p>"},{"location":"Faq/#16-cyber-security-services","title":"16. Cyber Security Services","text":"<p>16.1 What security measures does Leonardo offer? - Data encryption with secure key management (KMS). - Continuous monitoring and incident response via Leonardo\u2019s LDO-CERT SOC. - Built-in resilience policies, including disaster recovery and business continuity. - Software-defined architectures that improve isolation, automation, and control.</p> <p>16.2 Does Leonardo supports a Zero Trust security model? Yes. Leonardo is strengthening its cyber portfolio toward a Zero Trust architecture, where access is continuously validated, regardless of the user\u2019s position inside or outside the network.</p> <p>16.3. How does Leonardo manage cybersecurity emergencies? Leonardo\u2019s LDO-CERT performs: - Incident classification and response - Digital forensics - Threat analysis - Operational readiness for critical cyber events  </p> <p>16.4. Does Leonardo provide Cyber Resilience services? Yes. Leonardo provides a comprehensive Cyber Resilience model that includes risk identification, assessment, response, and continuous monitoring to ensure service continuity even during cyberattacks.</p> <p>16.5. Are the data stored on Leonardo protected and \u201csovereign\u201d? Yes: - Data is encrypted, and encryption keys can be customer-managed. - Geo-distributed storage enhances sovereignty and reduces single-point risk. - Security policies include continuous reviews and alignment with global standards.</p> <p>16.6 Does Leonardo collaborate with partners to enhance cloud security? Yes. For example: - Leonardo works with Aruba to deliver sovereign, high-performance cloud services enriched with cybersecurity capabilities. - Collaboration ensures national data residency and adherence to strict security standards.</p> <p>16.7 What international security standards does Leonardo follow? Leonardo follows industry best practices and global standards (including ISO frameworks), adopting modern governance, risk management, and compliance methodologies suitable for the current cybersecurity landscape.</p>"},{"location":"Hybrid/","title":"Hybrid Services","text":"<p>The following table lists the services included in the Hybrid category.</p> FAMILY LIST OF SERVICES Hybrid Edge Location - Pool Small (Confidential) Hybrid Bulk Data Transfer List of families and related Hybrid services"},{"location":"Hybrid/#hybrid-family","title":"Hybrid Family","text":"<p>Below is the list of services belonging to the Hybrid Edge family:</p> <ul> <li>Edge Location - Pool Small (Confidential</li> </ul> <p></p>"},{"location":"Hybrid/#edge-location-pool-small-confidential","title":"Edge Location - Pool Small (Confidential)","text":"<p> Edge Location - Pool Small (Confidential) Overview </p>"},{"location":"Hybrid/#services-description","title":"Services Description","text":"<p>The Edge Location Service provides a localized computing platform delivered across distributed edge locations, designed to offer low-latency processing, high availability, and centralized management. Built on Proxmox Virtual Environment as the core virtualization layer and integrated with a Leonardo Secure Cloud Management Platform (SCMP) for orchestration, automation, and governance, the service enables customers to deploy, manage, and scale applications and workloads directly at the edge, close to the point of data generation or consumption. The edge infrastructure operates as an extension of the corporate or hybrid cloud environment, maintaining consistent operational standards, security policies, and automation capabilities.</p> <p>The service is sized in host unit. A single unit is composed by 3 Hosts, with the following settings: 2x 24 Core CPU - 512 GB RAM - 32 TB SSD.</p>"},{"location":"Hybrid/#features-and-advantages","title":"Features and Advantages","text":"<p>The main functional capabilities of the service are:</p> <ul> <li>Application Hosting \u2192 execution of container-based or virtual machine\u2013based applications. Support for real-time workloads, IoT scenarios, and local data processing. Automated provisioning of application environments via CMP orchestration.</li> <li>Multi-tenant resource management \u2192 logical segmentation of resources for tenants or business units. Quota-based allocation of CPU, memory, storage, and network resources. Role-based access and differentiated permissions.</li> <li>Automation &amp; orchestration \u2192 automated provisioning of VMs, containers, and PaaS components. Standardized deployment workflows. Full lifecycle management of workloads (creation, update, decommissioning).</li> <li>Governance &amp; security \u2192 integration with Identity &amp; Access Management (IAM) systems. Enforcement of compliance and security policies. Centralized logging, audit trail capabilities, and continuous monitoring</li> <li>High availability &amp; resilience \u2192 Proxmox high-availability clustering with automated failover. Fault isolation and hardware resilience. Integrated backup and restore capabilities.</li> </ul> <p>The Architectural components are: </p> <ul> <li>Edge Compute Layer (Proxmox VE) \u2192 KVM hypervisor and LXC container virtualization. Proxmox clusters with distributed resource management. Local or distributed storage (Ceph, ZFS, or shared storage systems). Virtual networking using bridges, VLANs, and SDN capabilities</li> <li>Secure Cloud Management Platform (SCMP) \u2192 Central orchestration system managing all edge locations. Self-service portal for tenants and administrators. Policy engine for governance, permissions, and compliance enforcement. Monitoring, metering, and alerting functionalities. PIs for integration with external systems (CI/CD, ITSM, ERP) - Networking &amp; connectivity \u2192 secure connectivity between edge locations and datacenters (VPN, SD-WAN, MPLS). Network segmentation via virtualization technologies. Support for public and private addressing of workloads</li> <li>Integration with enterprise systems \u2192 integration with corporate authentication systems (LDAP, AD, SSO). Optional integration with Kubernetes for container-native workloads. Interoperability with public cloud platforms as part of a hybrid cloud model.</li> </ul> <p>Below are the technical and infrastructural requirements of cloud physical appliances that have been taken into consideration for the design of the technological solution for the services:</p> <ul> <li>Size and layout \u2192 the data center must have sufficient space to accommodate the necessary racks, with standard sizes (42U, 45U, or 48U) and configurations that allow easy access for maintenance and component management.</li> <li>Cabling \u2192 an organized and optimized cabling system is essential, with cables labeled and routed to minimize interference and facilitate technical interventions.</li> <li>Ventilation and cooling \u2192 racks must be located in spaces with adequate ventilation and cooling systems to prevent overheating and keep electronic components at optimal operating temperatures.</li> <li>Physical security \u2192 rack spaces must be protected from unauthorized access with physical security systems such as locks, biometric access controls, and continuous video surveillance.</li> <li>Power capacity \u2192 the data center must have adequate power to support expected workloads. This includes assessing the power required for each rack and planning the total capacity required.</li> <li>Redundant power supply \u2192 to ensure business continuity, it is necessary to provide redundant power systems such as uninterruptible power supplies (UPS) and emergency generators that can intervene in the event of a primary power outage.</li> <li>Power management \u2192 implement tools and technologies to monitor and manage energy consumption, optimizing resource use and reducing operating costs.</li> <li>Energy efficiency \u2192 use energy-efficient equipment and infrastructure to minimize consumption and environmental impact, adhering to best practices for data center energy management.</li> </ul> <p> Rack energy power output </p> <p> Power and BTU of appliances </p> <p>The service offers the following advantages:</p> <ul> <li>Reduced latency \u2192 processing occurs closer to the data source, improving performance for IoT, analytics, and real-time applications.</li> <li>Operational continuity \u2192 edge sites remain functional even in the event of connectivity loss to the central datacenter.</li> <li>Local data compliance \u2192 data remains within specific geographic boundaries, enabling regulatory adherence.</li> <li>Accelerated innovation \u2192 new services can be deployed rapidly across multiple sites using centralized orchestration.</li> <li>Unified management \u2192 a single platform controls all edge and cloud resources. Lower operational costs through automation of provisioning and routine maintenance.</li> <li>Modular scalability \u2192 the edge infrastructure can be expanded quickly with new nodes. Enhanced security through consistent policies and centralized logging.</li> <li>Architectural flexibility \u2192 support for VM-based, containerized, and mixed workloads.</li> <li>Operational efficiency \u2192 standardized processes for deployment, updates, and governance.</li> </ul> <p></p>"},{"location":"Hybrid/#bulk-data-transfer","title":"Bulk Data Transfer","text":""},{"location":"Hybrid/#supply-chain-for-storage-hardware-in-the-service-context","title":"Supply Chain for Storage Hardware in the Service Context","text":"<p>The supply chain for the specialized storage hardware used in the context of this service is a meticulously orchestrated ecosystem designed to ensure reliability, scalability, and compliance with stringent enterprise standards.  </p> <p>The hardware components\u2014primarily high-capacity storage appliances equipped with solid-state drives (SSD) or hybrid storage configurations\u2014are sourced through a vetted network of global manufacturers and distributors, emphasizing compatibility, resilience, and sustained performance under demanding operational conditions.  </p> <p>Raw materials and core electronic components typically originate from certified suppliers with strict quality controls and compliance certifications, encompassing ISO standards for manufacturing and environmental responsibility. These parts undergo assembly and rigorous quality assurance testing in strategically located manufacturing centers equipped with state-of-the-art fabrication and diagnostics tools to meet the exacting requirements of enterprise-grade data transfer solutions.  </p> <p>The finished appliances are then integrated with proprietary firmware and security modules before being provisioned at distribution hubs. These hubs serve as staging areas where customization\u2014such as encryption key injection, network configuration, and audit logging setup\u2014is applied in accordance with customer-specific parameters and security policies. From there, logistics chains involve carefully coordinated transportation utilizing trusted carriers capable of maintaining chain-of-custody protocols, tamper-proof packaging, and real-time tracking until delivery to the client site. </p> <p>This layered, end\u2011to\u2011end supply chain ensures that hardware is not only performant but also secure and fully traceable throughout its lifecycle, from component sourcing to customer deployment and eventual return for data ingestion and secure sanitization.</p>"},{"location":"Hybrid/#software-architecture-and-development","title":"Software Architecture and Development","text":"<p>The software underpinning the service is architected and developed by a dedicated specialized team comprising systems architects, software engineers, and security experts. This team typically operates within a corporate research and development environment with a focus on distributed storage systems, secure data transfer protocols, and device management frameworks. </p> <p>System architecture is designed to be modular, supporting scalability and interoperability with diverse enterprise environments and cloud storage backends. Software modules encompass embedded device firmware, secure boot and attestation layers, transfer orchestration engines, encryption key management subsystems, and centralized portals for device tracking, logging, and audit reporting. Development activities are governed by agile methodologies, emphasizing iterative testing, continuous integration/continuous deployment (CI/CD) pipelines, and strict adherence to internal coding standards as well as external compliance frameworks such as SOC 2, ISO/IEC 27001, and GDPR where applicable.  </p> <p>Cross-functional teams collaborate closely with supply chain, security, and operations units to ensure that software updates are rigorously validated for reliability and security before full deployment.</p>"},{"location":"Hybrid/#software-licensing-transparency-and-adaptability","title":"Software Licensing, Transparency, and Adaptability","text":"<p>The software components of the service embody a balanced approach to licensing and intellectual property protection, combining proprietary elements with open-source frameworks to facilitate transparency, security scrutiny, and adaptability.</p> <p>Core platform components leverage mature open-source libraries and protocols vetted by the community for security and performance, enabling rights for the client or partners to audit, adapt, and extend functionalities within defined license parameters (such as Apache 2.0, MIT, or similar permissive licenses).  </p> <p>For proprietary modules\u2014particularly those dealing with encryption, device attestation, and logistics orchestration\u2014customers and regulatory auditors are granted access to source code under non-disclosure agreements or via escrow arrangements to meet compliance and due diligence requirements. This ensures trust in the software stack\u2019s integrity, fosters collaborative innovation in extended use cases, and mitigates vendor lock-in risks.</p>"},{"location":"Hybrid/#security-patch-management-capabilities-independent-of-non-eu-vendors","title":"Security Patch Management Capabilities Independent of Non-EU Vendors:","text":"<p>To address geopolitical and regulatory concerns, the service provider maintains a robust local capability for developing, testing, and applying security patches independently of non-European Union (EU) vendors.  </p> <p>This strategy encompasses a dedicated European-based security engineering team integrated within the broader development organization, empowered to rapidly respond to emerging vulnerabilities and compliance directives. The team employs advanced vulnerability scanning, static and dynamic code analysis, and threat modeling tools supported by incident response program.  </p> <p>Patch development follows a rigorous lifecycle: discovery, analysis, coding remediation, multi-environment testing\u2014including integration and regression\u2014and staged rollout guided by well-defined risk criteria and communication protocols with customers.  </p> <p>This autonomous ecosystem reduces dependency on foreign-sourced software updates for critical security components, minimizes patching latency, and aligns with EU data sovereignty frameworks, reinforcing trust and operational continuity for customers with stringent data protection and audit requirements.</p>"},{"location":"ITSM/","title":"IT Service Management (ITSM)","text":"<p>The IT Service Management (ITSM) defines the process of the activities, responsibilities, and controls required to manage customer support requests in a structured, timely, and traceable manner. It applies to all types of tickets submitted by customers, including:</p> <ul> <li>Incidents (service disruptions or malfunctions).</li> <li>Service Requests (standard operational requests).</li> <li>Access Requests.</li> <li>Information Requests.</li> <li>Change-related inquiries.</li> <li>Other support needs requiring tracking and resolution.</li> </ul> <p>The objective is to ensure consistent quality of service, reduce resolution times, improve resource coordination, and maintain complete traceability of customer interactions Each phase includes defined roles, expected outputs, and quality criteria. Leonardo's methodology for delivering and supporting its services is inspired by ITIL\u00ae. The ITIL\u00ae framework has been used as a reference for delivering and improving services, particularly in the areas of Service Operation and Service Transition.</p>"},{"location":"ITSM/#process-steps","title":"Process steps","text":"<p>This section lists the process sequences for customer support requests.</p> <p>1) Ticket Intake The customer sends a request via email to the support address listed here: Send an email</p> <p>Upon receipt, the Service Desk (or designated support function) performs:</p> <ul> <li>Logging of the request into the ticketing system.</li> <li>Attribution of a unique ticket ID.</li> <li>Initial verification of provided information.</li> </ul> <p>All tickets are timestamped and stored for auditability.</p> <p>2) Classification and Prioritization The Service Desk categorizes the ticket into one of the predefined classes (Incident, Request, Access, etc.). Priority is determined using criteria such as:</p> <ul> <li>Impact (number of users/services affected).</li> <li>Urgency (time sensitivity of the issue).</li> <li>Service criticality (business relevance of the affected system).</li> </ul> <p>This ensures coherent treatment of tickets and alignment with Service Level Agreements (SLAs).</p> <p>3) Assignment After classification, the ticket is routed to the appropriate resolver group (e.g., Infrastructure, Application Support, Network Operations, Security, Service Delivery). Assignment criteria include:</p> <ul> <li>Required technical expertise.</li> <li>Workload distribution.</li> <li>Escalation rules.</li> <li>Operational hours and on-call availability.</li> </ul> <p>The resolver group assumes ownership of the ticket until resolution.</p> <p>4) Investigation and Resolution The assigned team performs root-cause investigation, corrective actions, or fulfillment activities depending on the ticket type. Typical activities include:</p> <ul> <li>System checks and diagnostics.</li> <li>Configuration adjustments.</li> <li>User guidance or remote assistance.</li> <li>Deployment of fixes or patches.</li> <li>Coordination with third-party vendors when applicable.</li> </ul> <p>Progress is continuously updated in the ticketing system.</p> <p>5) Customer Communication The customer is informed throughout the lifecycle of the ticket, including:</p> <ul> <li>Acknowledgement of receipt</li> <li>Status updates (especially for high-priority issues)</li> <li>Request for additional information</li> <li>Notification upon resolution</li> </ul> <p>Communication follows predefined templates and response-time commitments.</p> <p>6) Ticket Closure A ticket is closed only when:</p> <ul> <li>The solution has been delivered and validated.</li> <li>The customer has been informed.</li> <li>Documentation of actions taken is complete.</li> <li>Linked tickets (if any) have been updated.</li> </ul> <p>Quality controls ensure closure accuracy and SLA compliance.</p>"},{"location":"ITSM/#escalation-management","title":"Escalation management","text":"<p>Escalations ensure that prolonged or high-impact issues receive timely attention. They include:</p> <ul> <li>Functional escalation to more specialized teams.</li> <li>Hierarchical escalation to management when SLA breaches or major impacts are imminent.</li> <li>Vendor escalation for third-party system dependencies.</li> <li>Escalation paths and thresholds are predefined within the support framework.</li> </ul>"},{"location":"ITSM/#monitoring-and-quality-assurance","title":"Monitoring and quality assurance","text":"<p>Performance of the Ticket Management Process is monitored through KPIs such as:</p> <ul> <li>Ticket resolution time</li> <li>SLA compliance rate</li> <li>First Contact Resolution rate</li> <li>Backlog volume and aging</li> <li>Customer satisfaction feedback</li> </ul> <p>Periodic reviews identify improvement opportunities and ensure adherence to service standards.</p>"},{"location":"ITSM/#roles-and-responsibilities","title":"Roles and responsibilities","text":"<p>This section defines the roles, responsibilities, and operational boundaries for managing cloud services in accordance with a Shared Responsibility Model. The goal is to establish a clear framework that enables the secure, compliant, and efficient adoption of cloud services within the organization. The principles described here apply to all services offered and described in this documentation.</p> <p>Cloud security is a joint commitment between Leonardo, as a cloud service provider, and the organization, as a customer. Leonardo is responsible for cloud security, including physical infrastructure, network control layers, and platform services. The organization is responsible for cloud security, including data protection, identity and access management, workload configuration, and governance.  </p> <p>The distribution of responsibilities varies depending on the service model. As the organization adopts higher-level services (from IaaS to PaaS), Leonardo assumes a greater share of operational responsibility, while the organization retains responsibility for data, identity, and access governance.</p>"},{"location":"ITSM/#organizational-roles","title":"Organizational roles","text":"<p>To ensure effective management of shared responsibilities, the following internal roles are established:</p> <p>A) Platform/Cloud team</p> <p>Dedicated to the design, implementation, and management of the core cloud infrastructure. - Implements shared technical controls, including network configurations, platform security baselines, and monitoring frameworks. - Ennsures that Cloud environments comply with the organization's policies and technical standards.</p> <p>B) Workload/Application team</p> <p>Owns the design, security, and operation of specific workloads hosted in the cloud. - Manages application configurations, secure coding practices, updates, and lifecycle management. - Ensures appropriate data classification, protection, retention, and deletion practices.</p> <p>C) Security and compliance team</p> <p>Defines organizational security policies, standards, and regulatory controls.</p> <ul> <li>Conducts risk assessments and oversees compliance across cloud deployments.</li> <li>Implements identity and access management policies, encryption standards, and mandatory security controls.</li> </ul> <p>D) Governance and risk management</p> <p>Maintains the cloud governance framework, including the shared responsibility matrix.</p> <ul> <li>Ensures that cloud operations remain aligned with legal, regulatory, and organizational requirements.</li> <li>Coordinates reviews and audits to validate compliance and role execution.</li> </ul> <p>E) Operations and incident response team</p> <p>Provides monitoring and operational support for cloud environments and deployed workloads.</p> <ul> <li>Manages incident response procedures, including triage, remediation, and coordination with Microsoft where required.</li> <li>Ensures proper execution of change management policies.</li> </ul>"},{"location":"ITSM/#responsibility-matrix","title":"Responsibility matrix","text":"<p>A responsibility matrix is \u200b\u200bmaintained to explicitly document which responsibilities fall to Leonardo, which to the organization, and which are shared.  </p> <p> Division of responsibilities </p> <p>The matrix includes, but is not limited to, the following domains:</p> <ul> <li>Data protection and classification</li> <li>Identity and access management</li> <li>Security monitoring and threat detection</li> <li>Network and host security</li> <li>Application configuration and secure development</li> <li>Backup, restore, and recovery</li> <li>Compliance, auditing, and reporting</li> </ul> <p>This matrix is reviewed regularly and updated whenever service models, technologies, or organizational structures change.</p>"},{"location":"ITSM/#operational-processes","title":"Operational processes","text":"<p>The organization adopts a shared management operating model. The Platform Team provides standardized and secure environments and security barriers; the Workload Teams manage their solutions within these constraints. The Security and Governance Teams define mandatory controls and oversee compliance.</p> <p>Identity governance remains the organization's responsibility. The principles of least privilege, role-based access control (RBAC), and secure authentication must be implemented. Microsoft provides the identity platform, while the organization manages users, groups, and access permissions.</p> <p>The Workload Teams are responsible for ensuring the correct data classification and implementing the necessary protections, such as encryption, retention controls, and deletion policies.</p> <p>The Platform Team provides the technical capabilities for encryption, secure storage, and backup.</p> <p>Monitoring activities are shared:</p> <ul> <li>Leonardo monitors the security of the underlying cloud platform.</li> <li>The organization monitors workload behavior, user activity, configuration changes, and potential threats using security tools and logs.</li> </ul> <p>Incident responsibilities are divided by domain:</p> <ul> <li>Cloud infrastructure-related incidents may involve Leonardo.</li> <li>Incidents involving data, identities, workloads, or configurations fall within the responsibility of internal teams. A coordinated response plan ensures that escalation paths, communication channels, and reporting requirements are clearly defined.</li> </ul> <p>All changes to cloud resources must comply with the organization's change control procedures. Platform-level changes require coordination with the platform team; workload-level changes must be approved by the application teams, while remaining aligned with established Security and Governance policies.</p> <p>This framework is reviewed on a periodic basis to ensure continued relevance. Updates may be required when:</p> <ul> <li>new cloud services are introduced,</li> <li>organizational roles evolve,</li> <li>regulatory obligations change, or lessons learned from audits and incidents highlight areas for improvement.</li> </ul> <p>Continuous improvement is essential to maintaining a secure and well-governed cloud environment.</p>"},{"location":"IaaS/","title":"Infrastructure as a Service (IaaS)","text":"<p>The following table lists the services included in the Infrastructure as a Service (IaaS) category.</p> FAMILY LIST OF SERVICES Compute Confidental Private IaaS Compute Confidental Shared-IaaS (VMs) List of families and related IaaS services"},{"location":"IaaS/#compute-family","title":"Compute Family","text":"<p>Below is the list of services belonging to the Compute family:</p> <ul> <li>Confidental Private IaaS<ul> <li>Pool Small (Confidential)</li> <li>Pool Medium (Confidential)</li> <li>Pool Large (Confidential)</li> <li>Pool X-Large (Confidential)</li> </ul> </li> <li>Confidential Shared-IaaS (VMs)<ul> <li>VM Small (Confidential)</li> <li>VM Medium (Confidential)</li> <li>VM Large (Confidential)</li> <li>VM X-Large (Confidential)</li> </ul> </li> </ul> <p></p>"},{"location":"IaaS/#confidental-private-iaas","title":"Confidental Private IaaS","text":"<p> Confidental Private IaaS Architecture </p> <p> Administration of Confidental Private IaaS </p>"},{"location":"IaaS/#services-description","title":"Services Description","text":"<p>These services, deveoloped by Leonardo, enable the provision of Private virtual computing environments (IaaS), i.e., on a pool of physical resources, dedicated and isolated for each individual customer, based on the use of bare metal computing instances. Data from physical resources is encrypted and kept secure throughout all phases of use (at rest, in transit, and in use), leveraging the Confidential Computing paradigm. The Private IaaS (Confidential) services are based on the use of the Proxmox virtualizer, which allows the provision of IaaS services with confidential computing capabilities. Depending on the pool of computing resources required for each individual Organization, the most suitable service from the four available types can be selected:</p> Type Contained Elements Pool Small (Confidential) 3 Hosts (2xCPU 24 Core - 512 GB RAM - 32 TB SSD) Pool Medium (Confidential) 6 Hosts (2xCPU 24 Core - 512 GB RAM - 32 TB SSD) Pool Large (Confidential) 9 Hosts (2xCPU 24 Core - 512 GB RAM - 32 TB SSD) Pool X-Large (Confidential) 12 Hosts (2xCPU 24 Core - 512 GB RAM - 32 TB SSD) List of elements for each private IaaS pool"},{"location":"IaaS/#features-and-advantages","title":"Features and Advantages","text":"<p>Private Cloud resources are dedicated exclusively to each customer. The services use secure enclaves based on Trusted Execution Environments (TEEs) based on Confidential Hardware, which offer an advanced level of security for data in use, protecting it during processing. They support advanced encryption of data at rest, in transit, and in use. They use advanced remote attestation systems to verify the correctness of the TEE environment, isolating virtual machine memory from the host operating system and other malicious guests.</p> <p>The services offer the following advantages:</p> <ul> <li>Multi-Layer Security \u2192 data security and confidentiality in dedicated environments. Workload isolation through advanced virtualization. Dedicated firewalls and network micro-segmentation</li> <li>Faster Time-to-Market \u2192 automated provisioning and rapid resource management.</li> <li>Comprehensive control and centralized governance: centralized monitoring and auditing for traceability.</li> <li>Business continuity \u2192 built-in backup, snapshot, and high availability (HA) features ensure service continuity in case of hardware failures. Minimizes operational risk for critical applications.</li> </ul> <p></p>"},{"location":"IaaS/#confidential-shared-iaas-vms","title":"Confidential Shared-IaaS (VMs)","text":"<p> How to create a VM - Step 1 </p> <p> How to create a VM - Step 2 </p> <p> How to manage a VM </p>"},{"location":"IaaS/#services-description_1","title":"Services Description","text":"<p>These services, deveoloped by Leonardo, enable organizations or individuals to deploy and manage Virtual Machines (VMs) without the need to maintain their own physical servers.  They provide users with virtualized computing resources\u2014such as CPU, memory, storage, and networking\u2014hosted on a managed and shared physical infrastructure. The services are implemented using the Proxmox virtualizer, with a customized version offering Confidential Computing capabilities. Each user operates in a logically isolated environment, sharing the underlying hardware with other tenants. Data from physical resources is encrypted and kept secure during all phases of use (at rest, in transit, and in use), leveraging the Confidential Computing paradigm. Depending on the resource pool required by each individual organization, the most suitable service can be selected from the four available types:</p> Type Contained Elements VM Small (Confidential) 2 Vcpu 4 GB RAM VM Medium (Confidential) 4 Vcpu 8 GB RAM VM Large (Confidential) 8 Vcpu 16 GB RAM VM X-Large (Confidential) 16 Vcpu 32 GB RAM List of elements for each VMs type"},{"location":"IaaS/#features-and-advantages_1","title":"Features and Advantages","text":"<p>The services offer the following features:</p> <ul> <li>High Availability (HA) \u2192 automatic VM failover in case of node failure when HA is enabled.</li> <li>Backups \u2192 scheduled full or incremental backups using Proxmox Backup Server integration.</li> <li>Templates \u2192 predefined OS images (e.g., Ubuntu, Debian, CentOS, Windows Server) for rapid VM deployment.</li> <li>User Access \u2192 secure web interface and console access (noVNC/SPICE).</li> <li>Monitoring \u2192 real-time performance metrics and resource usage monitoring.</li> <li>Security and isolation \u2192 tenant isolation using VLANs and hypervisor-level separation.</li> <li>Access Control \u2192 role-based access control (RBAC).</li> <li>Data protection \u2192 encrypted storage backends and secure backup transfer protocols.</li> <li>Audit logging \u2192 comprehensive logging of user and system activities for compliance and troubleshooting.</li> <li>Provisioning \u2192 fully automated via API or web interface.</li> </ul> <p>The service architecture is built on a Proxmox cluster consisting of multiple physical nodes connected via a high-speed network. Each node contributes CPU, memory, and storage resources to a shared resource pool managed by Proxmox VE. The main components of the service are:</p> <ul> <li>Hypervisor \u2192 Proxmox VE with KVM (for full virtualization).</li> <li>Cluster management \u2192 centralized management via Proxmox Cluster Manager with quorum-based consistency.</li> <li>Storage backend \u2192 shared storage using Ceph supporting redundancy, scalability.</li> <li>Networking \u2192 virtual networking implemented through Linux bridges or VLAN tagging, with optional SDN integration for advanced network segmentation.</li> <li>Management interface \u2192 Web-based GUI and REST API for VM lifecycle operations (creation, modification, deletion, migration, snapshot, backup, restore).</li> </ul> <p>The services offer the following advantages:</p> <ul> <li>Cost reduction \u2192 no upfront investment in physical hardware, expensive hypervisor licenses, or datacenter infrastructure.</li> <li>Flexibility \u2192 resources (CPU, RAM, storage) can be scaled up or down quickly according to business needs.</li> <li>Faster Time-to-Market \u2192 virtual environments can be provisioned quickly. Ideal for testing, development, or rapid deployment of new services and applications. It reduces provisioning and approval times inside the organization.</li> <li>Capital and resource optimization \u2192 unused resources are dynamically shared across tenants, maximizing infrastructure efficiency. Better capital utilization compared to underused dedicated environments.</li> <li>Business Continuity \u2192 built-in backup and high availability (HA) features ensure service continuity in case of hardware failures. Minimizes operational risk for critical applications.</li> </ul>"},{"location":"PaaS/","title":"Platform as a Service (PaaS)","text":""},{"location":"PaaS/#general-features","title":"General features","text":""},{"location":"PaaS/#auto-scaling-scaling-to-zero","title":"Auto Scaling &amp; Scaling-to-Zero","text":"<p>The PaaS services described in this document are designed to run on orchestrated, cloud-native platforms where horizontal auto scaling is a native capability. Auto scaling dynamically adjusts the number of active instances in response to application load so that services can absorb traffic peaks while avoiding unnecessary over\u2011provisioning during off\u2011peak periods.</p> <p>At the platform level, an Horizontal Pod Autoscaler (HPA) or analogous controller continuously observes key metrics exposed by the workloads and the underlying infrastructure. These metrics commonly include CPU utilization, memory consumption, request rate, queue or backlog depth, and custom application indicators exported through standard monitoring interfaces. When the measured values exceed or fall below configured thresholds, the controller increases or decreases the replica count within the minimum and maximum limits defined for each service.  </p> <p>The same mechanism applies to many PaaS building blocks beyond purely stateless functions. These components can be configured to scale out when demand increases, distributing traffic across additional instances, and to scale in when demand subsides, consolidating activity on fewer instances. This behavior reduces the need for manual capacity planning, while still allowing organizations to define guardrails such as per\u2011tenant quotas, reserved capacity, or upper bounds imposed by licensing and compliance requirements.  </p> <p>For suitable workloads, several PaaS services also support scaling\u2011to\u2011zero. When a workload becomes idle and there are no active requests or tasks to process, the orchestration layer can progressively drain and stop all runtime instances associated with that service, leaving only the control and configuration plane active. In this state, compute capacity is released instead of being reserved for an idle service, which reduces the operational surface exposed to potential threats and improves infrastructure utilization. When new load arrives after a scale\u2011to\u2011zero phase, the platform automatically recreates the necessary runtime instances and starts routing work to them as soon as they become healthy; this can introduce a controlled start\u2011up latency, which can be mitigated for latency\u2011sensitive services by configuring a small minimum number of always\u2011on instances. </p> <p>Scaling\u2011to\u2011zero applies to workloads whose runtime instances can be stopped while still meeting durability and availability requirements. State\u2011heavy services such as relational databases, message brokers, and some analytics engines typically maintain at least one active replica or a minimal cluster footprint to guarantee durability, failover, and predictable performance characteristics. For these services, elasticity is achieved through controlled horizontal scaling of nodes, vertical tuning of resource allocations, and scheduled maintenance windows, with the serving tier remaining continuously available.  </p> <p>In all scenarios, auto scaling integrates with the platform\u2019s monitoring, logging, and governance capabilities. Scaling events are traceable, auditable, and can be correlated with business and security metrics to validate that capacity changes remain compliant with corporate policies.</p>"},{"location":"PaaS/#security-patching","title":"Security Patching","text":"<p>Security patching is part of the Vulnerability Management (VM) process and concerns the operational activities involved in applying software updates (called patches or fixes) designed to resolve security vulnerabilities found in operating systems, applications, firmware, or other IT components.</p> <p>In practice, security patching:</p> <ul> <li>fixes security flaws that could be exploited by attackers.</li> <li>improves system stability and reliability.</li> <li>reduces the risk of attacks such as malware, ransomware, or unauthorized access.</li> </ul> <p>These activities are carried out according to established schedules (Periodic VM) or as a result of risk analyses, internal/external alerts, or specific needs in response to urgent patches (such as emergency patches or zero-day patches), i.e., non-periodic (on-demand) VM.</p> <p>The VM process pursues the following objectives:</p> <ul> <li>identifying and assessing potential weaknesses (vulnerabilities) in the technological infrastructure.</li> <li>verifying compliance with security standards and corporate policies.</li> <li>checking the robustness of networks, systems, or applications against the possibility of exploitation by new cyber threats. evaluating the effectiveness of remediation actions taken to improve the security of systems, networks, or applications.</li> </ul> <p>The Security Operation Center (SOC), manages the VM process by performing the following activities:</p> <ul> <li>defines the scope of Vulnerability Management activities.</li> <li>contributes to planning the activities.</li> <li>relays any alerts or warnings from external or internal sources.</li> <li>analyzes the reports produced by the SOC.</li> <li>validates the remediation plan.</li> </ul> <p>The SOC, for its part, performs the following operational activities:</p> <ul> <li>collects vulnerability alerts from both internal and external sources.</li> <li>gathers information about the affected assets.</li> <li>plans, together with the CISO, security assessments aimed at identifying the technological perimeter subject to VM.</li> <li>carries out VA/PT activities and prepares the related reports.</li> </ul> <p>The phases of the vulnerability management process are:</p> <p>a) Planning b) Execution of activities c) Definition of the remediation plan d) Implementation of the remediation plan e) Monitoring</p> <p>In the specific case of PaaS services provided on the Kubernetes cluster, VM and security patching activities make use of the StackRox tool. StackRox  is the solution used to verify container security, providing capabilities to identify critical vulnerabilities in managed StackRox environments and supporting the processes of checking, monitoring, and correcting identified security issues:</p> <ul> <li>Vulnerability Management</li> <li>Network Segmentation</li> <li>Compliance</li> <li>Detection and Response</li> </ul>"},{"location":"PaaS/#encryption","title":"Encryption","text":"<p>The Data at Rest Encryption requirement\u2014i.e., ensuring the confidentiality of data stored on the infrastructure\u2019s disks through encryption\u2014is fulfilled by integrating the storage solutions, for both block storage and object storage, with a centralized Key Management System (KMS).  </p> <p>Specifically, for block storage, the confidentiality of data within Persistent Volumes (PV) created on the Kubernetes cluster infrastructure is ensured through the Ceph storage solution, which supports volume encryption. The enablement and configuration of the integration with the external KMS is performed at the storage class level, using the Key Management Interoperability Protocol (KMIP).  </p> <p>For object storage, the confidentiality of stored data is guaranteed through the native integration provided by the storage application solution (MinIO) with the KMS. MinIO supports automated SSE-KMS encryption for all objects written to a bucket, using a specific external key (EK) stored in the external KMS. MinIO encrypts stored data using a unique key retrieved from the KMS. The KMS is responsible for storing and managing the master key used to protect the data-encryption key utilized by the MinIO system.  </p> <p>All data-transmission communications are secured in accordance with the Data in Transit Encryption requirement. Protection is ensured through the mandatory use of the Transport Layer Security (TLS) protocol across all network channels. TLS provides confidentiality, integrity, and authentication for data exchanged between system components.</p>"},{"location":"PaaS/#replication","title":"Replication","text":"<p>The protection of data integrity and availability within the PaaS platform is ensured by integrating the Kubernetes cluster with a centralized backup service delivered through a Veeam solution.</p> <p>To integrate Veeam with Kubernetes clusters, the Veeam architecture must include a Media Agent responsible for executing the actual backup of the K8S cluster. Backup operations are performed through APIs exposed by the K8S infrastructure.</p> <p>The Kubernetes objects subject to backup are:</p> <ul> <li>the distributed etcd database hosted on the master nodes.</li> <li>the Persistent Volumes (Block &amp; File Storage) provided by the Ceph service.</li> </ul> <p>Given the criticality of the etcd database - which manages and stores the state and configuration of all objects within K8S - its backup is performed at a very high frequency (several times per hour). Furthermore, for certain types of applications (e.g., PostgreSQL databases) running on the K8S platform, achieving Application-Consistent backups requires integrating pre/post-backup scripts. These scripts place the application in a \u201cquiesce\u201d (read-only) state for the duration of the volume snapshot, and then perform an \u201cunquiesce\u201d operation to restore normal read-write activity. The Veeam backup platform allows the configuration of these pre/post scripts for each application requiring this approach to ensure Application-Consistent backup execution.</p>"},{"location":"PaaS/#high-performance-computing-description","title":"High Performance Computing description","text":"<p>The computational capacity is 14.3PFlops for the Davinci-2 is provided throught the GPUs NVIDIA H200 while 5PFlops for the Davinci-1 that is provided throught the GPU NVIDIA A100. Cooling is mixed, air and liquid depending on the technology and density-</p> <p>Technology assets:</p> <ul> <li>CPU Intel Cascade Lake</li> <li>CPU Intel Sapphire Rapids</li> <li>CPU AMD EPYC Rome</li> <li>CPU AMD EPYC Genoa</li> <li>NVIDIA A100 GPU</li> <li>NVIDIA Grace-Hopper</li> <li>NVIDIA H200 GPU</li> <li>NVIDIA RTX 8000 GPU</li> <li>NVIDIA L40s GPU</li> <li>AMD MI 300 GPU</li> </ul> <p>The infrastructure is hosted in Italy and managed entirely by internal staff. The architecture complies with NIST standards and is ISO27001 certified. Information management and protection is guaranteed by international standards and company policies. All data and infrastructure are hosted in Italy, with copying, backup, and redundancy systems.</p> <p>The virtualization platform used is OpenStack Community and OpenStack Canonical. Additional features developed by an internal team have been integrated into this platform.</p> <p>The entire application layer is based on Linux operating systems and open source software such as: Openstack, OpenPBS, Slurm.</p> <p>A testing system inside allows us to replicate features, so we can apply changes and patches without compromising production.</p>"},{"location":"PaaS/#list-of-services","title":"List of services","text":"<p>The following table lists the services included in the Platform as a Service (PaaS) category.</p> FAMILY LIST OF SERVICES Security Identity &amp; Access Management (IAM) Service Security Key Vault as a Service - Standard Security Endpoint Protection Security NGFW Platform Security PAM (Privileged Access Management) Security Intrusion Prevention System (IPS) Security PaaS Client/Foward Proxy Middleware PaaS API Management Middleware Functions As A Service (FAAS) Middleware Jboss as a Service Middleware Spring boot as a Service Middleware PaaS Business Process as a Service Middleware PaaS CMS as a Service Middleware Semantic Knowledge Search Data Protection Backup Infra &amp; Ops Platform Multicloud Management Platform Infra &amp; Ops Platform IT infrastructure Service Operations (Logging &amp; Monitoring) Infra &amp; Ops Platform PaaS Ticket Management Service Infra &amp; Ops Platform PaaS Operations Management DevSecOps Configuration Manager DevSecOps Test Automation DevSecOps Quality Code Analysis DevSecOps DevSecOps As A Service DevSecOps Qualizer DevSecOps Big Data Data Lake Big Data Business Intelligence Platform Big Data PaaS ETL Batch/Real time Processing Big Data Event Message Big Data Data Governance Artificial Intelligence (AI) Speech to Text Artificial Intelligence (AI) PaaS - AI Audio &amp; Video Analytics Artificial Intelligence (AI) OCR Artificial Intelligence (AI) Text Analytics/NLP     Artificial Intelligence (AI) Translation Artificial Intelligence (AI) AI Search - RAG Artificial Intelligence (AI) PaaS - AI Platform Artificial Intelligence (AI) AI SLM/LLM Collaboration Instant Messaging Database PaaS SQL - PostgreSQL Database PaaS SQL - MariaDB Database PaaS SQL - MS SQL Server EE Database PaaS SQL - MS SQL Server EE (BYOL) Database PaaS GraphDB Database PaaS NoSQL - MongoDB Database PaaS In Memory - Redis Networking PaaS CDN (Content Delivery Network) Networking PaaS Domain Name System (DNS) Networking Single public IP Networking L7 Load Balancer (regional) Networking Cloud interconnect Gold SW (10 Gbps max throughput) Networking Managed VPN Access Service Networking PaaS Client/Forward Proxy Networking PaaS Reverse Proxy Storage Block Storage (1000 GB) - High Density Storage Archive Storage (1000 GB) List of families and related PaaS services"},{"location":"PaaS/#security-family","title":"Security Family","text":"<p>Below is the list of services belonging to the Security family:</p> <ul> <li>Identity &amp; Access Management Service</li> <li>Key Vault as a Service - Standard</li> <li>End point protection</li> <li>NGFW Platform</li> <li>PAM (Privileged Access Management)</li> <li>Intrusion Prevention System (IPS)</li> <li>PaaS Web Application Firewall (WAF)</li> </ul> <p></p>"},{"location":"PaaS/#identity-access-management-iam-service","title":"Identity &amp; Access Management (IAM) Service","text":"<p> Identity &amp; Access Management Service (IAM) Overview </p>"},{"location":"PaaS/#service-description","title":"Service Description","text":"<p>The Service, , deveoloped by Leonardo, provides an essential level of security for identity and access management, ensuring basic protection against unauthorized access. It manages single sign-on access to guarantee access to all protected resources with a single authentication. It supports standard OIDC/OAUTH and SAML protocols for easy integration with applications and products. It enables first-level authentication with username/password and second-level authentication with multi-factor authentication based on Time-based One-Time Password (TOTP) protocols. It manages access authorization to system-protected resources only for users with rights to use them according to the Role-based Access Control (RBAC) and Attribute-based Access Control (ABAC) paradigms. Integration with external user repositories (LDAP or Active Directory) is also available. It manages the user lifecycle and related authorizations via the console.</p> <p>The service is offered with the following unit metric: 100 concurrent users.</p>"},{"location":"PaaS/#features-and-advantages","title":"Features and Advantages","text":"<p>The main features and functionalities of the service are:</p> <ul> <li> <p>Identity Management</p> <ul> <li> <p>User Management \u2192 creation, modification, and deletion of users; management of user profiles (name, email, custom attributes, roles, etc.); import/export of users from external directories (LDAP, Active Directory).</p> </li> <li> <p>Identity Federation \u2192 integration with external providers via LDAP or Active Directory; two-way or one-way synchronization of users and roles.</p> </li> <li>Account Management UI \u2192 self-service portal for users to update profiles and passwords, manage devices and active sessions, and view permissions.</li> </ul> </li> <li> <p>Access Management</p> <ul> <li>Single Sign-On (SSO) / Single Logout (SLO).</li> <li>Multi-Factor Authentication (MFA).</li> <li>Delegated Authentication (Identity Brokering).</li> <li>Role-Based Authorization (RBAC) and policies.</li> </ul> </li> <li> <p>Protocol and Integration</p> <ul> <li>Support for standard protocols, such as OpenID Connect (OIDC), OAuth 2.0, and SAML 2.0.\u00ec</li> <li>Ability to integrate  with API Gateways, microservices, and web frontends.</li> </ul> </li> <li> <p>Security and Management</p> <ul> <li>Session and Token Management.</li> <li>Password Policies.</li> <li>Events and Auditing.</li> <li>Scalability and High Availability \u2192 distributed architecture, with support for clustering and replication.</li> </ul> </li> <li> <p>Extensibility</p> <ul> <li>REST API for automated user, role, and client management.</li> <li>SPI (Service Provider Interfaces) for extending authentication, validation, or provisioning capabilities.</li> <li>Ability to implement custom authenticators or connect to external systems.</li> </ul> </li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Improved overall security \u2192 Centralizing authentication reduces the risk of vulnerabilities distributed across applications.</li> <li>Reduced maintenance and development costs \u2192 A single, centralized platform reduces the complexity and duplication of authentication code across applications.</li> <li>Agility and Scalability \u2192 Increased speed of onboarding new applications thanks to the use of standard protocols (OIDC, SAML, OAuth2).</li> <li>Maintainability and Standardization \u2192 Use of standard protocols (OIDC, SAML, OAuth2) that eliminate proprietary implementations and facilitate interoperability.</li> </ul> <p></p>"},{"location":"PaaS/#key-vault-as-a-service-standard","title":"Key Vault as a Service - Standard","text":"<p> Key Vault as a service Overview </p>"},{"location":"PaaS/#service-description_1","title":"Service Description","text":"<p>The service, based on Hashicorp Vault technology, provides a secure cloud repository (Vault) for storing and managing credentials and passwords used by cloud applications without having to manually install and manage dedicated IaaS machines. The service consists of a software platform that enables centralized and automated management of encryption keys, secrets, and certificates, with access controlled by identity-based authentication and authorization methods. It also allows organizations to significantly simplify key lifecycle management, ensuring centralized control while leveraging the native cryptographic capabilities of KMS providers.</p> <p>The service is offered with the following unit metric: 500 clients.</p>"},{"location":"PaaS/#features-and-advantages_1","title":"Features and Advantages","text":"<p>The main features and functionalities of the service are:</p> <ul> <li>Secure Secret Storage \u2192 Key/value secrets are stored in Key Vault As A Service in encrypted form, ensuring their integrity in the event of unauthorized access to raw storage.</li> <li>Dynamic Secrets \u2192 Key Vault As A Service can generate secrets on demand to allow users and/or applications to access different systems.</li> <li>Data Encryption \u2192 Key Vault As A Service can encrypt and decrypt workloads running on the PA infrastructure without archiving them, managing the entire lifecycle of the cryptographic material used in the encryption process.</li> <li>Leasing and Renewal \u2192 Key Vault As A Service associates a lease with each key or secret managed, which will result in its automatic revocation upon expiration and which can be renewed by clients through the integrated APIs provided by the platform.</li> <li>Revocation \u2192 Key Vault As A Service has integrated support for revoking keys and secrets, which can be revoked individually or in bulk (e.g., all keys of a specific user), for example in case of compromise.</li> </ul> <p>The service offers high availability and geographic replication. The main workflow of Key Vault as a Service consists of four phases:</p> <ul> <li>Authentication \u2192 The process by which a client provides information that Key Vault as a Service uses to determine the authenticity of the requester. Once the client is authenticated, the system generates a token that is associated with the relevant policy.</li> <li>Validation \u2192 Validation occurs through trusted third-party sources, such as Active Directory, LDAP, and Okta.</li> <li>Authorization \u2192 The client is then associated with the Key Vault as a Service security policy, which consists of a set of rules that define which API endpoints a user, machine, or application is allowed or denied access to with its token.</li> <li>Access \u2192 Key Vault as a Service then grants access to keys and encryption features, secrets, and certificates.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Risk reduction \u2192 thanks to automatic key rotation and secret lifecycle management, it increases the protection of sensitive data, simplifies regulatory compliance and reduces the risk of human errors.</li> <li>Operational efficiency and cost reduction \u2192 less internal management, automation and standardization, scalability without hardware investment.</li> <li>Optimized time-to-market \u2192 developers focus on code, not key management; also enables secure applications to be delivered faster, improving agility and innovation.</li> <li>Improved trust and reputation \u2192 audit and traceability to demonstrate secure secret management to stakeholders or customers.</li> <li>Cryptographic and standardized compliance \u2192 can be configured to use FIPS (Federal Information Processing Standards) validated cryptographic modules, ensuring that all encryption, signing, HMAC and key derivation operations comply with the standards.</li> </ul> <p></p>"},{"location":"PaaS/#endpoint-protection-service","title":"Endpoint Protection Service","text":"<p> Endpoint Protection Service Overview </p>"},{"location":"PaaS/#service-description_2","title":"Service Description","text":"<p>Powered by Bitdefender technology, the Endpoint Protection Service offers comprehensive protection for endpoint devices against malware, ransomware, and other threats, including antivirus, firewall, and application control capabilities. The service aims to provide the customer with an EPP platform for multi-layered protection of their endpoint devices, with capabilities to prevent, detect, and respond to cyber threats targeting those devices, including antivirus, anti-malware, personal firewall, web protection, application control, and patch management. The service provides a cloud-delivered, scalable, and centrally managed solution designed to protect customer endpoint devices from a broad spectrum of cyber threats. The service is delivered as a managed PaaS solution, offering continuous protection and simplified administration for organizations seeking robust endpoint security without the overhead of managing on-premise security infrastructures.</p> <p>The service is offered with the following unit metric: 100 endpoints.</p>"},{"location":"PaaS/#features-and-advantages_2","title":"Features and Advantages","text":"<p>The Endpoint Protection service offers a full suite of integrated security functions aimed at ensuring endpoint resilience and threat visibility across the organization:</p> <ul> <li>Antivirus and anti-Malware protection \u2192 continuous real-time scanning, heuristic analysis, and signature-based detection to identify and block known and emerging threats.</li> <li>Behavioral and threat analysis \u2192 advanced behavioral monitoring and threat intelligence integration to detect and mitigate unknown or zero-day attacks.</li> <li>Personal firewall \u2192 endpoint-level firewall providing granular control over inbound and outbound network connections, preventing unauthorized access and lateral movement.</li> <li>Web protection and URL filtering \u2192 protects users from malicious or fraudulent websites by evaluating URLs and blocking access to unsafe domains.</li> <li>Application control \u2192 allows administrators to define and enforce policies for approved and restricted applications, reducing the risk of untrusted software execution</li> <li>Patch and vulnerability management \u2192 automates the identification, prioritization, and deployment of patches and updates for operating systems and third-party applications.</li> <li>Centralized management console \u2192 offers unified visibility and control over all protected endpoints, enabling configuration management, alert handling, policy enforcement, and reporting from a single interface.</li> <li>Incident Detection and Response (EDR Integration) \u2192 provides integration capabilities with Endpoint Detection and Response tools to enhance investigation and automated remediation processes.</li> <li>Reporting and compliance monitoring \u2192 delivers customizable reports and dashboards to support compliance with organizational and regulatory security standards.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Endpoint Agent \u2192 a lightweight client installed on each endpoint device that performs local threat detection, policy enforcement, and communication with the management server. Management and control console \u2192 the central administrative interface, hosted within the PaaS environment, responsible for policy management, configuration, event correlation, and reporting.</li> <li>Threat intelligence service \u2192 continuously updated databases and analytics engines that provide real-time intelligence on emerging threats, indicators of compromise (IoCs), and reputation data.</li> <li>Policy management module \u2192 defines and distributes security configurations and operational rules across endpoint agents, ensuring uniform protection and compliance.</li> <li>Update and Patch Repository \u2192 centralized repository for antivirus signatures, security updates, and software patches, ensuring endpoints are continuously updated with the latest protection mechanisms. Event correlation and logging module \u2192 collects and analyzes security events from all endpoints, correlating data to detect anomalies and trigger automated responses when threats are identified. Integration and API layer \u2192 enables interoperability with other PSN security services (such as SIEM, SOC, or IAM systems) for advanced monitoring, alerting, and orchestration.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Comprehensive, multi-Layered protection \u2192 combines antivirus, anti-malware, firewall, web protection, and application control for complete endpoint security coverage.</li> <li>Centralized management and visibility \u2192 a unified management console provides real-time visibility across all endpoints, simplifying administration and reducing operational complexity.</li> <li>Continuous updates and threat intelligence \u2192 the service is continuously updated with the latest threat intelligence feeds, ensuring protection against emerging and zero-day threats.</li> <li>Automated patch and vulnerability management \u2192 streamlines the detection and remediation of system vulnerabilities, maintaining secure and compliant endpoint configurations.</li> <li>Advanced detection and Rrsponse capabilities \u2192 integrates with EDR (Endpoint Detection and Response) systems for enhanced detection, investigation, and automated threat remediation.</li> <li>High availability and resilience \u2192 built on a redundant and fault-tolerant cloud infrastructure to ensure uninterrupted protection and service continuity.</li> <li>Rapid incident response and containment \u2192 provides automated isolation and remediation of compromised endpoints, minimizing attack spread and impact.</li> <li>Integration with security ecosystem \u2192 supports API-based integration with SIEM, SOC, and IAM systems for centralized event correlation and coordinated response.</li> <li>Policy standardization across devices \u2192 ensures consistent security policies and enforcement across heterogeneous endpoint environments (Windows, macOS, Linux, mobile).</li> <li>Detailed reporting and analytics \u2192 offers customizable dashboards and reports for compliance, performance monitoring, and trend analysis.</li> </ul> <p></p>"},{"location":"PaaS/#ngfw-platform","title":"NGFW Platform","text":"<p> NGFW platform Overview </p>"},{"location":"PaaS/#service-description_3","title":"Service Description","text":"<p>The Next-Generation Firewall (NGFW) service, based on OPNsense technology, implements a firewall application system to manage inbound and outbound traffic flows. The platform includes all the advanced features of a firewall with additional threat detection capabilities based on artificial intelligence and machine learning. The device is also capable of analyzing the content of network packets, down to the application layer (deep packet inspection), and managing rules based on more than just ports and protocols. The service delivers intelligent traffic inspection, application-aware control, intrusion prevention, and threat detection across cloud, on-premise, and hybrid infrastructures. Unlike traditional firewalls that rely solely on port and protocol filtering, the NGFW PaaS incorporates deep packet inspection (DPI), machine learning-based threat analysis, and context-aware security policies to identify and mitigate sophisticated attacks, including malware, ransomware, zero-day exploits, and data exfiltration attempts.</p> <p>The service is offered with the following unit metric: 1 Gbps of Throughput.</p>"},{"location":"PaaS/#features-and-advantages_3","title":"Features and Advantages","text":"<p>The main features and functionalities of the service are:</p> <ul> <li>Intrusion prevention system (IPS) \u2192 provides signature-based and behavior-based detection to prevent known and unknown exploits. Protects against buffer overflows, SQL injection, cross-site scripting, and command injection attacks. Continuously updated with global threat intelligence feeds.</li> <li>Virtual Private Network (VPN) and secure remote access \u2192 provides site-to-site and remote access VPN with AES-256 encryption. Supports IPsec, SSL, and hybrid VPN tunnels for secure communication. Integrates with multi-factor authentication (MFA) for secure user access.</li> <li>Logging, monitoring, and analytics \u2192 real-time visibility into network traffic, user activity, and threat events. Integrated dashboards and customizable reports for compliance and auditing. Supports integration with SIEM/SOAR platforms for advanced analytics and incident response.</li> <li>High availability and scalability \u2192 redundant architecture ensuring failover, session synchronization, and minimal downtime. Auto-scaling capabilities to handle fluctuating workloads and peak network demand. Supports multi-zone and multi-region deployment for resilience and disaster recovery.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Web filtering and URL categorization / Web and email security \u2192 filters web traffic by category, blocks o restringe accesso a siti malevoli o non autorizzati.\u201d \u2014 Corretto, almeno a livello di proxy/filtraggio tramite plugin (es. proxy HTTP/HTTPS, filtraggio URL/blacklist). </li> <li>Firewall enforcement nodes / Stateful firewall, policy-based filtering, support VLAN, NAT, port forwarding, etc.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Enhanced cyber resilience \u2192 provides continuous protection against advanced cyber threats, ensuring business continuity and minimizing the risk of network downtime, data loss, or reputational damage.</li> <li>Regulatory compliance and risk reduction \u2192 simplifies compliance with major cybersecurity frameworks by enforcing standardized policies, secure configurations, and comprehensive audit logging.</li> <li>Operational efficiency and cost optimization \u2192 delivered as a managed PaaS, the service eliminates the need for dedicated hardware, manual updates, and specialized maintenance, significantly reducing operational costs.</li> <li>Scalable and flexible network protection \u2192 cloud-native design enables dynamic scaling according to traffic demand, ensuring consistent performance across hybrid and multi-cloud environments.</li> <li>Accelerated security modernization \u2192 enables organizations to transition from legacy firewalls to a modern, intelligent, and centrally managed security platform without downtime or complex migrations.</li> <li>Improved Visibility and Governance \u2192 consolidates monitoring and policy control across distributed environments into a single interface, empowering governance, risk, and compliance teams.</li> <li>Faster incident response \u2192 automated detection and orchestration reduce the time to identify and mitigate attacks, minimizing business impact and resource overhead.</li> <li>Business continuity and resilience \u2192 redundant and geo-distributed infrastructure ensures uninterrupted protection and service availability even during outages or attacks. Support for digital transformation initiatives \u2192 enables secure adoption of cloud services, remote access, and IoT solutions by integrating network security directly into cloud workflows.</li> <li>Comprehensive layered protection \u2192 combines firewall, intrusion prevention, antivirus, web filtering, and sandboxing into a unified, multi-layered security stack. Application and user awareness \u2192 identifies and controls applications and users regardless of port, protocol, or encryption, ensuring contextual, identity-based access control.</li> <li>Deep Packet Inspection (DPI) \u2192 examines every packet in real-time to detect encrypted or obfuscated threats, ensuring accurate threat identification and minimal false positives.</li> <li>AI-Driven threat detection and prevention \u2192 uses artificial intelligence, behavioral analytics, and threat intelligence feeds to detect zero-day attacks, ransomware, and polymorphic malware.</li> <li>Centralized Policy Management \u2192 provides unified control of security rules, compliance baselines, and configurations across all NGFW instances through a single management console.</li> <li>Real-Time analytics and reporting \u2192 offers comprehensive visibility into traffic patterns, security events, and policy compliance, with exportable reports for auditing and SOC integration.</li> <li>High availability and elastic scalability \u2192 implements active-active clustering, load balancing, and autoscaling to maintain performance and fault tolerance under varying network loads.</li> <li>Zero Trust and microsegmentation support \u2192 enforces least-privilege access and segmentation at the application, user, and workload level to contain breaches and minimize lateral movement.</li> <li>Integration with security ecosystem \u2192 seamlessly connects with SIEM, SOAR, CSPM, and IAM platforms for unified threat management, incident response, and automation workflows.</li> <li>Secure VPN and remote access \u2192 delivers site-to-site and user-based VPN capabilities with strong encryption and MFA integration for secure remote connectivity.</li> <li>Automated policy enforcement and updates \u2192 automatically distributes updated rules, signatures, and threat intelligence across all firewalls, ensuring continuous protection with minimal manual effort.</li> <li>Robust logging, monitoring, and auditability \u2192 maintains detailed, immutable logs for compliance, forensics, and real-time incident response, ensuring full visibility and traceability.</li> <li>Support for multi-tenant and hybrid environments \u2192 designed for organizations and service providers managing multiple clients or business units with logical separation and delegated administration.</li> </ul> <p></p>"},{"location":"PaaS/#pam-privileged-access-management-service","title":"PAM (Privileged Access Management) Service","text":"<p> PAM (Privileged Access Management) Service Overview </p>"},{"location":"PaaS/#service-description_4","title":"Service Description","text":"<p>Based on SSH solution, the Privileged Access Management (PAM) service manages and protects privileged access to critical environments, including credential management, session control, and real-time monitoring. PAM allows organizations to activate a privileged access management system. Its purpose is to act as a bridge between users (especially administrators) and the systems they manage, ensuring that administrative credentials are protected within a \"vault\" and hidden from the administrators themselves. Furthermore, the system can rotate administrative credentials or deny access to an administrator on a per-profile basis. Privileged accounts \u2014 such as system administrators, database managers, and DevOps automation services \u2014 represent a primary attack vector for cybercriminals. Compromise of these accounts can lead to severe data breaches, ransomware propagation, or full system takeover. The PAM PaaS delivers identity-centric protection and governance for all privileged credentials, sessions, and activities across on-premises, cloud, and hybrid environments. It enforces the principle of least privilege, enables session monitoring and recording, and automates credential rotation, vaulting, and just-in-time access provisioning to minimize risk exposure. Delivered as a managed PaaS, the service eliminates the complexity of deploying and maintaining traditional PAM infrastructure, providing organizations with continuous protection, compliance enforcement, and operational efficiency.</p> <p>The service is offered with the following unit metric: 10 administrative users.</p>"},{"location":"PaaS/#features-and-advantages_4","title":"Features and Advantages","text":"<p>The PAM PaaS provides a rich set of functionalities to secure and manage privileged accounts, credentials, and access sessions throughout their lifecycle.</p> <ul> <li>Centralized credential vaulting \u2192 securely stores and manages privileged credentials (passwords, SSH keys, API tokens, certificates) in an encrypted vault. Eliminates hard-coded or shared credentials across systems. Provides strong encryption, multi-factor authentication, and access auditing.</li> <li>Automated password and key rotation \u2192 enforces automatic, policy-driven rotation of privileged passwords and cryptographic keys.Integrates with directories, databases, network devices, and cloud services. Reduces exposure time in case of credential compromise.</li> <li>Just-in-Time (JIT) privilege elevation \u2192 grants temporary, time-bound privileged access based on contextual approval workflows. Automatically revokes privileges after task completion. Minimizes standing privileges and insider threat exposure.</li> <li>Session management and monitoring \u2192 records, monitors, and audits all privileged sessions (SSH, RDP, SQL, web consoles). Enables real-time session oversight and automated termination on policy violation. Provides full playback for forensic investigation and compliance.</li> <li>Multi-Factor Authentication (MFA) and adaptive access \u2192 enforces MFA for all privileged access events. Supports adaptive authentication based on device, geolocation, and behavioral risk scoring. Integrates with corporate identity providers (Azure AD, LDAP, SAML, OIDC).</li> <li>Role-Based Access Control (RBAC) \u2192 assigns privileges based on predefined roles, ensuring least-privilege enforcement. Supports fine-grained policies that define who can access what, when, and how. Facilitates separation of duties for compliance with ISO 27001 and NIS2.</li> <li>Command filtering and policy enforcement \u2192 inspects and filters privileged commands during active sessions.Blocks or flags suspicious commands or administrative actions in real time. Supports custom rule sets aligned with compliance and internal security standards.</li> <li>Secure remote access gateway \u2192 provides agentless, browser-based remote access to critical systems without exposing credentials. Supports RDP, SSH, and web management interfaces through encrypted tunnels. Logs all session activity for security and compliance.</li> <li>Integration with SIEM and SOAR platforms \u2192 sends logs, events, and alerts to centralized SIEM/SOAR solutions. Enables automated incident response, anomaly detection, and correlation with threat data. Provides standardized APIs and connectors for integration.</li> <li>Privileged Account Discovery \u2192 scans the environment to identify unmanaged privileged accounts, keys, and secrets. Assesses risk exposure and automates onboarding into the vault. Supports discovery across Active Directory, cloud platforms, databases, and containers.</li> <li>Audit, compliance, and reporting \u2192 provides detailed reports on access requests, approvals, and session activity. Supports compliance with GDPR, ISO 27001, PCI-DSS, HIPAA, and NIS2 directives. Offers customizable dashboards and automated report scheduling.</li> <li>Threat analytics and anomaly detection \u2192 leverages behavioral analytics to identify suspicious privileged user behavior. Detects deviations from normal activity patterns using AI and machine learning models. Generates alerts and can automatically revoke access on detected anomalies.</li> <li>API and DevOps integration \u2192 provides RESTful APIs and SDKs for integrating PAM controls into CI/CD pipelines. Protects privileged secrets in DevOps environments (Jenkins, GitLab, Ansible). Enables machine identity management and service account governance.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Credential vault (Secure storage layer) \u2192 core repository for all privileged credentials, keys, and secrets. Implements AES-256 encryption, HSM integration, and strong key management. Enforces access via secure APIs and MFA-protected sessions.</li> <li>Access control and policy engine \u2192 centralized component that enforces RBAC, access approval workflows, and least-privilege rules. Evaluates contextual access conditions (user role, time, device, risk score). Integrates with IAM and directory services for authentication and authorization.</li> <li>Session management and recording subsystem \u2192 manages all privileged session connections, including RDP, SSH, and database access. Captures full video/audio/text logs of user sessions for replay and forensic analysis. Supports live session termination, keystroke logging, and behavioral analytics.</li> <li>Just-in-Time (JIT) access provisioning engine \u2192 automates temporary privilege elevation for approved tasks. Integrates with ITSM systems for request/approval workflows. Ensures access expiration and automatic credential revocation.</li> <li>Discovery and onboarding module \u2192 continuously scans infrastructure to locate unmanaged privileged accounts and secrets. Automatically imports discovered credentials into the vault. Generates visibility reports and risk scores for unprotected assets.</li> <li>Multi-Factor Authentication and identity federation layer \u2192 connects with enterprise IAM systems for identity verification. Supports SSO, SAML 2.0, OIDC, and FIDO2 standards.Applies adaptive MFA policies based on context and risk posture.</li> <li>Analytics and threat detection engine \u2192 aggregates PAM telemetry to detect abnormal privileged activity. Uses AI-based behavioral baselines for early threat detection. Feeds alerts and analytics to SIEM/SOAR systems for incident correlation.</li> <li>Secure remote access gateway \u2192 provides proxy-based, credential-free access to internal systems. Prevents credential exposure during remote administration. Logs all actions for compliance and traceability.</li> <li>Integration and API gateway \u2192 exposes APIs for integration with ITSM, SIEM, SOAR, DevOps, and IAM tools. Supports automation and policy synchronization across multi-cloud environments. Enables secure machine-to-machine communications.</li> <li>Logging and audit repository \u2192 centralized collection point for all PAM events, access logs, and session data. Ensures immutability and time synchronization for forensic integrity. Supports long-term storage and secure archiving.</li> <li>Web management console \u2192 provides administrators with a unified interface for configuration, policy management, and monitoring. Offers dashboards, risk indicators, and compliance views. Supports delegated administration and role-based visibility.</li> <li>High availability and scalability layer \u2192 multi-zone deployment with redundant components to ensure continuous availability. Supports horizontal scaling for concurrent session and credential workloads. Implements backup, failover, and disaster recovery capabilities.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced risk of data dreaches and insider threats \u2192 minimizes the attack surface by enforcing strict control and monitoring of privileged accounts, effectively reducing both external and insider threat vectors.</li> <li>Regulatory and compliance alignment \u2192 simplifies adherence to key cybersecurity and privacy frameworks through standardized access policies, complete audit trails, and automated compliance reporting.</li> <li>Improved security governance and accountability \u2192 centralizes management of all privileged identities and enforces policy consistency across business units, increasing accountability and transparency.</li> <li>Operational efficiency and cost savings \u2192 delivered as a managed PaaS, it eliminates the need for on-premises infrastructure, manual credential management, and complex maintenance tasks, reducing operational overhead and total cost of ownership.</li> <li>Enhanced Business Continuity \u2192 ensures uninterrupted access to critical systems while maintaining full security control, even during infrastructure failures or security incidents.</li> <li>Support for digital transformation and cloud adoption \u2192 enables secure access to hybrid and multi-cloud environments, supporting DevOps pipelines, cloud-native workloads, and remote operations securely and efficiently.</li> <li>Increased organizational agility \u2192 automated workflows and just-in-time access provisioning streamline operational processes and accelerate response to evolving business and security needs.</li> <li>Improved trust and peputation \u2192 demonstrates strong security posture to clients, partners, and regulators by safeguarding the most sensitive access credentials and administrative activities.</li> <li>Comprehensive privileged access lifecycle management \u2192 covers the full lifecycle of privileged credentials \u2014 discovery, vaulting, rotation, monitoring, and decommissioning \u2014 ensuring continuous protection.</li> <li>Centralized and secure credential vaulting \u2192 uses enterprise-grade encryption and hardware security modules (HSMs) to protect privileged credentials and secrets from unauthorized disclosure.</li> <li>Automated password and key rotation \u2192 reduces credential exposure by automatically rotating and updating passwords, API keys, and certificates according to customizable security policies.</li> <li>Just-in-Time (JIT) access control \u2192 eliminates permanent administrative privileges by providing temporary, task-based elevated access, automatically revoked upon completion. Real-time session monitoring and recording \u2192 enables full visibility into privileged user actions, with live session control, playback, and forensic evidence for investigations.</li> <li>Command filtering and policy enforcement \u2192 prevents misuse of administrative access by blocking unauthorized commands and enforcing predefined policy rules during active sessions.</li> <li>Integration with Enterprise identity and security systems \u2192 seamlessly connects to IAM, SSO, SIEM, SOAR, and DevOps tools to ensure consistent access control and unified threat visibility.</li> <li>Behavioral analytics and anomaly detection \u2192 uses machine learning models to detect suspicious or abnormal privileged activity, triggering automated alerts and responses. Strong Authentication and Adaptive Security \u2192 implements MFA, context-based access control, and adaptive authentication to strengthen access security across all privileged sessions.</li> <li>Secure remote access gateway \u2192 provides agentless, credential-free remote access to internal systems through encrypted channels, reducing the risk of credential theft.</li> <li>Scalable cloud-native architecture \u2192 designed for elastic scaling to accommodate growth in users, systems, and sessions, ensuring consistent performance across large deployments.</li> <li>Continuous compliance and reporting \u2192 generates automated reports and dashboards that meet audit and compliance requirements, ensuring continuous adherence to security policies.</li> <li>Multi-tenant and delegated administration support \u2192 enables secure separation of administrative domains for different departments or customers, ideal for managed service providers or large organizations.</li> <li>Resilient and redundant infrastructure \u2192 built on a high-availability architecture with geographic redundancy, automatic failover, and disaster recovery capabilities. Extensive API and Automation Capabilities \u2192 exposes APIs for integration with orchestration and ITSM systems, enabling policy automation, credential management, and incident response workflows.</li> </ul> <p></p>"},{"location":"PaaS/#intrusion-prevention-system-ips-service","title":"Intrusion Prevention System (IPS) Service","text":"<p> Intrusion Prevention System (IPS) Service Overview </p>"},{"location":"PaaS/#service-description_5","title":"Service Description","text":"<p>Based on OPNsense, the Intrusion Prevention System (IPS) service actively intercepts network traffic for patterns of malicious or abnormal behavior and automatically and proactively blocks such malicious traffic. The Intrusion Prevention System (IPS) service not only detects but also prevents attacks in real time. It uses attack signatures and behavioral analysis to identify and block known and unknown threats, protecting the IT infrastructure from potential compromise. Unlike an IDS, an IPS is integrated into the network architecture, at least for mission-critical network flows.</p> <p>The service is offered with the following unit metric: 1 Gbps of Throughput.</p>"},{"location":"PaaS/#features-and-advantages_5","title":"Features and Advantages","text":"<p>The main features and functionalities of the service are:</p> <ul> <li>Traffic inspection and analysis \u2192 performs deep packet inspection (dpi) and protocol decoding for inbound, outbound, and east-west traffic. Applies signature-based rules (known attack patterns), anomaly/behavior analysis (baseline deviation), and policy enforcement. Supports real-time blocking of malicious connections and content.</li> <li>Signature and threat intelligence engine \u2192 maintains an updated signature library for known exploits and malicious traffic patterns. Integrates external threat intelligence feeds to identify malicious ips, domains, C2 channels, and exploit kits.</li> <li>Policy-driven prevention and inline blocking \u2192 automates blocking, connection termination, or traffic modification (e.g., reset, drop) when threats are detected. Policy profiles are configurable by severity, traffic zone, protocol, application, and asset criticality.ts.</li> <li>Zone and network segment enforcement \u2192 inspects traffic crossing defined security zones (e.g., lan \u2192 dmz, cloud \u2192 on-prem) and enforces segmentation rules.</li> <li>Logging, alerting, and reporting\u2192 generates detailed logs of detected intrusions, blocked events, and session information. Provides dashboards and reports for monitoring detection/prevention performance, compliance, and trends.</li> <li>Continuous update and threat intelligence sync \u2192 automatically delivers new signatures, behavioral models, and threat intelligence to all enforcement nodes to keep protection current.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Enforcement / data plane nodes \u2192 high-performance inline sensors (virtual or hardware) that inspect and enforce traffic rules, perform dpi, session tracking, and blocking. Deployed across zones (edge, cloud gateway, internal segment).</li> <li>Signature and threat intelligence repository \u2192 stores rule sets, malware and attack signatures, reputation data, ip/domain blacklists, and threat feed aggregations.Regularly updated and distributed to enforcement nodes.</li> <li>Policy engine and configuration repository \u2192 manages configuration of inspection zones, severity thresholds, blocking actions, traffic handling rules, and enforcement workflows.Maintains versioning, audit history, and rollback capabilities.</li> <li>Integration and api gateway \u2192 exposes restful apis and webhooks for integration with siem, soar, orchestration, and other security tools. Supports event export, automation triggers, and third-party tool connectivity.</li> <li>Logging, monitoring, and reporting subsystem \u2192 collects logs, alerts, session metadata, and traffic flows, storing them in a secure, indexed repository. Provides dashboards, forensic search, export capabilities, and report generation.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Proactive protection against cyber threats \u2192 prevents network intrusions and exploits in real time, reducing the risk of data breaches and business disruption.Continuously analyzes traffic to identify and stop attacks before they escalate.</li> <li>Reduced operational costs \u2192 eliminates the need for dedicated on-premises intrusion prevention appliances and complex management.Delivered as a cloud-based paas with predictable subscription costs and minimal maintenance overhead.</li> <li>Enhanced business continuity \u2192 blocks disruptive and malicious traffic automatically, ensuring uninterrupted operations.Minimizes downtime and revenue loss caused by security incidents.</li> <li>Improved regulatory and compliance posture \u2192 supports adherence to security standard frameworks  Provides continuous monitoring, detailed logs, and auditable reports for compliance verification.</li> <li>Centralized visibility and governance \u2192 provides unified control and visibility over network traffic across cloud, hybrid, and on-premises environments. Simplifies governance and policy enforcement from a single management interface.</li> <li>Scalability and flexibility \u2192 dynamically scales according to traffic load and business needs, adapting to cloud and hybrid deployments.Supports integration with existing soc and siem platforms for extended visibility.</li> <li>Reduced risk exposure and faster incident response \u2192 accelerates threat response through automated blocking and integration with orchestration tools. Shortens mean time to detect (mttd) and mean time to respond (mttr).</li> <li>Improved security posture through continuous updates \u2192 continuously updated with new signatures, threat intelligence, and behavioral models. Ensures up-to-date protection against emerging and zero-day attacks.</li> <li>Advanced detection and prevention capabilities \u2192 combines signature-based, heuristic, and anomaly-based detection techniques for comprehensive threat coverage. Uses deep packet inspection (dpi) for high-precision traffic analysis.</li> <li>Real-time inline prevention \u2192 automatically blocks malicious traffic inline without human intervention. Prevents exploits, denial-of-service attempts, and command-and-control communications in real time.</li> <li>Machine learning and behavioral analytics \u2192 employs machine learning models to identify unknown and evolving threats. Continuously refines detection accuracy through feedback and adaptive learning.</li> <li>Seamless integration with existing infrastructure \u2192 integrates easily with SIEM, SOAR, and SOC systems for centralized monitoring and automated response.Supports api-based integration for custom workflows and automation.</li> <li>High availability and redundancy \u2192 designed for continuous uptime through clustering, failover, and auto-scaling mechanisms. Ensures uninterrupted protection even during maintenance or component failure.</li> <li>Centralized management and policy control \u2192 allows administrators to define, deploy, and manage security policies across distributed environments from a single console. Enables consistent enforcement across multi-cloud and hybrid architectures.</li> <li>Encrypted traffic inspection \u2192 supports ssl/tls decryption and inspection for comprehensive visibility into encrypted traffic streams. Ensures full coverage against hidden or encrypted attacks.</li> <li>Automation and orchestration capabilities \u2192 supports automated remediation workflows for threat containment and isolation. Reduces human workload and response time through integration with orchestration tools.</li> </ul> <p></p>"},{"location":"PaaS/#paas-web-application-firewall-waf","title":"PaaS Web Application Firewall (WAF)","text":""},{"location":"PaaS/#service-description_6","title":"Service Description","text":"<p>The WAF is a fully managed web application firewall service designed to safeguard applications hosted within your environment on the cloud. It provides a protective layer between your public-facing services and the internet, ensuring that malicious traffic is intercepted before it can exploit vulnerabilities. The service is delivered as a turnkey solution, meaning that all necessary components, licenses, and updates are handled by the provider, allowing administrators to focus on their applications rather than the underlying security infrastructure. The WAF inspects HTTP and HTTPS traffic directed at web applications. It evaluates requests against defined rules to determine whether they are legitimate or potentially harmful. Administrators can adopt either a negative security model, which blocks traffic matching known exploit signatures, or a positive security model, which denies all traffic by default and only allows explicitly permitted requests. The firewall integrates protection against the most critical threats identified by the OWASP Top 10, including injection attacks, cross-site scripting, and insecure deserialization. </p>"},{"location":"PaaS/#features-and-advantages_6","title":"Features and Advantages","text":"<p>The WAF leverages OPNsense\u2019s NGINX plugin with NAXSI (Negative Application Security for nginx) to deliver its capabilities.NAXSI is a rule-based engine specifically designed to detect and block malicious web requests. </p> <p>Rule Types</p> <ul> <li>Main Rules: These are globally valid and designed to block common attack vectors such as SQL injection, XPath injection, or cross-site scripting attempts.  </li> <li>Basic Rules: These are used to fine-tune configurations, typically by whitelisting certain requests or creating additional rules for specific application contexts.  </li> <li>Custom Rule Sets: Administrators can define custom rules to tailor protection to their applications. For example, they may whitelist certain parameters for trusted applications while maintaining strict controls elsewhere.  </li> </ul> <p>Logging and Monitoring</p> <p>Logs are generated in near real time, providing visibility into blocked and allowed requests, and can be dispatched to the centralized log analytics service to analyze traffic patterns and identify potential threats. </p> <p>OWASP Guidance</p> <p>Configuration can be guided by OWASP cheat sheets, which provide best practices for securing web applications.  </p> <p>Provisioning the Service </p> <p>The WAF is provisioned through the Secure Cloud Management Platform, the central portal for managing cloud services. Administrators can deploy the firewall by selecting the WAF option within the platform. Provisioning can also be performed via APIs, enabling integration into automated workflows. Once deployed, the firewall is automatically patched and maintained by Leonardo, ensuring that the system remains up to date with the latest security fixes.</p> <p>Configuration and Management </p> <p>Configuration is performed through the Secure Cloud Management Platform.  Administrators can: - Define rule sets for both negative and positive security models. - Apply NAXSI main and basic rules to protect against common exploits. - Customize rules to allow specific traffic patterns while blocking suspicious requests. - Monitor logs to gain insight into traffic directed at their applications.  </p>"},{"location":"PaaS/#middleware-family","title":"Middleware Family","text":"<p>Below is the list of services belonging to the Middleware family:</p> <ul> <li>PaaS API Management</li> <li>Functions as a Service (FAAS)</li> <li>Jboss as a Service</li> <li>Spring boot as a Service</li> <li>PaaS Business Process as a Service</li> <li>PaaS CMS as a Service</li> <li>Semantic Knowledge Search</li> </ul> <p></p>"},{"location":"PaaS/#paas-api-management","title":"PaaS API Management","text":"<p> PaaS API Management </p>"},{"location":"PaaS/#service-description_7","title":"Service Description","text":"<p>Based on Kong solution, it is a platform of tools and services that facilitates the management, control, monitoring, and protection of APIs (Application Programming Interfaces) without having to manually implement all the components.  The service typically offers:</p> <ul> <li>API gateways to route and secure traffic;</li> <li>Authentication and authorization: Rate limiting and throttling to control consumption;</li> <li>Logging and observability: Integration with security and DevOps systems.</li> </ul> <p>The API manager facilitates API lifecycle management, including aspects such as creation, version management, deprecation, and retirement, to ensure backward compatibility, allowing developers to gradually migrate to new versions without disrupting existing applications. The API manager allows you to define and enforce policies, such as usage limits, quota management, custom authentication, data transformations, and caching. These policies allow you to control API behavior and ensure compliance with security requirements and guidelines. The API Manager can integrate with other systems and tools, such as identity and access management (IAM) systems, performance monitoring systems, data analytics systems, and security gateways. This integration expands the API Manager's functionality and integrates it into the ecosystem of existing applications and services.</p> <p>The service is offered for a unit size of 500 M of API requests.</p>"},{"location":"PaaS/#features-and-advantages_7","title":"Features and Advantages","text":"<p>The main features and functionalities of the service are:</p> <ul> <li>API Publishing \u2192 the API Manager offers tools for publishing APIs, allowing developers or authorized users to access them. For optimal use, clear and comprehensive documentation is provided describing how to use the APIs, which endpoints are available, which parameters are requested, and how to interpret the responses.</li> <li>Access Control \u2192 the API Manager manages the authentication and authorization of users who wish to use the APIs. This allows you to control who can access the APIs and with what permission levels. The API Manager can adopt authentication mechanisms such as access tokens, API keys, or digital certificates to ensure API security.</li> <li>Monitoring and Analytics \u2192 the API Manager offers tools for monitoring API performance, such as the number of requests, response times, and errors. This information allows developers and administrators to monitor API usage, identify any performance issues, and take corrective action.</li> </ul> <p>The architecture, based on Kong technology, is divided into several key components that interact to provide comprehensive functionality to users:</p> <ul> <li>Front-end \u2192 administration clients and graphical interfaces (Admin GUI, Dev Portal) accessible via browser or dedicated applications, which allow users to configure services, manage users, and monitor metrics in real time.</li> <li>Back-end Kong Control Plane \u2192 manages configurations, policies, plugins, and API orchestration.</li> <li>Back-end Data Plane \u2192 routes user requests to back-end services, applying security rules, transformations, caching, and rate limiting. - Database \u2192 stores configurations, users, roles, statistics, and logs. Supports replication and high availability capabilities to ensure resilience and business continuity</li> <li>Integrations \u2192 supports integrations with development tools, CI/CD, monitoring systems, and project management platforms, allowing Kong to be incorporated into existing enterprise workflows.</li> <li>Security and Authentication \u2192 offers advanced security options, including multi-factor authentication, support for enterprise protocols (OIDC, SAML, LDAP), and granular access control, ensuring data protection and compliance with corporate standards.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced time to market \u2192 APIs can be published and managed quickly without building the infrastructure from scratch.</li> <li>Flexibility and scalability \u2192 the platform grows with business needs, supporting traffic spikes or new integrations without disruption.</li> <li>Reduced operating costs \u2192 no hardware or maintenance investments: infrastructure management is delegated to the PaaS provider.</li> <li>API monetization \u2192 ability to create API-driven business models (e.g., exposing APIs to partners or customers with pricing plans).</li> <li>Enhanced security and compliance \u2192 secure management of APIs and traffic between services, with authentication, authorization, and rate limiting policies, protecting the infrastructure from unauthorized access.</li> <li>Open ecosystem \u2192 Facilitates partnerships and innovation thanks to an API-ready and standardized infrastructure.</li> </ul> <p></p>"},{"location":"PaaS/#functions-as-a-service-faas","title":"Functions as a Service (FAAS)","text":"<p> Functions As a Service (FAAS) Interface </p>"},{"location":"PaaS/#service-description_8","title":"Service Description","text":"<p>FaaS (Function as a Service) is an event-driven system design model running on stateless containers, where developers create, deploy, and execute small, independent functions to perform specific tasks without worrying about the underlying infrastructure. Adopting FaaS allows for standardization of application development and execution by centralizing cross-functional capabilities such as orchestration, automatic provisioning, monitoring, integrated service management, and event-driven flow control. </p> <p>It offers tools to:</p> <ul> <li>centrally manage serverless functions;</li> <li>automate component lifecycle management.</li> </ul> <p>The FaaS platform provisions and scales the underlying resources based on demand. It is ideal for highly dynamic scenarios with variable workloads and integrates seamlessly with microservices and event-based architectures.</p> <p>The service is offered with the following metrics: 100 VCPUs.</p>"},{"location":"PaaS/#features-and-advantages_8","title":"Features and Advantages","text":"<p>The service goes beyond simply providing an execution engine; it also offers a complete ecosystem, consisting of:</p> <ul> <li>Serverless execution \u2192 stateless functions and event-driven workflows, scalable and available in various programming languages.</li> <li>Portability and independence \u2192 can run on any Kubernetes cluster, across multiple environments, without lock-in constraints.</li> <li>Security and compliance \u2192 data protection and centralized access management.</li> <li>The solution enables organizations to adopt a modern and flexible model, reducing operational complexity and benefiting from a standardized and easily accessible service.</li> </ul> <p>The service is delivered through Apache OpenServerless, an open-source, cloud-agnostic serverless platform based on Apache OpenWhisk as a Function-as-a-Service (FaaS) engine.</p> <p>The service offers the following advantages:</p> <ul> <li>Reduced operating costs \u2192 you only pay for the actual use of features.</li> <li>Flexibility and scalability \u2192 resources adapt to demand.</li> <li>Operational efficiency \u2192 eliminating the need to directly manage servers, patches, and updates.</li> <li>High availability \u2192 built-in redundancy and fault tolerance, ensuring high availability of features even in the event of hardware failures or other interruptions.</li> <li>Accelerated time-to-market \u2192 rapid release of new features without worrying about the infrastructure.</li> <li>Agile development \u2192 focus on code and business logic, not server management.</li> <li>Continuous innovation \u2192 rapid experimentation with new, low-cost services. Competitive advantage in cost and speed compared to traditional hosting models.</li> </ul> <p></p>"},{"location":"PaaS/#jboss-as-a-service","title":"Jboss as a Service","text":""},{"location":"PaaS/#service-description_9","title":"Service Description","text":"<p>The service is based on an open source platform for running and managing Enterprise Java applications, designed to offer reliability, scalability, and flexibility in modern environments.  It allows to run Java EE/Jakarta EE applications and microservices, providing a robust environment for business logic, data persistence, and transaction management. It allows to manage the application lifecycle, including deployment, updates, rollbacks, and centralized configuration, ensuring secure and repeatable processes. Thanks to its modular architecture, compatibility with cloud environments, and rich integration with automation and security tools, it represents a strategic solution for companies seeking efficiency, innovation, and operational control.</p> <p>The service is sized per container. Each one consists of:</p> <ul> <li>4 VCPUs</li> <li>8 GB of RAM</li> </ul>"},{"location":"PaaS/#features-and-advantages_9","title":"Features and Advantages","text":"<p>JBoss offers a robust, high-performance, and secure environment for developing and managing enterprise applications, providing a stable foundation for the growth and evolution of enterprise systems. The main features and functionalities of the service are:</p> <ul> <li>Security and Compliance \u2192 manages security, authentication, authorization, and data protection.</li> <li>Web Services \u2192 JAX-RS, JAX-WS, creation and management of RESTful and SOAP APIs for service integration.</li> <li>Microservices Management \u2192 MicroProfile, a set of specifications optimized for developing microservices-based applications. Includes features such as configuration, resiliency, monitoring, and metrics.</li> </ul> <p>The architectural components of the service are as follows:</p> <ul> <li>Front-end \u2192 administration interfaces (Web Console, CLI) accessible via browser or terminal, which allow administrators to manage configurations, deployment, resources, and monitoring.</li> <li>ack-end \u2192 the server core manages application execution, request processing, resource management (datasources, JMS queues, batch, etc.), and integration with external systems via resource adapters and connectors.</li> <li>Database \u2192 integrates with relational and NoSQL databases via configurable datasources, used by applications for data persistence.</li> <li>Security and Authentication \u2192 offers an advanced security subsystem for authentication, authorization, encryption, and auditing. It supports authentication via LDAP, Kerberos, SSO, and integration with external identity providers, ensuring secure access that complies with corporate standards.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced time to market \u2192 application lifecycle automation, centralized management, and easy integration with DevOps pipelines reduce development and release times, accelerating response to market needs.</li> <li>Reduced operating costs \u2192 centralized resource management and the platform's modularity optimize the use of existing infrastructure, reducing waste and operating costs.</li> </ul> <p></p>"},{"location":"PaaS/#spring-boot-as-a-service","title":"Spring boot as a Service","text":"<p> Spring boot as a Service </p>"},{"location":"PaaS/#service-description_10","title":"Service Description","text":"<p>This service allows you to use Spring Boot, an open-source framework for Java application development, as a managed service. It is designed to simplify the development of production-ready Java applications by providing a platform that eliminates much of the manual configuration required by the traditional Spring framework and reduces the need for server provisioning and dependency management. With a preconfigured environment optimized for the Spring Boot framework, the service allows teams to focus on developing business features, reducing release times and costs.</p> <p>The service is sized for single containers. Each container has 16 GB of RAM.</p>"},{"location":"PaaS/#features-and-advantages_10","title":"Features and Advantages","text":"<p>The main features and functionalities of the service are:</p> <ul> <li>Automatic environment provisioning \u2192 automatic configuration of Java runtime (JDK), integrated application server, and Spring Boot framework. No need to manually configure build environments or containers. Simplified deployment \u2192 ability to directly upload a JAR or source code (e.g., via Git, API, or CI/CD pipeline).</li> <li>Scalability \u2192 horizontal (replication) and vertical (CPU/RAM resources) scaling managed by the PaaS based on load.</li> <li>Integrated monitoring and logging \u2192 access to runtime metrics (CPU, memory, latency, throughput); centralized logs (stdout/stderr) accessible via console or API; integration with BI tools (Prometheus, Grafana, etc.).</li> <li>Configuration and secret management \u2192 centralized configuration (environment variables, Spring Cloud Config, or Vault); secure management of credentials, tokens, and keys. Integrated support services \u2192 easy connection to managed databases (PostgreSQL, MySQL, MongoDB); support for messaging (RabbitMQ, Kafka), caching (Redis), and storage; automatic service binding via environment variables or injection.</li> <li>Security and isolation \u2192 each application is isolated (namespace, container, or dedicated VM); HTTPS/TLS by default, identity management, and integration with authentication systems (OAuth2, SSO).</li> </ul> <p>The solution is based on the following architectural layers:</p> <ul> <li>Infrastructure layer \u2192 provides the hardware and virtual resources needed to run application containers (Compute nodes, Storage, Networking, Security layer); automatic provisioning via IaC (Infrastructure as Code).</li> <li>Orchestration layer (Platform Runtime) \u2192 manages the lifecycle of Spring Boot containers, from deployment to monitoring, ensuring availability, replication, and load balancing</li> <li>Application layer (Spring Boot Runtime) \u2192 Spring Boot runs within a container; supports Actuator endpoints for health checks and metrics; exposes HTTP/REST APIs on predefined and configurable ports</li> <li>Management layer and PaaS services \u2192 web dashboard or CLI to manage applications, versions, and resources. REST API for automation (deployment, scale, logs, metrics). Integration with external logging and monitoring systems.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced time to market \u2192 Deployment automation and simplified environment management allow applications to be brought into production more quickly.</li> <li>Reduced operating costs \u2192 No hardware or maintenance investments: infrastructure management is handled for the customer.</li> <li>Observability and monitoring \u2192 Preconfigured tools to track performance, errors, and response times.</li> <li>Guaranteed security \u2192 Automatic patch and update management.</li> <li>Environment consistency \u2192 Same environments for development, testing, and production.</li> <li>Microservices support \u2192 Simplified management of distributed architectures.</li> </ul> <p></p>"},{"location":"PaaS/#business-process-as-a-service","title":"Business Process as a Service","text":"<p> Business Process as a Service </p>"},{"location":"PaaS/#service-description_11","title":"Service Description","text":"<p>Based on Kogito solution, it is a comprehensive Business Process Management (BPM) platform that helps companies model and automate complex processes, improve productivity and service quality, and ensure control, traceability, and flexibility in an integrated and scalable environment. It combines workflow automation, application integration, and performance monitoring in a single solution. The goal is to improve operational efficiency, reduce execution times, and ensure process consistency across the organization. It facilitates collaboration between business users and IT during the creation, management, validation, and deployment of customized process and decision automation solutions. Business users can modify business logic and business processes without requiring assistance from IT staff.</p> <p>The service is sized for istance. Each one consists of:</p> <ul> <li>8 VCPUs</li> <li>16 GB of RAM</li> </ul>"},{"location":"PaaS/#features-and-advantages_11","title":"Features and Advantages","text":"<p>The main features and functionalities of the service are:</p> <ul> <li>Process Modeling &amp; Simulation \u2192 allows business analysts and developers to collaborate on process definition using a standard language (BPMN 2.0) with drag-and-drop tools.</li> <li>Process Automation &amp; Orchestration \u2192 allows for the automation of repetitive tasks and decision rules.</li> <li>Human Workflow Management \u2192 automatic assignment of tasks based on roles, priorities, and workloads. Intuitive user portal for completing, delegating, or commenting on tasks.</li> <li>Monitoring, Reporting &amp; Optimization \u2192 real-time dashboard for performance analysis based on KPIs and SLAs, reporting, optimization recommendations through predictive analytics, and historical data.</li> <li>Security &amp; Governance \u2192 integrated authentication with LDAP/Active Directory. Granular roles for users and groups (process owner, approver, admin). Complete audit trail for compliance and traceability. Version control and approvals prior to deployment.</li> <li>Cloud &amp; DevOps Integration \u2192 offered as a managed cloud service. Integration with CI/CD pipelines and DevOps tools.</li> </ul> <p>The service, based on IBM technology, is organized into the following integrated modules that cover the entire process lifecycle\u2014from modeling to performance measurement.</p> <ul> <li>Process Designer \u2192 Visual process modeling tool.</li> <li>Process Center \u2192 Centralized repository and collaborative environment, allows you to manage multiple versions of processes, reuse common components, and collaborate across multiple teams.</li> <li>Process Server \u2192 Process execution engine. Manages both human and automated tasks.</li> <li>Process Portal \u2192 User portal for receiving, executing, or approving tasks.</li> <li>Performance Data Warehouse (PDW) \u2192 Performance collection and analysis system, stores process execution data and enables historical analysis and real-time monitoring.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li> <ul> <li>Operational efficiency and cost reduction* \u2192 automation and reduction of manual and repetitive tasks, resulting in reduced personnel costs, errors, and inefficiencies.</li> </ul> </li> <li>Transparency and control \u2192 end-to-end visibility. Each process is tracked in real time. Increases accountability and control.</li> <li>Quality and standardization \u2192 consistent and compliant processes. Ensures processes are always executed consistently, reducing deviations and variability.</li> <li>Compliance and auditability \u2192 complete traceability for audits and regulatory compliance. Every step and decision is documented, facilitating internal controls and regulatory compliance</li> <li>Monitoring and observability \u2192 integrated dashboards and analytics.</li> </ul> <p></p>"},{"location":"PaaS/#content-management-systems-cms-as-a-service","title":"Content Management Systems (CMS) as a Service","text":"<p> Content Management Systems (CMS) as a Service </p>"},{"location":"PaaS/#service-description_12","title":"Service Description","text":"<p>The service, based on Wordpress, provides comprehensive and versatile tools for creating and managing websites and blogs based on CMS (Content Management System) solutions, which are cloud-based Content Management Systems (CMS) delivered as a service, without having to install or maintain software on your own server. It offers a centralized system that allows for scalable, integrable, and multi-channel content management, with consumption-based costs and no infrastructure overhead. This allows users to focus solely on content creation and management, while the platform handles hosting, maintenance, and updates.</p> <p>The service is offered every 1000 users for unit.</p>"},{"location":"PaaS/#features-and-advantages_12","title":"Features and Advantages","text":"<p>The main features and functionalities of the service are:</p> <ul> <li>Website creation \u2192 content publishing.</li> <li>Content management (CMS) \u2192 ability to create, edit, and delete content.</li> <li>Intuitive user interface \u2192 easy content access.</li> <li>Customization via themes and plugins \u2192 layout management and use of plugins for customization</li> <li>SEO-friendly \u2192 search engine visibility.</li> <li>Flexibility and scalability \u2192 adaptability based on needs.</li> <li>Open Source and Community \u2192 collaboration with the online community.</li> <li>Accessibility \u2192 tools to improve readability, contrast, keyboard navigation, and compliance with accessibility standards for users with disabilities.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Accelerated time to market \u2192 rapid launch of websites and apps.</li> <li>Reduced operating costs \u2192 no servers or internal maintenance. High availability and resilience.</li> <li>Support for omnichannel strategies (web, mobile, e-commerce, IoT).</li> <li>Ability to operate in multiple markets with multilingual websites.</li> <li>Simplified collaboration for distributed teams.</li> <li>Continuous innovation at no additional cost \u2192 new features released by the provider.</li> <li>Native integration with cloud services (CRM, analytics, AI, CDN).</li> <li>Front-end/back-end separation \u2192 freedom to use modern frameworks (React, Vue, Angular, etc.).</li> </ul> <p></p>"},{"location":"PaaS/#semantic-knowledge-search","title":"Semantic Knowledge Search","text":"<p> Semantic Knowledge Search Service </p>"},{"location":"PaaS/#service-description_13","title":"Service Description","text":"<p>This service, developed by Leonardo, provides a ready-to-use platform that makes information contained within the information assets easily accessible, using a semantic search engine capable of interpreting natural language queries in different languages. It considers the search context, word variations, and synonyms to find relevant results from a semantic database for a given domain based on a user's natural language query. The service allows for the management of content in various formats (Word documents, PDFs, PowerPoint presentations, emails, images, etc.) through an upload service capable of inferring and processing the document type. The tool is able to filter and select the most relevant information for the user through the use of an NLP (Natural Language Processing) model, also allowing complete navigation of the indexed document. The services are designed to ensure digital sovereignty through deployment on a secure national infrastructure, with a particular focus on latency and optimization of computational resources. It allows users to enter feedback on individual results returned by the search engine, in order to take into account domain knowledge to better refine the results provided by the system.</p> <p>The service is sized per container unit. Each container consists of:</p> <ul> <li>8 VCPUs</li> <li>16 GB of RAM</li> </ul>"},{"location":"PaaS/#features-and-advantages_13","title":"Features and Advantages","text":"<p>The platform bases its semantic search methodology on a database of carefully selected internal information sources, as well as on feedback from system users. This way, the results produced will prove significantly more effective, as the output of an IT tool will be combined with the assessments of domain experts. The platform will allow users to:</p> <ul> <li>Submit natural language queries in different languages.</li> <li>Reduce information search times, which will no longer be based on manual consultation of documentation, but will instead benefit from the efficiency of AI</li> <li>Optimize the tool and share the experiences of individual operators through the feedback system.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Client App \u2192 user-friendly frontend through which users can interact to submit questions in different languages, find documents relevant to the question, narrow the search field through relevant metadata, submit feedback, and index their documents by uploading one or more files.</li> <li>FastAPI Framework \u2192 modern, fast (high-performance) web framework for creating APIs with Python, based on the OpenAPI and JSON Schema standards.</li> <li>Bidirectional Encoder Representations from Transformers \u2192 pre-trained deep learning models that provide a foundation upon which to build custom versions to address a wide range of tasks. Examples include sentiment analysis, named entity recognition, text engagement (i.e., next sentence prediction), semantic role labeling, text classification, and coreference resolution.</li> <li>Apache Tika \u2192 Software for data extraction, language identification, and content analysis. It can find and extract text and metadata from over a thousand file formats.</li> <li>OpenSearch \u2192 A distributed search engine that provides extremely fast full-text search capabilities and high-performance indexing of all data types. Interaction with the search engine occurs via REST API technology.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Faster and more informed decisions \u2192 teams have easier access to corporate knowledge, reducing analysis and decision-making time.</li> <li>Better use of information assets \u2192 implicit or distributed knowledge within corporate silos (documents, emails, databases, CRM, etc.) is made searchable and semantically linked, reducing the loss of know-how or information dispersion.</li> <li>Reduced operating costs \u2192 PaaS eliminates the need to manage proprietary infrastructure for indexing, NLP, and data linking.</li> <li>Innovation and competitive advantage \u2192 differentiate products and services with a more intelligent user experience.</li> <li>Accelerated time to market \u2192 PaaS services are ready to use and easily integrated via API, allowing for the rapid development of new knowledge-driven applications.</li> <li>Simplified scalability and management \u2192 manage provisioning, updates, load balancing, and fault tolerance.</li> <li>Access to advanced AI/NLP technologies \u2192 semantic engines based on embeddings, ontologies, graph search, and machine learning without having to implement them internally. - Continuous updates with the latest developments.</li> <li>Multi-source integration \u2192 Semantic Knowledge Search PaaS allows you to connect structured and unstructured data from multiple sources and supports standard connectors (REST API).</li> <li>Managed security and compliance \u2192 authentication, authorization, and encryption are integrated into the service.</li> </ul>"},{"location":"PaaS/#data-protection-family","title":"Data Protection Family","text":"<p>Below is the list of services belonging to Data Protection family:</p> <ul> <li>Backup Platform</li> </ul> <p></p>"},{"location":"PaaS/#backup-platform-service","title":"Backup Platform Service","text":"<p> Backup Service </p>"},{"location":"PaaS/#service-description_14","title":"Service Description","text":"<p>The PaaS Backup (Veeam-based solution) is a fully managed platform service that provides automated, secure, and reliable data protection for virtual machines, cloud workloads, and application data. The service ensures consistent backups, rapid restores, and long-term retention without requiring customers to deploy or maintain backup servers, storage repositories, or complex scheduling policies. The solution is designed for enterprise-grade data protection, offering backup automation, disaster recovery enablement, policy-based lifecycle management, and secure multi-tenant separation within cloud environments.</p> <p>The service is offered for single TB sizing.</p>"},{"location":"PaaS/#features-and-advantages_14","title":"Features and Advantages","text":"<p>The service offers the following key features:</p> <ul> <li>Automated VM and cloud resource backup \u2192 Protects: virtual machines, cloud instances, application data, OS and configuration states. Supports image-level and incremental backups for optimal efficiency.</li> <li>Policy-based backup management \u2192 Create backup policies defining: scheduling, retention periods, backup types (full, incremental, differential), storage tiers. Ensures consistent and compliant protection across environments.</li> <li>Application-consistent backups \u2192 supports VSS-based and application-aware backups for: databases (SQL, Oracle, etc.), Active Directory, file systems, transactional workloads. Guarantees recoverability and data integrity.</li> <li>Multiple restore options \u2192 Full VM restore, instant recovery to cloud infrastructure, file-level recovery, application or database item-level restore, cross-region or cross-environment recovery</li> <li>Backup storage flexibility \u2192 uses managed backup repositories within the cloud. Tiers include: performance storage (for fast restore), capacity storage (for long-term retention), archival storage (optional)</li> <li>Immutable and secure backups \u2192 optional immutability features for ransomware protection. Write-once, read-many (WORM) retention policies. Encrypted transport and encrypted-at-rest repositories.</li> <li>Monitoring and reporting \u2192 dashboards for job success, failures, and SLA compliance. Alerts for - Disaster recovery integration \u2192 supports replication features for DR strategy. Enables fast failover to cloud environments. Provides restore testing and verification tools.</li> <li>Zero infrastructure management \u2192 No need to deploy backup servers or agents manually. Provider handles: scaling, patching, repository management, backup infrastructure health.</li> </ul> <p>The main components of the service are:</p> <p>Backup management cluster \u2192 centralized system orchestrating all backup operations. Handles scheduling, job execution, and policy enforcement. Highly available and fully managed by the provider. - Backup proxies and data movers \u2192 distributed components that handle data transfer. Optimize performance by offloading backup/restore workloads. Integrated with cloud virtualization platforms. - Backup repository layer \u2192 Multi-tier repository infrastructure for: short-term storage, long-term retention, immutable storage. Redundant and scalable for large data volumes. - Control plane \u2192  Manages: backup policies, job configurations, user permissions and multi-tenancy, SLA definitions, reporting and analytics, API-driven automation.\u00e0 - Data plane \u2192 responsible for: VM snapshot creation, data extraction and compression, transport - Security &amp; compliance layer \u2192 encryption in transit and at rest. Tenant isolation at storage and management layers. Compliance with data protection standards (GDPR, ISO, etc.). - Observability &amp; alerting layer \u2192 real-time monitoring of backup/restore jobs. Alerts on job failures, capacity issues, and SLA violations. Audit logs for operations and access tracking.</p> <p>The service offers the following advantages:</p> <ul> <li>Reliable and consistent data protection \u2192 ensures all virtual machines and data are continuously protected. Reduces risk of data loss and improves operational resilience. </li> <li>Simplified backup management \u2192 fully managed service eliminates infrastructure complexity Policy-based automation ensures compliance and consistency.</li> <li>Fast and flexible recovery \u2192 instant VM recovery dramatically reduces downtime. Granular restore options improve operational efficiency.</li> <li>Ransomware resistance \u2192 immutable backups prevent malicious modification or deletion. Secure repository design strengthens recovery posture.</li> <li>Cost efficiency \u2192 no need to purchase backup servers, licenses, or storage hardware.</li> <li>High scalability \u2192 handles growing workloads and storage needs. Suitable for expanding cloud environments and hybrid infrastructures.</li> <li>Improved compliance and governance \u2192 detailed reporting supports audits, SLA measurement, and regulatory compliance. Centralized retention policies ensure consistent data handling.</li> <li>Unified protection across hybrid environments \u2192 protects both cloud and on-prem workloads (if extended). Supports modernization and migration scenarios.</li> <li>Reduced operational overhead \u2192 provider manages infrastructure, maintenance, patching, and upgrades. IT teams focus on core applications instead of backup operations.</li> <li>Business continuity enablement \u2192 integrates with replication and DR features. Supports failover during incidents or migrations.</li> </ul>"},{"location":"PaaS/#infra-ops-platform-family","title":"Infra &amp; Ops Platform Family","text":"<p>Below is the list of services belonging to the Infra &amp; Ops Platform family:</p> <ul> <li>Multicloud Management Platform</li> <li>IT infrastructure Service Operations (Logging &amp; Monitoring)</li> <li>PaaS Ticket Management Service</li> <li>PaaS Operations Management Service</li> </ul> <p></p>"},{"location":"PaaS/#multicloud-management-platform","title":"Multicloud Management Platform","text":"<p> Leonardo Secure Cloud Management Platform (SCMP)  - Inventory interface </p> <p> Leonardo Secure Cloud Management Platform (SCMP) - Costs dashboard </p>"},{"location":"PaaS/#service-description_15","title":"Service Description","text":"<p>Secure Cloud Management Platform (SCMP) is a Multicloud management software platform, designed by Leonardo, for governance, lifecycle management, brokering, and resource automation in hybrid and multi-cloud environments. It offers a self-service portal with a unified service catalog, governance, and customizable dashboards and reports to monitor infrastructure performance and costs. The platform allows to orchestrate, monitor, and control usage, costs, and workflow performance in complex or hybrid multi-cloud environments. It integrates seamlessly with leading Enterprise Cloud Service Providers, On-premise resource virtualization and edge computing systems. It can also manage self-service provisioning of resources: e.g., virtual machines (VMs), storages, clusters, containers, services, complex applications (such as blueprints), or entire application stacks (IaaS, PaaS, CaaS).  </p> <p>The service is sized and offered based on volumes:</p> <ul> <li>less than \u20ac1.000.000,00 in annual managed resource expenditure for Cloud resources. </li> <li>every 5 TB of managed RAM for on-premise or hybrid resources.</li> </ul>"},{"location":"PaaS/#features-and-advantages_15","title":"Features and Advantages","text":"<p>The service offers the following key features:</p> <ul> <li>High compatibility and integration \u2192 integration with major CSPs (AWS, Azure, GCP, Oracle, etc.), virtualization and on premise vendors and systems (VMware, OpenStack, HPE, Nutanix, Hyper-V, bare metal, PXE provisioning), and container orchestration systems (Kubernetes). Integration with third-party systems (e.g., ERP) to offer process automation.</li> <li>High level of granularity and customization \u2192 the platform offers various graphical views for monitoring and reporting, to meet the needs of each user and team. You can choose whether to have aggregate views and reports by system/subsystem, or by element type or individual element.</li> <li>Performance and cost monitoring \u2192 through integrated, unified, and intuitive dashboards, users can monitor the current and forecasted status of systems, subsystems, and related resources in terms of resource usage and generated costs. Views can be presented in graphical form with custom tables or graphs, or through the creation of reports, which can be exported in various formats or sent to users periodically. The platform manages the monitoring of aggregate and/or resource/team/cloud costs and enables predictive cost analysis (what-if analysis) to identify waste, comply with recommendations (e.g., resizing, rightsizing), implement budget guardrails, etc.</li> <li>Self-Service Catalog and Item Provisioning \u2192 authorized users can create and manage their own catalog to orchestrate and manage the various elements within it. For example, an authorized user can deploy new infrastructure resources (e.g., VMs, storage resources, network resources, etc.) to the desired CSPs, launch or modify standard or custom services, pre-configured environments, and blueprints (both proprietary and IaC).</li> <li>Multicloud security monitoring \u2192 thanks to compatibility with existing security systems and appliances (e.g., SIEM, Key Vaults, Remote attestation for confidential computing, etc.), you can centrally manage your organization's security posture, detecting any vulnerabilities, discrepancies, or non-compliance on the systems or resources monitored by the platform.</li> <li>Data and User Security Management \u2192 the platform does not process customer data, but only the use of CSP services and/or resources. Identity and access management (IAM) mechanisms are foreseen with the implementation of MFA and RBAC authentication logics, compliant with the principle of least privilege, to regulate access to IT resources and related information based on roles, responsibilities and authorization levels.</li> </ul> <p>The main components are:</p> <ul> <li>Abstraction Layer (ABS) \u2192 lowest platform layer that executes operational workflows towards integrated CSPs.</li> <li>Resource Layer/Manager (RM) \u2192 highest platform layer responsible for executing user requests. It is composed of the following modules:<ul> <li>Costs: module responsible for managing and displaying resource costs.</li> <li>Security: module responsible for managing and displaying security policies and resource compliance status.</li> <li>Monitoring: module responsible for managing and displaying resource usage metrics.</li> <li>Inventory and Catalog: modules responsible for managing and displaying all allocated and available resources.</li> <li>Provisioning: module responsible for the automation and provisioning logic of resources and other services. Tenant: Module responsible for multi-tenant service management and external operational requests</li> </ul> </li> <li>Persistence Layer \u2192 NoSQL database (MongoDB) used by the RM to store normalized data retrieved from the respective ABS submodules.</li> <li>Integration and Communication Layer \u2192 facilitates and orchestrates asynchronous information communication between the ABS and RM modules of the system; allows the ABS submodules to interact with the various APIs of the respective CSPs and external systems</li> <li>Security and Authentication Layer \u2192 access management and encryption of sensitive data from provider systems.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Simplify the management of heterogeneous and complex IT infrastructures \u2192 centralizes resource management across multiple clouds or hybrid infrastructures, simplifying visibility, management, and control of distributed resources.</li> <li>Scalability and flexibility \u2192 identifies the most suitable IT services and resources at the time, continuously adapting to business needs.</li> <li>Cloud expense optimization \u2192 enables constant monitoring and optimization of current and forecasted IT infrastructure expenses.</li> <li>Agility and speed \u2192 on-demand resource allocation and automation of daily operations (e.g., resource management, configuration, scaling) reduces provisioning times and the workload for IT groups.</li> <li>Faster and more informed decisions \u2192 guides IT development strategy with a data-driven approach.</li> <li>Reduced time to market \u2192 reduces the time required to develop and deploy new applications, improving time to market and accelerating response to market needs.</li> <li>Improves the reliability of services and processes \u2192 governance, security, and compliance policies can be centrally managed, ensuring that Resources are protected and regulations are complied with.</li> <li>IT Operations Support \u2192 can be integrated with IT service management (ITSM) and IT operations automation tools (such as Ansible, Chef, SaltStack), improving service quality and reducing manual errors.</li> </ul> <p></p>"},{"location":"PaaS/#it-infrastructure-service-operations-logging-monitoring","title":"IT infrastructure Service Operations (Logging &amp; Monitoring)","text":"<p> IT infrastructure Service Operations (Logging &amp; Monitoring) interface </p>"},{"location":"PaaS/#service-description_16","title":"Service Description","text":"<p>Developed by Leonardo, this is an Application Performance Monitoring (APM) service that monitors and controls infrastructure performance supporting applications (e.g., latency, errors, service availability) and workloads deployed in the Cloud environment. It provides centralized collection and analysis across various infrastructure elements: Servers and VMs, Containers and orchestrators, Cloud providers, and Network.  </p> <p>The service is offered per 1 GB of data storage.</p>"},{"location":"PaaS/#features-and-advantages_16","title":"Features and Advantages","text":"<p>The Log &amp; Audit service built on OpenTelemetry provides a unified and vendor-neutral way to collect, process, and export observability data. Its core capabilities include:</p> <p>The service offers the following main features:</p> <ul> <li>Log collection &amp; aggregation \u2192 vaptures application logs, system logs, and security-relevant audit trails. Supports structured logging for consistent and machine-readable data.</li> <li>Audit trail generation \u2192 tracks user actions, configuration changes, and security-sensitive operations. Ensures immutability and integrity through standardized data formats and export pipelines.</li> <li>Distributed tracing \u2192 enables end-to-end traceability across microservices. Helps correlate logs, metrics, and traces for full-context auditability.</li> <li>Metrics and performance data \u2192 collects operational and performance metrics (CPU, memory, network, API latency). Correlates metrics with logs and traces for accurate diagnostics.</li> <li>Policy-driven data processing \u2192 allows filtering, sampling, redaction, and enrichment through OpenTelemetry Collectors. Ensures sensitive information is processed according to compliance policies.</li> <li>Multi-destination export \u2192 exports data to SIEM platforms, log analytics tools, data lakes, or object storage. Supports Elasticsearch, Splunk, Loki, BigQuery, and more.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Instrumentation Layer \u2192 applications and services instrumented using OpenTelemetry SDKs and auto-instrumentation agents. Generates logs, metrics, and traces in a standardized OTLP format.</li> <li>OpenTelemetry collector \u2192 central component responsible for: receiving data (logs, metrics, traces); processing/enriching it; exporting it to one or more backends. Can run as: a sidecar in Kubernetes, a daemonset on each node, a centralized collector cluster.</li> <li>Export &amp; storage layer \u2192 observability and security data coud be sent to: log storage (Elasticsearch, Loki, Cloud logging platforms); SIEM systems (Elastic SIEM, Splunk, Azure Sentinel); Audit archives (S3, GCS, object storage).</li> <li>Visualization &amp; analytics \u2192 dashboards and visual tools (Grafana). </li> <li>Support centralized log analysis, auditing, forensics, and compliance reporting.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Improved security &amp; compliance \u2192 centralized audit trails simplify compliance with standards (ISO 27001, SOC2, GDPR). Enhanced visibility into user actions and critical events reduces risk.</li> <li>Reduced vendors Lock-in \u2192 OpenTelemetry is vendor-neutral, enabling freedom to switch backends without re-instrumenting code.</li> <li>Better decision-making \u2192 unified observability data supports data-driven product and business insights. Helps organizations identify usage patterns, performance bottlenecks, and customer-impacting issues.</li> <li>Cost optimization \u2192 policy-driven sampling and data routing help reduce storage and licensing costs. Ability to send different data types to cost-efficient storage tiers.</li> <li>Unified observability pipeline \u2192 Single consistent pipeline for logs, metrics, and traces reduces operational complexity.</li> <li>Improved troubleshooting \u2192 correlation of logs, metrics, and traces dramatically speeds up root cause analysis. Reduces MTTR (Mean Time To Repair).</li> <li>Scalability &amp; flexibility \u2192 the OpenTelemetry Collector can be scaled horizontally to handle high data volumes. Supports multi-cloud and hybrid architectures natively.</li> <li>Standardization across teams \u2192 developers, SREs, and security teams use a common telemetry standard. Simplifies onboarding and reduces friction in cross-team operations.</li> <li>Extensibility \u2192 pluggable components allow integration with new tools or pipelines without redesigning the system.</li> </ul> <p></p>"},{"location":"PaaS/#paas-ticket-management-service","title":"PaaS Ticket Management Service","text":"<p> Ticket Management Service interface </p>"},{"location":"PaaS/#service-description_17","title":"Service Description","text":"<p>The service offers tools for managing user requests, incidents, related problems, and the entire ticketing cycle. Intelligent automation: integrated AI functions (classification, knowledge suggestion, sentiment, and draft generation) reduce manual workload and speed up resolution. Self-service and multi-channel: users can open tickets via the portal or email and view their status. This promotes a good user experience. Integration with assets, services, and configuration: It can connect to the service catalog, CMDB, and asset management, making ticketing part of a broader IT management ecosystem.</p> <p>The service is offered for a number of Service Desk operators. Each subscription is for 50 operators.</p>"},{"location":"PaaS/#features-and-advantages_17","title":"Features and Advantages","text":"<p>The service, based on Matrix42, features a modular architecture, with components covering the user interface, workflow/automation engine, integration with external systems, databases, and reporting. It offers the following main features:</p> <ul> <li>Incident and Service Request Management \u2192 allows for the logging, classification, and resolution of incidents and service requests via a portal, email robot, or Service Desk agent.</li> <li>Self-Service Portal and Service Catalog \u2192 the portal allows users to request services, check ticket status, view announcements, and view knowledge/FAQs. Workflow, Automation, and Low-Code Platform \u2192 offers a visual workflow builder (drag &amp; drop) with no coding required to automate processes such as approvals, escalations, and ticket assignment.</li> <li>Integrated Artificial Intelligence \u2192 the \"AI Assist\" module automatically suggests ticket category, impact, and urgency, analyzes user sentiment (\"user mood\"), and suggests knowledge base articles or similar tickets (\"resolution helper\").</li> <li>SLA Monitoring, Reporting, and Dashboards \u2192 analyzes support processes, KPIs, and provides visibility into service desk performance.</li> <li>Customization, Roles, and Permissions \u2192 Supports the definition of user roles, granular permissions, filters, custom views, and dedicated dashboards. agents/managers.</li> </ul> <p>The main components of the service are:</p> <ul> <li>UUX (Unified User Experience): the platform's UI component, which unifies the web interface (\"low-code solution\") for users, agents, and administrators.</li> <li>SolutionBuilder: A low-code/\"no-code\" module for configuring/modifying layouts, views, data models, and interfaces. Allows interface and data customization without (much) code. - Workflow Studio / Designer / Worker Engine: components for defining, managing, and executing workflows and automations.</li> <li>Database and storage: the platform uses multiple databases (e.g., \"Master\" database for operational data, \"Data Warehouse\" for analysis/reporting, \"History Database\" for logs and change history), typically on Microsoft SQL Server + Analysis Services + Reporting Services.</li> <li>Integration / API / Data providers: the platform supports integration with Active Directory/Azure AD, external databases, REST API, SOAP, flat files, and SQL for reading/writing.</li> <li>Flexible deployment: it can be delivered on-premise, in a public cloud, a private cloud, or a hybrid (\"Cloud your way\") to adapt to compliance, scalability, and geographic requirements.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced operating costs \u2192 thanks to process automation and a reduction in manual tasks, fewer repetitive interventions and a lower cost per ticket. Increased support team productivity \u2192 thanks to workflow automation, the use of AI (for automatic classification, suggestions, pre-populated responses), and self-remediation, the manual burden on IT operators is reduced. The self-service portal and knowledge base enable self-resolution of many user issues.</li> <li>Support for business decisions \u2192 integrated reports and dashboards provide KPIs on average response times, resolution, ticket volumes by category, and seasonal trends.</li> <li>Improved user experience \u2192 users can open tickets, monitor status, and find solutions independently, reducing frustration and wait times. Furthermore, it fosters a collaborative and efficient environment between users and support teams, with agents viewing the same status in real time.</li> <li>Improved control and governance of IT services \u2192 provides a comprehensive view of assets, users, and services, supporting regulatory compliance and service level agreement (SLA) monitoring in a documented and traceable manner.</li> <li>Native integration with the IT ecosystem \u2192 possible integrations with SSO systems (e.g., Active Directory/Azure AD), UEM, Asset Management, Change Management, IT monitoring, HR systems, and others via API, reducing information silos and improving data quality.</li> </ul> <p></p>"},{"location":"PaaS/#paas-operations-management","title":"PaaS Operations Management","text":"<p> PaaS Operations Management Overview </p>"},{"location":"PaaS/#service-description_18","title":"Service Description","text":"<p>The PaaS Operations Management service provides a fully managed platform for monitoring, observability, incident detection, and operational oversight of IT infrastructures and applications. Based on Zabbix and NetEye, the service delivers enterprise-grade monitoring capabilities\u2014such as telemetry collection, alerting, performance analytics, and event correlation\u2014without requiring customers to deploy or maintain monitoring servers, databases, or agents. Designed for hybrid and cloud-native environments, the service centralizes monitoring for compute, network, storage, security, and application layers, ensuring full visibility and operational continuity.</p> <p>The service is offered and sized for every 25 concurrent users.</p>"},{"location":"PaaS/#features-and-advantages_18","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Comprehensive infrastructure &amp; application monitoring \u2192 tracks the health and performance of: VMs, containers, hosts, and cloud resources, networks, firewalls, and load balancers, storage systems and databases, application services and APIs. Supports agent-based and agentless checks.</li> <li>Centralized metrics, logs, and telemetry collection \u2192 consolidates metrics, ping checks, SNMP data, application logs, and custom KPIs. Ensures unified observability across heterogeneous environments. Retains historical data for trend analysis.</li> <li>Intelligent alerting &amp; notifications \u2192 event-driven alerts based on thresholds, anomalies, or dependency rules. Multi-channel notifications (email, SMS, webhook, ITSM integration). Avoids alert noise through suppression, deduplication, and escalation rules.</li> <li>Event correlation and root cause analysis \u2192 NetEye\u2019s correlation engine groups related events. Identifies probable root causes across interconnected systems. Reduces mean time to detect (MTTD) and mean time to repair (MTTR).</li> <li>Dashboards and visualization \u2192 customizable dashboards for operations, NOC screens, and business KPIs. Visual representations of system health, topology maps, and SLA views.</li> <li>SLA monitoring and reporting \u2192 tracks service availability against SLA targets. Generates performance, capacity, and downtime reports. Supports compliance audits and service management.</li> <li>Automated discovery \u2192 auto-detects new cloud resources, VMs, hosts, network devices, and services. Automatically assigns monitoring templates. Keeps monitoring configuration aligned with dynamic environments.</li> <li>Integration with ITSM and automation tools \u2192 supports integration with ticketing systems (ServiceNow, Jira, etc.). Exposes APIs for orchestration and automated remediation workflows.</li> <li>Zero infrastructure management \u2192 no monitoring servers, databases, or scaling logic to manage. The provider handlespatching, backup, capacity, and high-availability.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Zabbix monitoring cluster \u2192 distributed monitoring cluster for data collection and event processing. Supports high availability and horizontal scaling. Responsible for metrics ingestion, - NetEye observability and correlation layer \u2192 enhances Zabbix data with event correlation and analytics. Adds long-term storage, dashboards, reporting, and advanced alerts. Integrates with log management and SIEM modules if required.</li> <li>Data collection layer \u2192 supports multiple collection methods: Zabbix agents, SNMP collector, API polling, log ingestion, push gateway metrics, cloud-native exporters. Ensures flexibility across heterogeneous environments.</li> <li>Storage layer \u2192 time-series storage for metrics (TSDB). Log and event indexing engines. Redundant and scalable architecture for long-term data retention.</li> <li>Control plane \u2192 manages: template management, alert rules, agent policies, discovery rules, user and permissions configuration, integrations and webhooks</li> <li>Data plane \u2192 collects telemetry from monitored systems. Processes events, evaluates triggers, and generates alerts. Streams metrics to dashboards and correlation modules.</li> <li>Visualization &amp; reporting layer \u2192 provides dashboards, SLA reports, historical charts, and heatmaps. UI tailored for NOC operations and technical teams.</li> <li>Security &amp; multitenancy \u2192 segregated monitoring domains per tenant or project. Secure role-based access controls (RBAC). Encrypted communication between monitoring agents and servers.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>End-to-end visibility \u2192 unified monitoring across cloud, on-prem, and hybrid environments. Central view of all operational metrics and services.</li> <li>Faster detection and resolution \u2192 intelligent alerts and event correlation reduce noise and improve detection. Lower MTTR thanks to root cause analysis and detailed telemetry.</li> <li>No Infrastructure to manage \u2192 fully managed service\u2014no servers, DBs, or upgrades to maintain. Reduces operational burden on IT and DevOps teams.</li> <li>Enhanced reliability and SLA compliance \u2192 continuous monitoring ensures proactive issue identification. Supports SLA tracking and reporting for internal/external services.</li> <li>Scalability and performance \u2192 handles thousands of checks per second. Automatically adapts to growing or dynamic infrastructures.</li> <li>Cost efficiency \u2192 avoids the cost of deploying, licensing, and maintaining monitoring platforms.</li> <li>Enterprise-grade security \u2192 isolated tenant environments. Encrypted agent communications and secure data storage.</li> <li>Improved operations and governance \u2192 supports audit requirements with historical logs and performance reports. Ensures transparency and accountability in service operations.</li> <li>Integration with ITSM and automation \u2192 automatic ticket creation for incidents. Enables self-healing workflows and auto-remediation.</li> <li>Better user and customer experience \u2192 early detection prevents service degradation. Ensures smooth, predictable operation of business-critical applications.</li> </ul>"},{"location":"PaaS/#devsecops-family","title":"DevSecOps Family","text":"<p>Below is the list of services belonging to the  DevSecOps family:</p> <ul> <li>Configuration Manager</li> <li>Test Automation</li> <li>Quality Code Analysis</li> <li>DevSecOps As A Service</li> <li>Qualizer DevSecOps</li> </ul> <p></p>"},{"location":"PaaS/#configuration-manager","title":"Configuration Manager","text":"<p> Configuration Manager Service interface </p>"},{"location":"PaaS/#service-description_19","title":"Service Description","text":"<p>The service, based on Red Hat Ansible Automation Platform, is a comprehensive automation solution for managing IT infrastructure, simplifying operations, and accelerating development and deployment processes. It is a platform that acts as a powerful and flexible configuration manager, helping organizations automate repetitive or manual tasks, implement complex configurations, and orchestrate workflows centrally and securely through a declarative and automated approach, ensuring consistency and improving overall operational efficiency and compliance.</p> <p>The service is offered and sized in units of 25 Managed workers.</p>"},{"location":"PaaS/#features-and-advantages_19","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Declarative automation \u2192 use of playbooks to clearly describe the desired state of resources. Support for role-based automation, reuse, and modular configurations.</li> <li>Centralized execution management \u2192 task orchestration via Ansible Controller with scheduling, auditing, and notifications. Dashboards and reporting for real-time monitoring of automations.</li> <li>Integration with DevOps pipelines \u2192 support for CI/CD tools (Jenkins, GitLab, GitHub Actions, OpenShift Pipelines). Automatic execution of playbooks in response to events or code commits. Credential and secret management. Integration with Red Hat Ansible Vault, CyberArk, HashiCorp Vault, and other secret managers.</li> <li>Scalability and multi-tenancy \u2192 support for multi-organization environments with role and access segregation. Distributed execution via containerized Automation Execution Environments.</li> <li>Compliance and security \u2192 full operation logging and Role-Based Access Control (RBAC)-based access control. Compliance with corporate and regulatory security standards.</li> </ul> <p>The service uses an agentless architecture and YAML-based playbooks to define, deploy, and maintain desired system states across various infrastructure components, including servers, networks, storage, and cloud resources. The main components of the service are:</p> <ul> <li>Automation Controller \u2192 Web interface and REST API for centralized automation management. Orchestration engine that coordinates playbook execution.</li> <li>Automation Execution Environments (EE) \u2192 standardized containers containing the Ansible runtime, modules, plugins, and specific dependencies. They enable portability and consistency of execution across different environments.</li> <li>Automation Hub \u2192 private repository for distributing content collections (modules, roles, plugins). It promotes reuse and version control of Ansible content.</li> <li>Automation Mesh \u2192 distributed architecture for scalable job execution on remote nodes or in the cloud. Ensures reliability and load balancing of automations</li> <li>Inventory and Credential Store \u2192 defines target systems (servers, VMs, containers, network devices, cloud services). Securely manages access credentials for each target or environment. APIs and Integrations \u2192 RESTful API for integration with external monitoring, ticketing, or orchestration systems.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced operating costs \u2192 automating repetitive and manual tasks reduces the time spent on system management and maintenance.</li> <li>Increased reliability and service quality \u2192 standardized and automated configurations reduce inconsistencies between environments (dev, test, prod).</li> <li>Scalability of IT business \u2192 the platform grows with the organization, managing hundreds or thousands of nodes without linear staff growth.</li> <li>Improved IT compliance and governance \u2192 all changes are tracked and documented, ensuring transparency and compliance with regulations and corporate policies.</li> <li>Increased productivity and collaboration \u2192 DevOps, IT Operations, and Security teams can work on a single shared platform, reducing organizational silos.</li> <li>End-to-end automation \u2192 from operating system configuration to application deployment, patch management, and ongoing maintenance.</li> <li>Standardization and repeatability \u2192 playbooks ensure consistent configurations and easy reuse of automation code.</li> <li>Centralized and secure management \u2192 a single interface (Controller) for orchestrating jobs, managing inventories, credentials, and access policies (RBAC). Secure management of credentials and secrets (Vault), centralized auditing, and support for enterprise authentication (LDAP, SSO, OAuth).</li> <li>Distributed scalability \u2192 job execution can be distributed across multiple nodes, improving performance and resilience.</li> <li>Complete visibility and traceability \u2192 dashboards and analytical reports allow you to monitor the effectiveness of automations and resource usage.</li> </ul> <p></p>"},{"location":"PaaS/#test-automation","title":"Test Automation","text":"<p> Test Automation Service </p>"},{"location":"PaaS/#service-description_20","title":"Service Description","text":"<p>The service is designed to automate software testing activities, with the goal of improving quality, reducing release times, and increasing development process efficiency. The solution uses the UiPath RPA (Robotic Process Automation) platform to automate software testing (functional, regression, API, user interface). It was created to support both IT and business teams in the continuous validation of applications, digital processes, and RPA robots to increase testing efficiency and ensure software integrity. It supports Agile and DevOps approaches with Continuous Testing to ensure code changes do not introduce new defects. Centralized monitoring: Test results are collected and displayed in a single interface, facilitating monitoring and analysis via UiPath Test Manager and extensible with dashboards on UiPath Insights.</p> <p>The service is sized and offered per user units. Each unit is consists of: 10 automation testers -concurrent, 5 Robots.</p>"},{"location":"PaaS/#features-and-advantages_20","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Test automation for applications \u2192 test automation for web, desktop, mobile, and API applications. Support for cross-browser and cross-platform testing. Reuse of RPA components \u2192 automations developed in UiPath Studio can be reused as test cases. This reduces test creation time and costs.</li> <li>Test Manager \u2192 centralized tool for planning, executing, and monitoring tests. Dashboard with KPIs and integrated reporting.</li> <li>DevOps Integration \u2192 integration with CI/CD tools (Azure DevOps, Jenkins, GitLab, etc.). Ability to run tests in software release pipelines.</li> <li>Scalability \u2192 tests can be deployed to UiPath robots in parallel, reducing execution times.</li> <li>Automated Continuous Testing \u2192 \"Shift-left\" approach: quality is validated from the early stages of development. Ensures fewer bugs in production.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Studio / Studio Pro \u2192 Development environment (IDE) for creating automated tests, similar to creating RPA workflows.</li> <li>Orchestrator \u2192 for scheduling, deploying, and running tests at scale.</li> <li>Test Manager \u2192 for managing requirements, organizing test suites, collecting metrics and reporting.</li> <li>Robotic Test Execution \u2192 UiPath robots become \"digital testers,\" running tests autonomously.</li> <li>Testing Robots \u2192 Specialized test execution robots; support testing frameworks such as NUnit, MSTest, and Junit.</li> <li>Insights \u2192 Manages the creation of dashboards for monitoring various testing processes; allows you to calculate the return on investment of initiatives.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced software release times \u2192 thanks to faster and more continuous testing cycles.</li> <li>Improved software quality \u2192 fewer bugs in production and reduced maintenance costs.</li> <li>Reduced manual testing costs \u2192 less time spent on manual testing and more focus on strategic testing.</li> <li>High Return on Investment (ROI) \u2192 thanks to a single automation and testing platform.</li> <li>IT-business alignment \u2192 greater reliability and traceability of results.</li> <li>Support for Agile and DevOps CI/CD approaches with continuous validation.</li> <li>Reduced risk of regressions \u2192 more confident release of new features.</li> <li>Multi-level test automation (UI, API, mobile, desktop, SAP, Salesforce).</li> <li>Controlled scalability \u2192 assigned resources can be scaled horizontally or vertically to meet performance and operational needs.</li> <li>Multi-platform support (Web, Mobile, Mainframe, API, Enterprise systems).</li> </ul> <p></p>"},{"location":"PaaS/#quality-code-analysis","title":"Quality Code Analysis","text":"<p> Quality Code Analysis Service </p>"},{"location":"PaaS/#service-description_21","title":"Service Description","text":"<p>The service, based on SonarQube, offers public administrations a robust static code analysis tool, supporting software quality and integration into CI/CD processes. Thanks to its architecture and ability to integrate into the continuous development and analysis cycle, it enables the development of high-quality software and fully supports DevSecOps initiatives. The service also enables in-depth source code security analysis, detecting known vulnerabilities, injections, poor cryptographic practices, uncontrolled access, and potential exploits. Integrating directly into CI/CD pipelines or through supported DevOps platforms, it analyzes source code against a broad set of quality rules, covering aspects such as code maintainability, software reliability, and application security.</p> <p>The service is offered per unit of line of codes. Each unit consists of 1 M lines of codes.</p>"},{"location":"PaaS/#features-and-advantages_21","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Static code analysis \u2192 automatically scans source code with over 5,000 predefined or customizable rules. Supports over 30 languages.</li> <li>Quality gates \u2192 defines minimum quality thresholds (e.g., zero critical bugs, zero vulnerabilities, code coverage &gt; 80%). If the code does not meet the criteria, the build is blocked, preventing the release of \"dirty\" software.</li> <li>Bug and vulnerability Detection \u2192 highlights issues that could cause runtime errors or security risks. Integration with OWASP Top 10, CWE, and SANS security rules.</li> <li>Code smells &amp; debt \u2192 identify development practices that reduce readability or increase technical debt. Calculates an indicator of the time required to \"clean up\" the code.</li> <li>Test coverage \u2192 measures the percentage of code covered by unit tests. Helps identify critical untested areas.</li> <li>DevOps integration \u2192 can be integrated into CI/CD processes. Provides immediate feedback to developers throughout the development cycle</li> <li>Reporting and dashboards \u2192 interactive dashboards with KPIs on quality, security, and maintainability. Historical trends to monitor code quality evolution over time</li> <li>Multi-branch &amp; Pull request analysis \u2192 analysis of specific branches and pull requests for immediate feedback before merging.</li> </ul> <p>The main components of the service are:</p> <ul> <li>SonarQube server \u2192 core module of the service, responsible for running analyses, applying static verification rules, and centralized results management. It includes: analysis engine, quality gate engine, rule repository, user and permissions management, and RESTful APIs.</li> <li>Database \u2192 stores analysis results, active rules, and project history. Supports PostgreSQL, Oracle, SQL Server, and MySQL.</li> <li>SonarScanner \u2192 code analysis tool. It can be run locally by developers or integrated into CI/CD pipelines.</li> <li>CI/CD Integration \u2192 plugins and APIs available for Jenkins, Azure DevOps, GitLab CI, GitHub Actions, Bamboo, and TeamCity.</li> <li>Security and Governance \u2192 Authentication via LDAP, Active Directory, SAML, and OAuth. Granular roles (Admin, Project Admin, Developer, and Viewer).</li> <li>Web portal \u2192 browser-accessible user interface that allows developers, QA, team leaders, and analysts to view detailed project metrics and quality indicators, consult and manage Quality Gates, and view aggregated dashboards and reports at the project portfolio level. The portal is secure, multi-user, and configurable via granular roles and permissions.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Lower risk of bugs in production and reduced maintenance costs \u2192 more reliable and stable software, cleaner and more maintainable code.</li> <li>Compliance with security standards \u2192 regulatory and audit support.</li> <li>Increased customer/stakeholder trust \u2192 software perceived as more secure and robust.</li> <li>Long-term Return On Investment (ROI) \u2192 less time and resources spent on late fixes.</li> <li>Increased team productivity \u2192 less rework, more focus on new features.</li> <li>Support for Agile and DevOps approaches \u2192 the service enables the Clean as You Code approach and automates quality and security checks, reducing time to remediation thanks to immediate feedback to developers.</li> <li>Improved software quality \u2192 through the systematic application of quality rules, the service helps improve code maintainability and readability. Technical debt management \u2192 estimate the time to fix issues.</li> </ul> <p></p>"},{"location":"PaaS/#devsecops-as-a-service","title":"DevSecOps As A Service","text":"<p> DevSecOps As A Service </p>"},{"location":"PaaS/#service-description_22","title":"Service Description","text":"<p>The service, based on Gitlab, offers an integrated environment for the complete management of the software development lifecycle according to the DevSecOps approach and practices, providing the tools needed for collaboration, development, testing, security, and software release in a single integrated environment. The service aims to support organizations in introducing application development, release, and management processes characterized by automation, security, and compliance, thus promoting the creation of reliable digital solutions aligned with required quality standards. It allows you to manage projects and repositories, control source code versions, automate CI/CD pipelines, and collaborate efficiently with development teams.</p> <p>The service is offered per user unit in the following options: 100 Users Ultimate/500 Users premium/2000 Free.</p>"},{"location":"PaaS/#features-and-advantages_22","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Git repositories \u2192 represent the collection point for source code. They enable versioning, change tracking, and collaboration across multiple development teams.</li> <li>CI/CD pipeline \u2192 automation of build, test, and release phases. They reduce manual errors, speed delivery times, and ensure process repeatability.</li> <li>Security Integration (DevSecOps) \u2192 automatic scans of code (SAST), dependencies (SCA), container images, and infrastructure configurations. Early identification of vulnerabilities and tracking of remediation directly within development workflows.</li> <li>Artifact and Container Management \u2192 centralized storage of build artifacts and container images. Support for secure and controlled deployment across the various phases of the environment (development, testing, production).</li> <li>Monitoring and governance \u2192 dashboards to view code quality, security, and project status. Role-based access controls and integration with identity management systems to ensure compliance and accountability.</li> </ul> <p>The main components of the service are:</p> <ul> <li>GitLab core platform \u2192 this is the core of the platform and encompasses its main features: a web interface, API, database, and team collaboration tools.</li> <li>Git repository \u2192 a service dedicated to managing Git repositories. It handles code versioning and timely tracking of all changes.</li> <li>CI/CD Engine GitLab Runner \u2192 a service responsible for executing CI/CD jobs defined within pipelines, automating build, test, and deployment processes.</li> <li>Artifact registry \u2192 a module dedicated to managing and archiving artifacts generated during CI/CD pipelines, such as packages, container images, and libraries. It ensures traceability, security, and reuse of software components.</li> <li>Test Management \u2192 a component that supports the structured management of testing activities, enabling the planning, execution, and monitoring of test cases to ensure software quality throughout the development lifecycle.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced time to market \u2192 thanks to automation and integrated pipelines.</li> <li>Reduced operating costs \u2192 a single platform instead of multiple separate tools.</li> <li>Increased team productivity \u2192 thanks to centralized collaboration. </li> <li>High Return On Investment (ROI) \u2192 reduced rework and post-release remediation.</li> <li>Increased stakeholder trust \u2192 more secure code and faster releases.</li> <li>Native security integration \u2192 integrated DevSecOps capabilities. Ensures compliance with corporate and regulatory policies.</li> <li>Integrate project management with native tools (issue boards, milestones, etc.).</li> <li>Centralize source code and CI/CD pipeline management.</li> <li>Foster collaboration between technical and project teams.</li> <li>Increase team productivity through process automation.</li> </ul> <p></p>"},{"location":"PaaS/#qualizer-devsecops","title":"Qualizer DevSecOps","text":"<p> Qualizer DevSecOps Service </p>"},{"location":"PaaS/#service-description_23","title":"Service Description","text":"<p>The Leonardo's Qualizer service is a platform designed to meet the needs for visibility, control, and continuous improvement of the software lifecycle throughout the development cycle, in accordance with the DevSecOps and Agile approach. It offers a centralized tool for analyzing, observability, and governance of software quality. The service allows you to aggregate data from various sources, security, monitoring, and testing tools, integrating them into a user dashboard (portal) that clearly and graphically displays various interactive metrics and insights.</p> <p>The service is sized and offered per project unit. Each unit consists of 10 projects.</p>"},{"location":"PaaS/#features-and-advantages_23","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Ingestion \u2192 automatically collects data from the main tools used in development processes, such as code management systems, continuous integration tools, and software quality and security analysis. The collected data is processed and made available for consultation and analysis.</li> <li>Data processing \u2192 processes the data collected by the ingestion module, normalizes it, and extracts key metrics. The data is structured and made highly accessible via dashboards.</li> <li>Project management \u2192 this module allows you to configure and organize projects within the service. It allows organizations to specify which products, pipelines, and tools they wish to monitor and associate useful information for navigation and management with each project.</li> <li>Analytics engine \u2192 the service provides summary and analytical views that aggregate the collected information and present it clearly and understandably (e.g., DevOps performance metrics; code security status; code quality; number of tests performed; percentage of tests passed).</li> <li>Presentation layer \u2192 data is made available through dashboards that allow for the analysis and continuous monitoring of key metrics.</li> </ul> <p>The Qualizer service is cloud-native and based on a containerized microservices system. This architecture allows Qualizer to be flexible, resilient and secure, with the ability to adapt to different technological scenarios. At a logical level, the architecture is divided into the following main components:</p> <ul> <li>Core modules \u2192 each service module (e.g., ingestion, project management, data processing) is implemented as an independent microservice, orchestrated in a Kubernetes/OpenShift environment to ensure high availability and functional isolation.</li> <li>Database for storing collected data \u2192 data acquired from external systems is stored in a centralized database, which is then processed and normalized to support efficient metrics processing, interactive consultation, and dashboard generation.</li> <li>Integration via REST API \u2192 the service interacts with external platforms through standard APIs, enabling continuous data collection.</li> <li>Messaging broker \u2192 the service uses a Kafka-based messaging system to ensure decoupling between modules, support high event loads, and facilitate horizontal scalability.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced time to market \u2192 thanks to automation and integrated pipelines.</li> <li>Reduced operating costs \u2192 a single platform instead of multiple separate tools.</li> <li>Increased team productivity \u2192 thanks to collaboration between developers and security specialists, aligning objectives and timelines.</li> <li>High Return On Investment (ROI) \u2192 reduced rework and post-release remediation.</li> <li>Increased stakeholder trust \u2192 more secure code and faster releases.</li> <li>Centralized security management \u2192 vulnerabilities detected by various scanning tools are collected, normalized, and tracked in a single location, facilitating the work of security teams and reducing the risk of omissions.</li> <li>Reduced remediation time \u2192 thanks to immediate visibility of vulnerabilities, Qualizer accelerates the process of taking charge and resolving issues. - Continuous improvement based on collected metrics \u2192 through standardized dashboards and indicators, the service allows you to objectively measure team and project performance.</li> <li>Unified dashboard for quality, security, and deployment monitoring.</li> </ul>"},{"location":"PaaS/#big-data-family","title":"Big Data Family","text":"<p>Below is the list of services belonging to the Big Data family:</p> <ul> <li>Data Lake</li> <li>Business Intelligence</li> <li>Batch/Real time Processing</li> <li>Event Message</li> <li>Data Governance</li> </ul> <p></p>"},{"location":"PaaS/#data-lake","title":"Data Lake","text":"<p> Data Lake Service </p>"},{"location":"PaaS/#service-description_24","title":"Service Description","text":"<p>Developed by Leonardo, it provides a ready-to-use platform that has all the features developers, data scientists, and analysts need to easily archive data of all sizes, shapes, and velocities. It allows for the ingestion of a wide range of heterogeneous data sources (structured, semi-structured, and unstructured), from various internal and external sources within the organizations (relational databases, files, web applications, cloud, web services, etc.), and of various classification types. It integrates with the Processing/ETL module for accessing data and metadata for the necessary processing or normalization, and with the Data Governance module for managing data access and managing data security and protection.</p> <p>The service is sized and offered per storage unit. Each unit contains 1 TB.</p>"},{"location":"PaaS/#features-and-advantages_24","title":"Features and Advantages","text":"<p>Data Lake is the foundation for all Big Data services; without it, other services cannot be activated. It was designed based on, and with full wire-protocol compatibility with, Amazon's renowned cloud storage product (Simple Storage Service). This enables the scalability needed to manage data volumes in the petabyte range (and beyond) typical of the Big Data world, while ensuring maximum interoperability and compatibility with languages, libraries, and products compatible with the S3 protocol. Data Lake's capabilities are based on a horizontally scalable infrastructure, capable of supporting heavy read and write loads, ensuring consistent performance even in scenarios characterized by large amounts of data and intensive throughput.</p> <p>The development technology is based on MinIO, an object storage solution fully compatible with the S3 protocol. The application layer is built on distributed object storage, which in turn relies on an underlying block storage layer, which can be implemented either bare metal or using software-defined solutions. The overall architecture is based on containers orchestrated by a resource manager based on an enterprise-class Kubernetes distribution.</p> <p>The service offers the following advantages:</p> <ul> <li>Compliance and governance \u2192 supports versioning, auditing, encryption (AES-256), and integration with identity management systems.</li> <li>Flexibility and scalability \u2192 supports horizontal scalability; ideal for companies with rapidly growing data or multi-petabyte storage needs.</li> <li>Rapid time to market \u2192 allows you to quickly deploy new analytical applications or data pipelines without worrying about underlying management.</li> <li>Simplified management \u2192 teams don't need to worry about technical maintenance. There's no need to configure clusters, load balancers, manual replication, or complex monitoring; it offers native monitoring and alerting tools.</li> <li>Reduced operating costs \u2192 the service is built with open source standards and compatible with S3, thus reducing licensing costs compared to proprietary solutions.</li> <li>High availability and resilience \u2192 integrated replication and support for erasure coding ensure data resilience and business continuity.</li> <li>Optimized performance \u2192 designed for high-performance object storage, with high throughput and low latency. Ideal for real-time analytics and intensive ML/AI workloads.</li> <li>Interoperability \u2192 S3 API compatibility allows for easy integration of existing applications. Supports multi-protocol access.</li> <li>Automation and DevOps-friendly \u2192 it enables continuous updates without downtime and simplified backup management.</li> </ul>"},{"location":"PaaS/#disaster-recovery-dr-architecture","title":"Disaster Recovery (DR) architecture","text":"<p>Data replication within MinIO Object Storage is managed directly at the application level. The solution provides Site Replication capabilities that enable native management of data distributed across multiple Data Centers (DCs), synchronizing buckets, objects, access policies, and encryption configurations. Typically, data availability and resilience in distributed object storage systems is achieved through deployment across multiple physical locations. In this architecture, MinIO clusters are deployed in geographically separate data centers to provide disaster recovery capabilities.  Replication between MinIO sites can be configured:</p> <ul> <li>as synchronous inside the same Region for HA configuration.</li> <li>as ynchronous beetween different Regions for DR configuration.  </li> </ul> <p>In this deployment, thanks to the high bandwidth and low latency connections available between data centers, synchronous Site Replication was adopted between clusters, ensuring data consistency across locations. Access to the different clusters can be achieved either via direct addressing or through a load balancer, depending on architectural and operational needs.From an internal management perspective, MinIO automatically organizes storage units into erasure sets, which are logical groups that form the foundation of system availability and resilience. To ensure uniform distribution, MinIO applies a striping mechanism for erasure sets across the various nodes in the pool, avoiding load concentrations or single points of failure. Objects are then divided into data blocks and parity blocks, which are distributed within the erasure sets, ensuring redundancy, fault tolerance, and operational continuity.</p> <p></p>"},{"location":"PaaS/#data-lake-cold","title":"Data Lake-Cold","text":"<p> Data Lake Service </p>"},{"location":"PaaS/#service-description_25","title":"Service Description","text":"<p>This is the same technology and architectural solution as the previous Data Lake service, adapted for cold storage scenarios, i.e., data that is rarely used and accessed slowly.</p> <p>This implies the following features:</p> <ul> <li>Much less frequent data access</li> <li>Slower data recovery times</li> <li>Lower storage costs</li> <li>Used for historical data, old logs, and long-term backups</li> </ul>"},{"location":"PaaS/#features-and-advantages_25","title":"Features and Advantages","text":"<p>For features, components, and benefits, see the full service offering Data Lake.</p> <p></p>"},{"location":"PaaS/#business-intelligence","title":"Business Intelligence","text":"<p> Business Intelligence Service </p>"},{"location":"PaaS/#service-description_26","title":"Service Description","text":"<p>Developed by Leonardo with Grafana technology, the Business Intelligence Service is a platform with an analytics environment designed to provide real-time, interactive data visualization and monitoring capabilities. It centralizes data ingestion, transformation, storage, and dashboarding within a scalable service that eliminates the need for organizations to maintain on-premises analytics infrastructure. Built on the Grafana visualization engine, the platform empowers users to explore metrics, logs, and business KPIs through intuitive dashboards while integrating seamlessly with diverse data sources across cloud and hybrid ecosystems.</p> <p>The service is sized and offered per user unit. Each unit consists of 100 users.</p>"},{"location":"PaaS/#features-and-advantages_26","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Unified Data Visualization \u2013 Provides dynamic, customizable dashboards that consolidate operational, financial, and business performance data from multiple sources.</li> <li>Multi-source Connectors \u2013 Supports native integration with SQL databases, time-series platforms, cloud storage, IoT systems, and third-party analytics services.</li> <li>Real-time Monitoring \u2013 Enables continuous tracking of business and operational metrics with live updates, alert rules, and automated notifications.</li> <li>Role-based Access Control (RBAC) \u2013 Ensures secure, granular access to dashboards, data, and administrative functions based on user roles and permissions. Advanced Querying and Exploration \u2013 Offers powerful query capabilities, including support for SQL, PromQL, InfluxQL, and other engine-specific languages.</li> <li>Alerts and Anomaly Detection \u2013 Provides rule-based alerts, thresholds, and pattern detection to identify anomalies or performance issues across business workflows.</li> <li>White-labeling and Custom Branding \u2013 Allows organizations to apply their own visual identity to dashboards, reports, and portal interfaces.</li> <li>API and Automation Support \u2013 Facilitates integration with third-party systems through APIs, webhooks, and automation workflows.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Visualization Layer \u2013 The dashboard engine that renders interactive charts, tables, alerts, and analytics views.</li> <li>Data Source Integration Layer \u2013 Connectors and plugins enabling ingestion from databases, cloud platforms, streaming services, logs, and monitoring tools.</li> <li>Data Processing Pipeline \u2013 Optional ETL/ELT engines for cleaning, transforming, and aggregating raw data prior to visualization.</li> <li>Time-Series and Analytical Storage \u2013 Managed storage solutions (e.g., Prometheus, Loki, InfluxDB, Elasticsearch, SQL warehouses) optimized for real-time queries.</li> <li>User and Access Management \u2013 Centralized identity integration with SSO, LDAP, OAuth2, or corporate IAM platforms</li> <li>Alerting and Notification Engine \u2013 Framework that triggers alerts via email, Slack, Teams, PagerDuty, or SMS based on metric conditions.</li> <li>Management and Administration Console \u2013 Web interface for configuring data sources, managing tenants, provisioning resources, and monitoring platform health.</li> <li>API Gateway \u2013 Provides programmatic access for provisioning dashboards, exporting data, managing alerts, and embedding visuals.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Faster and better decisions \u2192 real-time or near-real-time access to data, intuitive visualizations, and drill-down into information, enabling more informed decisions.</li> <li>Increased productivity and speed of insight \u2192 automated creation/reporting, self-service dashboards, and easy sharing enable business users to act faster.</li> <li>Reduced total cost of ownership (TCO) and lower costs \u2192 managed infrastructure and reduced need for on-premise infrastructure reduce overall costs.</li> <li>Increased collaboration and a data-driven culture \u2192 dashboard sharing, integration with other tools, and ease of use promote adoption among non-technical users.</li> <li>Access anywhere and from different devices \u2192 availability via cloud, mobile apps, and remote access allows users to work on the move or from different locations.</li> <li>Extensive data integration \u2192 support for numerous connectors to on-premise and cloud sources, enabling consolidation of disparate data.</li> <li>Efficient data preparation and modeling \u2192 integrated tools enable ETL, modeling, and complex calculations.</li> <li>Interactive and self-service visualization \u2192 intuitive, drag-and-drop interface and pre-built templates allow non-technical users to build reports independently.</li> <li>Security, governance, and compliance \u2192 Features such as encryption and auditing support access control and compliance. Infrastructure scalability and flexibility.</li> </ul> <p></p>"},{"location":"PaaS/#paas-etl-batchreal-time-processing","title":"PaaS ETL - Batch/Real time Processing","text":"<p> PaaS ETL - Batch/Real time Processing </p>"},{"location":"PaaS/#service-description_27","title":"Service Description","text":"<p>It is a platform that provides a set of tools for processing, integrating, quality-checking, and preparing data from heterogeneous sources stored in the Data Lake, both in real time and in batch mode. It offers a user-friendly graphical interface for designing and implementing data integration workflows using a visual approach, following the ETL (Extract \u2013 Transform \u2013 Load) approach. This reduces the complexity of data integration and allows users to focus on business logic rather than programming code. It supports a wide range of data sources, including relational databases, files, web applications, cloud, web services, and more. This makes it extremely flexible for data integration in a variety of contexts. It also offers data quality management tools, allowing users to clean, standardize, and enrich their data to ensure its accuracy and reliability.</p> <p>The service is sized and offered per worker node. Each worker consists of: </p> <ul> <li>16vCPU</li> <li>128 GB of RAM</li> </ul>"},{"location":"PaaS/#features-and-advantages_27","title":"Features and Advantages","text":"<p>The main features and functionalities of the service are:</p> <ul> <li>Heterogeneous and large-scale data processing \u2192 It supports a large number of data sources in batch and streaming mode (for example, datasets stored on HDFS, S3, ADLS Gen2, and GCS in CSV, Parquet, Avro, and other formats, as well as RDBMS via JDBC or all popular NoSQL, Apache Kafka, and more).</li> <li>It is natively integrated with the Data Lake and Batch/Real-Time Processing PaaS of the Big Data family.</li> <li>It allows to implement complex data pipelines \u2192 leveraging the parallel and distributed computing capacity provided by a Spark cluster.</li> <li>It provides an interactive mode to debug flows and explore data easily and intuitively.</li> <li>It guarantees the maximum scalability necessary to meet the needs of organizations of any size, from small businesses to large enterprises.</li> </ul> <p>The main architectural components of the service are as follows:</p> <ul> <li>Visual ETL Architecture \u2192 provides various blocks that allow you to visually design an ETL, ELT, and ELL pipeline. It allows you to read, write, and modify data from different sources, interfacing with the Data Lake and Monitoring module, and can use the Processing module for data-intensive processing.</li> <li>Apache Spark \u2192 Open-source parallel processing framework that supports in-memory processing to improve the performance of applications that analyze Big Data.</li> <li>JupyterLab \u2192 Interactive notebook-based development environment designed primarily for working with data, scientific calculations, and machine learning. It supports writing and executing interactive code in languages \u200b\u200bsuch as Python, R, or Julia.</li> <li>NodeRed \u2192 Visual, low-code development environment for creating applications that connect devices, web services, APIs, and systems.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Support for data-driven strategies, faster and more informed decisions \u2192 centralized data for service customization (e.g., real-time analytics for marketing, IoT, e-commerce, etc.) and ready-to-use pipelines without complex development. </li> <li>Greater focus on core business \u2192 development and IT teams do not have to worry about technical maintenance, as it is managed. - Reduced operating costs and service scalability \u2192 no infrastructure to manage; support for large data volumes (batch) or continuous flows (streaming); automation of extraction, transformation, and loading processes with real-time scheduling or triggers; same framework for historical data and real-time flows.</li> <li>Integration with cloud ecosystem (data warehouse, data lake, BI, AI/ML).</li> <li>Guaranteed security and compliance (encryption, access, audit logs).</li> <li>Integrated monitoring \u2192 metrics, alerts, and centralized logging for ETL pipelines.</li> </ul> <p></p>"},{"location":"PaaS/#event-message","title":"Event Message","text":"<p> Event Message Service </p>"},{"location":"PaaS/#service-description_28","title":"Service Description","text":"<p>It provides a platform developed by Leonardo for developing real-time applications and data pipelines and acts as a message broker, providing publish-subscribe functionality. It increases the scalability and resilience of existing applications by decoupling architectural components using a reactive approach based on asynchronous interactions. The platform can scale horizontally and provide ordered message delivery capabilities. Like other Big Data PaaS modules, the solution is based on containerized resources orchestrated via Kubernetes. It enables near-real-time analytical processes through streaming and facilitates the implementation of IoT use cases.</p> <p>The service is sized and offered per worker node. Each worker consists of: - 16 vCPU - 128 GB of RAM</p>"},{"location":"PaaS/#features-and-advantages_28","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>A useful tool for implementing reliable data exchanges between different components.</li> <li>Ability to partition messaging workloads as application requirements change.</li> <li>Real-time streaming for data processing.</li> <li>Native support for data/message playback.</li> <li>Integration with the Batch/Stream Processing module.</li> <li>Web interface for monitoring: Brokers Topics/Messages, Consumers, ACLs.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Apache Kafka-based solution \u2192 publish-subscribe messaging platform built to manage real-time data exchange for streaming, distributed pipelining, and replay of data feeds for fast, scalable operations.</li> <li>Broker-based solution that operates by maintaining data streams as records within a cluster of servers.</li> <li>Topic \u2192 addressable abstraction used to show interest in a given data stream (series of records/messages).</li> <li>Partitions \u2192 topics can be divided into a series of order queues called partitions. </li> <li>Persistence \u2192 server clusters that durably maintain records/messages as they are published. </li> <li>Producers \u2192 defines which topic/partition a given record/message should be published to. </li> <li>Consumers \u2192 entities that process records/messages.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Faster time-to-market \u2192 New applications can be integrated rapidly via events, accelerating the development of new products and features.</li> <li>Greater agility \u2192 Facilitates the creation of modular and scalable services without major changes to the existing system.</li> <li>Reduced risk of operational failures \u2192 PaaS often includes SLAs, monitoring, backup, and redundancy, reducing the risk of downtime or data loss.</li> <li>Faster, more informed decisions \u2192 Real-time analytics for marketing, IoT, and e-commerce.</li> <li>Predictable costs \u2192 Reduces the risk of over-provisioning or unexpected maintenance costs.</li> <li>Scalability \u2192 Support for large event volumes without performance degradation</li> <li>High availability and fault tolerance</li> <li>Simplified management \u2192 No need to manage clusters, patches, software upgrades, or complex configurations</li> <li>Optimized Performance and Latency \u2192 Compression, batching, and automatic topic management improve performance</li> <li>Security and Compliance \u2192 Authentication, authorization, and encryption in transit and at rest are managed by the provider.</li> </ul> <p></p>"},{"location":"PaaS/#data-governance","title":"Data Governance","text":"<p> Data Governance Service </p>"},{"location":"PaaS/#service-description_29","title":"Service Description","text":"<p>A service developed by Leonardo that provides a platform with a single, secure, and centralized point of reference for data control. Leveraging search and discovery tools and connectors to extract metadata from any data source, it simplifies data protection, analysis, and pipeline management, as well as accelerating ETL processes. It allows you to automatically analyze, profile, organize, link, and enrich all metadata, implement algorithms for automatic metadata and relationship extraction, and support regulatory and data privacy compliance with intelligent data lineage tracking and compliance monitoring. It simplifies data search and access and verifies its validity before sharing it with other users. It enables the production of data quality data (a measure of data condition based on factors such as accuracy, completeness, consistency, and reliability). It allows you to oversee data error resolution efforts and maintain compliance with internal audits and external regulations. It provides immediate support for the detection and classification of personal data and other sensitive data.</p> <p>The service is sized and offered for a single license.</p>"},{"location":"PaaS/#features-and-advantages_29","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Data Search &amp; Discovery \u2192 Automatic exploration of Data Lake datasets for (meta)data that can enrich or deepen knowledge of the information held.</li> <li>Data &amp; Metadata Catalog \u2192 Extraction of information that makes the data searchable.</li> <li>Data Lineage \u2192 Tracking the entire data lifecycle, from source to destination.</li> <li>CL/Audit \u2192 Allows for robust granular data access permission management and auditing of data usage (this means being able to answer the question \"Who accessed what data and when?\" at any time).</li> </ul> <p>The service use a tool of Data Hub that extends the concept of a data catalog by offering data discovery, data observability, and data governance functions. It integrates natively with other architecture components, adding all the features that are particularly useful for achieving compliance objectives, such as privacy, security, and process quality management. This tool allows you to verify changes made to data within the catalog over time, distinguishing the various sources that have populated the Data Lake, the type of data entered (personal data, financial data, etc.), and identifying data that is sensitive to specific laws or compliance procedures, whether internal or external to the organization. Data integration within DataHub occurs primarily in two ways: - PUSH \u2192 automatically within third-party applications such as Airflow, Apache Spark, Great Expectations, etc. - PULL \u2192 manually by the developer prior to loading the data into the data lake via dedicated REST APIs.</p> <p>The service offers the following advantages:</p> <ul> <li>Improved governance and compliance \u2192 Complete data traceability (\"data lineage\") to demonstrate compliance with GDPR, ISO, or industry regulations.</li> <li>Increased data trust \u2192 Certainty about the data's provenance, how it has been transformed, and how up-to-date it is. </li> <li>Reduced risks and operational costs \u2192 Fewer duplications, inconsistencies, and \"orphaned\" datasets. Reduced time wasted searching or validating data.</li> <li>Accelerating time to market \u2192 Easily discover and reuse existing datasets, reducing reliance on technical teams.</li> <li>Greater focus on core business \u2192 Teams no longer need to worry about technical maintenance.</li> <li>Centralized catalog and metadata \u2192 Provides an active data catalog with technical and operational metadata. Automatically integrate with Big Data systems (Kafka, Hive, Spark, Databricks, etc.).</li> <li>Automated Data Lineage \u2192 Automatically tracks end-to-end data flows from ingestion to transformations, all the way to consumption (dashboard, API, ML).</li> <li>Native APIs and integrations \u2192 Exposes APIs and plugins for continuous integration with orchestration, observability, quality, and security tools.</li> <li>Access and Security Policy Management \u2192 Centralizes access policies based on roles and classifications. Improves data security without fragmenting rules across services.</li> <li>Automation and Self-Service \u2192 Fosters a self-service data discovery model for data engineers and data scientists.</li> <li>Scalability and modern architecture \u2192 Microservices architecture and Metadata Graph.</li> </ul>"},{"location":"PaaS/#artificial-intelligence-ai-family","title":"Artificial Intelligence (AI) Family","text":"<p>Below is the list of services belonging to the Artificial Intelligence (AI) family:</p> <ul> <li>Speech to Text</li> <li>AI Audio &amp; Video Analytics</li> <li>OCR</li> <li>Text Analytics/NLP</li> <li>Translation</li> <li>AI Search - RAG</li> <li>AI Platform</li> <li>AI SLM/LLM</li> </ul> <p></p>"},{"location":"PaaS/#speech-to-text","title":"Speech to Text","text":""},{"location":"PaaS/#service-description_30","title":"Service Description","text":"<p>This service provides an advanced speech-to-text model for transcribing audio files into text, trained on a vast dataset of audio and text in various languages \u200b\u200busing neural AI (deep learning) models specialized in automatic speech recognition (ASR). The service is optimized for English transcription, but can also recognize and transcribe speech in other languages, still returning the text in English. Furthermore, it can automatically identify the spoken language and supports automatic speech translation. It is useful for automatically transcribing conversations, interviews, meetings, call centers, podcasts, or videos; supporting chatbots and voice assistants, translating voice into text understandable by NLP or AI systems; indexing and analyzing audio content (semantic search, sentiment analysis, data mining); and digitizing voice archives and official minutes, ensuring accuracy and traceability.</p> <p>The service is sized and offered per GPU. Each GPU consists of one NVIDIA H200 partition.</p>"},{"location":"PaaS/#features-and-advantages_30","title":"Features and Advantages","text":"<p>This is a Whisper-based service that provides an API layer and an SDK for integration with existing applications. All tasks are represented as a sequence of tokens that the model predicts, unifying and optimizing the speech processing pipeline.</p> <p>The service offers the following main features:</p> <ul> <li>Automatic Speech Recognition (ASR) \u2192 converts speech to text in real time or from audio files (WAV, MP3, MP4, FLAC, etc.). Multilingual support. Advanced Neural Accuracy \u2192 uses sequence-to-sequence Transformer models, trained for a wide range of speech processing tasks, such as multilingual speech recognition, speech translation, and language identification.</li> <li>Multilingual Recognition and Machine Translation</li> <li>Real-time Transcription (Streaming) Batch Processing</li> <li>Temporal Segmentation \u2192 returns start/end timestamps to synchronize text and audio (useful for subtitles or editing).</li> <li>Text Cleanup and Normalization \u2192 automatically corrects punctuation, capitalization, and formatting.</li> <li>Accent and Ambient Noise Support \u2192 is robust against background noise, poor microphones, and natural (non-studio) speech.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Whisper engine (ASR Core) \u2192 transformer neural model trained on millions of hours of audio-text data.</li> <li>Language detection module \u2192 automatically identifies the language of the speech.</li> <li>Post-processing &amp; text normalization \u2192 corrects the transcription, inserts punctuation, and adds consistent formatting.</li> <li>Optional translation layer \u2192 uses a Neural Machine Translation (NMT) model to translate the transcription into another language. </li> <li>Storage and logging \u2192 stores results, metadata, and logs for auditing and analysis. </li> <li>Integration layer (API / SDK) \u2192 interface for external apps, dashboards, or AI pipelines.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced operating costs \u2192 automate the transcription of audio, meetings, interviews, and minutes without requiring dedicated staff.</li> <li>Increased staff productivity \u2192 automatic transcription saves hours of work.</li> <li>Accelerated document processes \u2192 minutes, interviews, meetings, or consultations can be transcribed and distributed in real time, improving administrative efficiency.</li> <li>Accessibility and inclusion \u2192 generate subtitles and text from audio/video content, improving accessibility for people with hearing impairments and multilingual communication.</li> <li>Data-driven decisions (Voice Analytics) \u2192 voice transcriptions become analyzeable text data, supporting data-driven decisions.</li> <li>Improved customer experience \u2192 chatbots, contact centers, and digital assistants become more effective by recognizing voice and responding naturally.</li> <li>High linguistic accuracy \u2192 the service, based on Transformer architecture, guarantees more precise transcriptions even in the presence of accents, noise, or natural speech.</li> <li>Structured and interoperable output \u2192 output in standard formats (JSON, TXT, SRT, VTT, DOCX) easily integrated with databases or document workflows.</li> <li>Model updates \u2192 managed and ongoing model updates, improving accuracy and reducing errors over time.</li> <li>High performance and low latency \u2192 processing in milliseconds for live streams, seconds for large files.</li> <li>Multimodal AI support \u2192 can be combined with Text Analytics, Translation, and Text-to-Speech services to create complete speech pipelines (e.g., transcription + translation + synthesis).</li> <li>Service scalability \u2192 allows you to simultaneously manage thousands of speech streams by providing and managing the necessary infrastructure.</li> </ul> <p></p>"},{"location":"PaaS/#ai-audio-video-analytics","title":"AI Audio &amp; Video Analytics","text":"<p> AI Audio &amp; Video Analytics Services </p>"},{"location":"PaaS/#services-description","title":"Services Description","text":"<p>These are two services, separate but integrable when necessary, developed by Leonardo.</p> <p>The AI Audio Analytics PaaS provides a ready-to-use platform that, thanks to AI-based algorithms on audio sources, allows the identification of unique features from audio streams using preloaded AI models. These features allow the identification of a person's voice, noises, and possible anomalies in the monitored environment.  </p> <p>The AI Video Analytics PaaS is a ready-to-use platform with pre-trained algorithms that leverage computer vision techniques, capable of processing and understanding visual information present in two-dimensional images or video sequences.</p> <p>The Audio and Video analytics services are sized and offered for GPU unit, specifically:</p> <ul> <li>for audio analytics: 1 partition H200 GPU per unit</li> <li>for video analytics: 1 H200 GPU per unit</li> </ul>"},{"location":"PaaS/#features-and-advantages_31","title":"Features and Advantages","text":"<p>The AI \u200b\u200bAudio Analytics platform can work with signals produced in the field from various audio sources, overcoming the \"curse of dimensionality\" problem caused by the high-dimensionality of the phenomenon through the use of unsupervised and supervised approaches. These approaches dynamically identify an optimal set of features to identify similarities between signals for the same event/process and differences between signals for different events/processes. The output of these processes can then be treated as characteristics in statistical detection methods, but they rely heavily on the analyst's understanding of a possible link between the signal and the process/event being detected. The AI \u200b\u200bAudio Analytics solution is primarily composed of the following tools: - Swagger UI \u2192 a collection of HTML, CSS, and JavaScript assets automatically generated from the documentation, which must comply with the OpenAPI standard. - ML models \u2192 algorithms for extracting information from audio sources for:     - Speaker identification: an ML model capable of identifying the speaker using voice characteristics.     - Audio anomaly insight: an ML model capable of detecting sound anomalies in production or cyclical systems.     - Environment classification: an ML model capable of identifying and classifying audio tracks. - FastAPI framework \u2192 a modern, fast (high-performance) web framework for building APIs with Python.</p> <p>The AI \u200b\u200bVideo Analytics platform includes subsystems: preprocessing, image analysis, and image interpretation. The service can perform video analysis while optimizing computation time through the use of single-pass convoluted networks, which analyze all parts of the image in parallel and simultaneously, eliminating the need for sliding windows. The AI \u200b\u200bVideo Analytics solution is primarily composed of the following tools: - ML models \u2192 algorithms for extracting information from video sources.     - Object detector: recognizes and locates people and objects within a given frame by extracting metadata containing classification and spatial location     - Spacial counter: an extension of the Object Detector model, it can also process a single-shot counting for each object class for each frame     - Object counter: capable of both locating people and objects and obtaining a count of the detected objects.</p> <p>The service offers the following advantages:</p> <ul> <li>Improved security and compliance \u2192 automatic detection of anomalous behavior, intrusions, or risky situations. Support for compliance policies and audits based on video/audio evidence.</li> <li>Improved customer experience \u2192 analysis of tone of voice, emotions, and wait times for improved quality of service and customer interactions.</li> <li>Reduced operating costs \u2192 automated continuous monitoring of environments, processes, and media flows, resulting in optimized human resources and response times.</li> <li>Data-driven decisions \u2192 media content becomes a source of structured and analyzable data for visual and audio insights that can be integrated into Business Intelligence systems.</li> <li>Innovation and new business models \u2192 enable new services such as retail analytics, behavioral marketing, intelligent security, and event monitoring for competitive advantage and market differentiation.</li> <li>Scalability and simplified management \u2192 management of resources, workloads, and updates.</li> <li>Integrated advanced analytics \u2192 ready-to-use features, e.g. Facial recognition, object detection, speech-to-text, voice sentiment, anomaly detection.</li> <li>Real-time and batch processing \u2192 analysis of live streams or recorded media archives, thanks to the integration of Processing PaaS.</li> <li>Multi-format and multi-source support \u2192 compatibility with various formats (MP4, AVI, WAV, RTSP, etc.) and heterogeneous devices (cameras, microphones, sensors).</li> <li>Integrated security and privacy \u2192 stream encryption, access control.</li> <li>Operational monitoring and insights.</li> </ul> <p></p>"},{"location":"PaaS/#optical-character-recognition-ocr","title":"Optical Character Recognition (OCR)","text":"<p> Optical Character Recognition (OCR) Service </p>"},{"location":"PaaS/#services-description_1","title":"Services Description","text":"<p>The services offer innovative computer vision capabilities, enabling the transformation of visual content containing text into processable digital content. It is useful for analyzing images, reading text, and detecting faces with predefined image tagging, text extraction with Optical Character Recognition (OCR), and responsible facial recognition. The OCR component (reading printed or handwritten text) is integrated as a REST API or client library that allows you to send images/documents and obtain text extraction from them. It is useful in multiple scenarios: automatic text extraction from images and vice versa, document processing (e.g., scanning PDFs, form images, extracting written or printed text), and process automation (e.g., data acquisition from forms, invoices, intelligent archiving, full-text search in image content). The service is offered using open soource OCR technologies with container-based sizing. Each container consists of 16 GB of RAM.</p>"},{"location":"PaaS/#features-and-advantages_32","title":"Features and Advantages","text":"<p>The main features of the service are:</p> <ul> <li>Text recognition \u2192 recognizes printed or written text in over 100 languages</li> <li>Multi-language models \u2192 can process mixed languages \u200b\u200b(e.g., English + numbers + symbols)</li> <li>Multiple image input \u2192 supports PNG, JPEG, TIFF, BMP, PDF (via external libraries such as pdfimages).</li> <li>Page layout analysis \u2192 recognizes text blocks, columns, paragraphs, direction, and orientation. Multiple output formats.</li> <li>Model training &amp; fine-tuning \u2192 ability to train models on specific fonts or languages \u200b\u200b(with dedicated datasets).</li> <li>Image enhancement \u2192 supports skew correction, binarization, thresholding, and deskewing.</li> </ul> <p>The main components of service are:</p> <ul> <li>API Layer \u2192 Exposes REST endpoints for loading images or URLs.</li> <li>Compute Layer \u2192 Runs the Tesseract engine in scalable containers.</li> <li>Storage Layer \u2192 Stores image input and text output.</li> <li>Processing Layer \u2192 OCR engine and image management.</li> <li>API Layer \u2192 Exposes REST endpoints for loading images or URLs.</li> <li>Monitoring &amp; Logging \u2192 Performance monitoring and call logging.</li> <li>Security Layer \u2192 API and data protection.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Lower document management costs \u2192 fewer staff dedicated to data entry and fewer errors that generate correction costs or disputes.</li> <li>Paperless transformation \u2192 enables the complete digitalization of archives and paper flows, reducing paper consumption and physical space.</li> <li>Faster and more traceable workflows \u2192 Scanned documents become immediately accessible data and can be integrated into management systems.</li> <li>Traceability and compliant archiving \u2192 Facilitates compliant digital archiving, improving compliance management (GDPR, electronic preservation).</li> <li>Extensive support \u2192 Native support for dozens of languages \u200b\u200band formats (e.g., PDF, JPEG, PNG, TIFF, scanned documents).</li> <li>Standard formats \u2192 The extracted text is immediately usable in management or analytics systems.</li> <li>Real-time and batch processing \u2192 Analysis of live streaming or recorded multimedia archives, thanks to the integration of Processing PaaS.</li> <li>Managed maintenance and updates \u2192 the infrastructure, security, and updates of AI models are managed.</li> </ul> <p></p>"},{"location":"PaaS/#text-analyticsnlp","title":"Text Analytics/NLP","text":"<p> Text Analytics Service </p>"},{"location":"PaaS/#service-description_31","title":"Service Description","text":"<p>The Text Analytics PaaS solution, developed by Leonardo, provides a ready-to-use NLP (Natural Language Processing) platform capable of extracting structured and interpretable information from unstructured texts, enabling quantitative and qualitative analyses that would be time-consuming and difficult to perform manually. The system can identify entities (people, places, organizations, etc.), translations, key concepts, and sentiment from text to identify and extract opinions from text. Multilingual support.</p> <p>The service is sized per unit of 1 partition H200 GPU.</p>"},{"location":"PaaS/#features-and-advantages_33","title":"Features and Advantages","text":"<p>The solution can perform various types of analysis, including:</p> <ul> <li>Entity Extraction (NER) \u2192 recognizes the names of people, companies, places, products, dates, etc.</li> <li>Sentiment analysis \u2192 understands whether the text expresses a positive, negative, or neutral opinion.</li> <li>Theme and Topic detection \u2192 identifies key concepts in the text.</li> <li>Language Detection \u2192 detects the language in which a text was written.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Swagger UI \u2192 Collection of HTML, CSS, and JavaScript assets automatically generated from the documentation, which must be compliant with the OpenAPI standard.</li> <li> <p>ML Models \u2192 List of ready-to-use pre-trained models, including:</p> <ul> <li>Key Phrase Extraction: extracts salient parts of text.</li> <li>Language Detection: infers language from text.</li> <li>Named Entity Recognition: extracts real-world entities from text, such as the names of people, places, data, companies, etc.</li> <li>Sentiment Analysis: recognizes sentiment from text.</li> </ul> </li> <li> <p>FastAPI Framework \u2192 Modern, fast (high-performance) web framework for building APIs with Python.  </p> </li> </ul> <p>Model creation workflow: 1. Data acquisition \u2192 obtains raw text data from various sources to create a robust dataset for NLP tasks. 2. Text preprocessing \u2192 includes several steps to refine the raw text data for meaningful analysis and model training (e.g., text cleaning) Text, tokenization, stopword removal, normalization). 3. Feature Engineering \u2192 transforms raw textual data into numerical features that machine learning models can understand and effectively use to capture semantic meaning, contextual information, and word relationships. 4. Modeling &amp; Evaluation \u2192 the heart of the pipeline, where models are applied and evaluated using various approaches (heuristics, ML, Deep Learning, etc.) to comprehensively measure model performance from both a technical and practical perspective. 5. Deployment \u2192 marks the transition of the developed model from the development environment to a production environment, followed by continuous monitoring and adaptation to ensure lasting performance and relevance.</p> <p>The service offers the following advantages:</p> <ul> <li>Better understanding for users and service consumers \u2192 analyzes feedback, reviews, chats, and surveys to extract sentiment.</li> <li>Data-driven decisions \u2192 transforms unstructured text into quantifiable insights that can be displayed in dashboards.</li> <li>Reduced operational costs \u2192 automates text comprehension, significantly reducing human overhead.</li> <li>Reduced operational costs \u2192 automates text comprehension, significantly reducing human overhead.</li> <li>Automation and scalability \u2192 analyzes large volumes of text from heterogeneous sources.</li> <li>Faster time to market \u2192 simple integration via API with third-party systems and applications.</li> <li>Multilingualism and semantic support \u2192 understands meanings, synonyms, and context (not just keywords).</li> </ul> <p></p>"},{"location":"PaaS/#translation","title":"Translation","text":""},{"location":"PaaS/#service-description_32","title":"Service Description","text":"<p>Developed by Leonardo using AI-based machine translation (NMT) technologies, the multilingual translation service to enable rapid and accurate translation of text from the source language to the target language in real time. The service draws inspiration from the human brain not only for its neural structure, but also for its ability to adapt, learn from new experiences, and interact with users. The result is a so-called human-in-the-loop approach, a cycle in which machine and human continuously support each other, providing exceptional translation quality and process efficiency that surpasses previous approaches. </p> <p>It is sized per GPU unit. Each unit consists of 1 NVIDIA H200 GPU.  </p>"},{"location":"PaaS/#features-and-advantages_34","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Neural Machine Translation (NMT) \u2192 uses deep neural networks for more natural and contextual translations than statistical models.  </li> <li>Real-time translation \u2192 streaming translation for chat, call centers, multilingual apps, or conferences.  </li> <li>Document translation \u2192 translation of complete files (DOCX, PDF, TXT, HTML, etc.) while maintaining layout and formatting.  </li> <li>Custom translation \u2192 training of custom AI models with glossaries and datasets specific to the industry or company.  </li> <li>Automatic language recognition \u2192 automatically detects the source language before translation.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Translator REST API \u2192 main endpoint for sending text, receiving translations, or metadata (languages, glossaries).</li> <li>AI NMT Engine \u2192 proprietary neural engine based on Transformer networks (similar to GPT) for contextual translations.</li> <li>Custom Translator \u2192 portal + API for training models with custom datasets.</li> <li>Document translation API \u2192 service dedicated to batch file translation (integration with Blob Storage).</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>International expansion \u2192 allows you to easily communicate with customers, suppliers, and citizens of different languages, enabling access to new markets or linguistic communities.</li> <li>Reduced translation time and costs \u2192 automates the translation of texts, documents, and communications, reducing reliance on human translators and accelerating publication workflows.</li> <li>Multilingual process automation \u2192 integrates translation directly into digital processes, eliminating manual tasks and downtime.</li> <li>Improved access to information and knowledge \u2192 International content (reports, technical documents, studies) becomes immediately accessible in local languages.</li> <li>Accuracy thanks to neural translation models (NMT) \u2192 Neural translation engines understand context and produce more natural-sounding texts than older statistical models.</li> <li>Multiformat support \u2192 automatic translation of texts, documents (PDF, DOCX, HTML), and data streams in real time.</li> <li>Linguistic customization \u2192 ability to train custom models with glossaries or corporate terminologies for more consistent translations.</li> <li>AI Model Updates \u2192 Constantly updating the included neural models, improving accuracy and language support without manual intervention.</li> </ul> <p></p>"},{"location":"PaaS/#ai-search-rag","title":"AI Search - RAG","text":"<p> AI Search - RAG Service </p>"},{"location":"PaaS/#service-description_33","title":"Service Description","text":"<p>AI Search-RAG is a system developed by Leonardo for automatically generating answers to user-generated questions using context and information from reliable data sources. It can be integrated into environments requiring a virtual assistant capable of responding using reliable, contextualized information. The system generates answers by first searching for relevant information or passages from a reliable external knowledge base using AGENTIC RAG (Retrieval-Augmented Generation) techniques. This service allows for better contextualization of the search, further improving the quality and accuracy of the generated answers compared to traditional text-based RAGs. AI Search allows individuals and organizations to quickly access relevant, contextualized information through a simple and intuitive graphical interface built on a chat model, improving efficiency and productivity through advanced intelligent search tools.</p> <p>The service is sized per GPU unit. Each unit consists of one NVIDIA H200 GPU.</p>"},{"location":"PaaS/#features-and-advantages_35","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Activation of the Big Data PaaS Data Lake service \u2192 to meet object storage needs.</li> <li>Use of appropriately optimized Large Language Models and Embeddings \u2192 to provide value to specific contexts and for specific users.</li> <li>User authentication \u2192 integrates with existing security protocols. Understands natural language \u2192 provides coherent and complete answers, retrieving multimodal information from knowledge expressed as text and audio. Supports multilingual models</li> <li>Feedback collection \u2192 after a query is resolved, AI Search collects user feedback</li> <li>Document segmentation by user</li> </ul> <p>The main components of the service are:</p> <ul> <li>Model Repository \u2192 at a minimum, a virtual assistant and an embedding model are required.</li> <li>Vector Database and Search Engine \u2192 it uses a vector database that stores vector representations (embeddings) of the input data, allowing documents and information to be retrieved based on their meaning (semantic search). It also uses a traditional search engine (lexical search) that operates on text and metadata, performing searches based on keywords and structured criteria (e.g., BM25, FT-IDF).</li> <li> <p>Document Manager \u2192 responsible for retrieving documentation from a specific repository and indexing it in the vector database for use in user queries. AI Search is composed of three layers:</p> </li> <li> <p>Data layer \u2192 represents the database and the primary source of information.</p> </li> <li>Analysis layer \u2192 responsible for all processing, analysis, and generation of answers to user queries. It includes the Retriever and the Generator, responsible for retrieving the most relevant information and creating coherent and personalized responses, respectively.</li> <li>User layer \u2192 interface through which the user interacts directly with the service, offering the ability to query the knowledge base, view answers with referenced sources, manage documents, and provide feedback.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Access to up-to-date knowledge \u2192 answers always based on the most recent internal and external documents.</li> <li>Reduced operational costs \u2192 less time spent on manual searches and repetitive support.</li> <li>Improved customer/employee experience \u2192 relevant, clear, personalized answers.</li> <li>Increased competitiveness \u2192 leverages proprietary knowledge, not just public knowledge.</li> <li>Risk mitigation \u2192 reduces errors and hallucinations, increasing the relevance of output to user questions.</li> <li>Upgradability without retraining \u2192 simply update the database/document repository, not the LLM.</li> <li>Hybrid vector search \u2192 combines semantic search with traditional text search.</li> <li>Model efficiency \u2192 LLM-based host model oversees activities and decisions and supervises other, simpler agents (LLM).</li> <li>Traceability and transparency \u2192 sources cited to support the answer can be displayed.</li> <li>Bias reduction \u2192 thanks to the indexing of the text on a vector DB, the LLM conductor will receive as input a context relevant to the questions asked by the users.</li> </ul> <p></p>"},{"location":"PaaS/#ai-platform","title":"AI Platform","text":"<p> AI Platform Service </p>"},{"location":"PaaS/#service-description_34","title":"Service Description","text":"<p>The AI \u200b\u200bPlatform PaaS service, developed by Leonardo, uses AI technologies (machine learning and deep learning) to provide domain experts (data scientists, data analysts, and AI engineers) with a collaborative platform to create, track, use, and monitor ML models simply and intuitively, yet reliably and efficiently. The service provides a ready-to-use platform capable of easily managing the entire lifecycle of ML models. The solution is certified, managed, and maintained by the provider. The platform can be enhanced using, in addition to the Data Lake service, other technologies made available by the Big Data PaaS. The services are designed to ensure digital sovereignty through deployment on secure national infrastructure, with a particular focus on latency and optimization of computational resources.</p> <p>The service is sized per unit of 1 GPU H200.</p>"},{"location":"PaaS/#features-and-advantages_36","title":"Features and Advantages","text":"<p>The platform is capable of managing the lifecycle of ML models through the following phases:</p> <ul> <li>Data processing \u2192 which will be optimized if the Big Data PaaS Data Governance and Processing Engine services are activated for the extraction, transformation, and loading of datasets into the AI \u200b\u200bPlatform.</li> <li>Model training and evaluation process \u2192 through a JupyterLab on the AI \u200b\u200bplatform. - Model tracking and saving process. </li> <li>Model management process \u2192 through the model registry provided by the MLOps tool.</li> <li>Model serving process \u2192 for the creation of Docker images ready for deployment on any target system. These can be tested directly on the platform through the swagger describing the inference service.</li> </ul> <p>The solution is primarily composed of the following custom tools:</p> <ul> <li>JupyterLab \u2192 allows the creation and sharing of web scripts in JSON format using a Notebook, which follow a schema and an ordered list of input/output cells. The created Jupyter documents can be exported as HTML, PDF, Markdown, or Python documents.</li> <li> <p>Mlflow \u2192 allows for the lifecycle management of ML models. It simplifies the complex procedures for implementing machine learning. Consisting of:</p> <ul> <li>MLflow Tracking: records and tracks metrics and artifacts (models plus their dependencies) of the training process.</li> <li>MLflow Model Registry: stores models in a centralized registry to collaboratively manage the entire model lifecycle.</li> <li>DBMS Metadata: stores all metadata in a relational database to track all development flows of a given ML model.</li> <li>Object Storage: stores all developed models and their dependencies to facilitate the subsequent model serving process in production.</li> </ul> </li> <li> <p>Model Serving \u2192 facilitates the deployment of ML models at scale in production environments through the creation of Docker images.</p> </li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced initial and operational costs \u2192 there is no need to invest in hardware infrastructure (GPU, cluster, server, storage, etc.), thus reducing maintenance, upgrade, and security costs.</li> <li>Scalability \u2192 the service can scale compute and storage resources based on model complexity or data volume.</li> <li>Faster time to market \u2192 models can be developed, tested, and deployed much faster thanks to pre-built tools and pipelines.</li> <li>Focus on business value \u2192 domain experts can focus on model research and development, increasing team productivity and efficiency.</li> <li>Easy integration with other services \u2192 trained models can be quickly integrated with other services (API management, Business Intelligence, Data Lake, etc.) to create complete AI-driven solutions.</li> <li>Automated model lifecycle management \u2192 native MLOps support for model versioning, performance monitoring, and automatic retraining.</li> <li>Managed and optimized environment \u2192 the execution environment is preconfigured with ML libraries, with security updates and patches managed by the provider.</li> <li>Integrated monitoring and logging \u2192 training metrics, logs, and results are tracked to easily diagnose convergence or overfitting issues.</li> <li>Simplified deployment \u2192 creating Docker images for model inference allows for simplified deployment to any target system.</li> </ul> <p></p>"},{"location":"PaaS/#ai-slmllm","title":"AI SLM/LLM","text":"<p> AI SLM/LLM Services </p>"},{"location":"PaaS/#services-description_2","title":"Services Description","text":"<p>These are Generative AI PaaS developed by Leonardo that provide optimized linguistic inference capabilities. They use predefined linguistic models to understand and generate natural text. They allow the use of two types of linguistic models:</p> <ul> <li>Small Language Model (SLM): small-scale linguistic models that are lighter, more efficient, and specialized in specific domains, offering fast and precise solutions for everyday linguistic needs.</li> <li>Large Language Model (LLM): linguistic models with numerous parameters for extremely high linguistic comprehension and generation capabilities, ideal for complex interactions, virtual assistants, semantic search, and automation. SLMs are suitable for performing specific, less complex applications and tasks (e.g., text autocompletion, short sentence translation, and text classification), where an LLM would be too computationally expensive.</li> </ul> <p>The services are sized per GPU unit:</p> <ul> <li>for AI SLM service each unit consists of 1 partition NVIDIA H200 GPU.</li> <li>for AI LLM service each unit consists of 1 NVIDIA H200 GPUs.</li> </ul>"},{"location":"PaaS/#features-and-advantages_37","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Tenant isolation \u2192 each customer will have a dedicated Tenant on the PSN infrastructure with complete isolation of data, configurations, and uploaded models.</li> <li>Resource allocation \u2192 each customer will be assigned dedicated infrastructure resources (CPU, GPU, RAM, Storage) to their Tenant, sized appropriately.</li> <li>Auto-scaling \u2192 tenant resources can scale to respond to load variations.</li> <li>Cloud-native deployment \u2192 the service will be deployed in the customer's tenant in cloud-native mode on the OpenShift platform, ensuring portability, resilience, and standardization of operating procedures.</li> <li>Centralized observability \u2192 provides centralized platform monitoring services with log collection, metrics, and alerting for complete observability, audit trails, and advanced troubleshooting.</li> <li>PaaS integration \u2192 uses PSN PaaS components for storage, networking, security, and identity management, ensuring compliance with project requirements and leveraging the economies of scale of shared infrastructure.</li> </ul> <p>Both services feature a modular architecture designed to ensure scalability, flow segregation, and ease of integration into public administration processes.</p> <ul> <li>API Layer \u2192 provides access to SLM/LLM services through two main methods: REST API calls for integration with existing systems, or through a Web UI for direct, user-friendly interaction.</li> <li>Inference layer \u2192 this is the heart of the service, where SLM/LLM models reside and execute. It consists of:</li> <li>Inference engine \u2192 runs language models optimized for latency and GPU/CPU resource consumption.</li> <li>Model pool management \u2192 maintains a set of validated and pre-configured models, selectable by the customer. Only one model is active per tenant at any time.</li> <li>Platform layer \u2192 provides cross-functional support services and includes: Resource Management &amp; Scaling: Dynamic allocation of computational resources (CPU, GPU, RAM, storage), load-based auto-scaling, and service lifecycle management.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Technological accessibility \u2192 access to no-code Generative AI technology solutions.</li> <li>Reduced operating costs \u2192 no upfront investment in hardware infrastructure or proprietary models.</li> <li>Faster time to market \u2192 easier models to integrate into business solutions.</li> <li>Operational efficiency \u2192 automate repetitive tasks, reducing processing times and improving service quality.</li> <li>Flexible adoption \u2192 choose between SLM (small, specialized models) or LLM (generalist models with broader knowledge capabilities) depending on the use case.</li> <li>Risk mitigation \u2192 leverage pre-trained and validated models without the need for specialized ML skills.</li> <li>Easy integration with existing systems \u2192 orchestrate complex processes through microservices and integrated ML pipelines.</li> <li>Performance optimization \u2192 PaaS allows you to combine both advantages: use SLM for simple, targeted tasks, while LLM is used only for tasks that require broader, more generalized linguistic understanding.</li> <li>Fast and simplified model testing \u2192 ready-to-use models thanks to the playground functionality available directly in the interface. - Rapid prototyping and DevOps AI \u2192 ready-to-use environment for developing, testing, and deploying applications through standard interfaces.</li> <li>Multi-model and hybrid AI \u2192 ability to combine open source and proprietary models in the same ecosystem.</li> </ul>"},{"location":"PaaS/#collaboration-family","title":"Collaboration Family","text":"<p>Below is the list of services belonging to the Collaboration family:</p> <ul> <li>Instant Messaging</li> </ul> <p></p>"},{"location":"PaaS/#instant-messaging","title":"Instant Messaging","text":"<p> Instant Messaging Service </p>"},{"location":"PaaS/#service-description_35","title":"Service Description","text":"<p>It is a messaging and collaboration platform based on the Mattermost solution that offers secure tools for team communication, file sharing, and integration with other applications, supporting productivity in distributed work environments. It allows you to organize all team communications in one place via channels. In addition to standard messaging, channels support automation, slash commands, bot integrations, code snippets, and more. Suitable for environments with high security, privacy, and control requirements. It supports multi-factor authentication, Active Directory, LDAP, SSO, and more. The platform can be customized and extended by integrating it with the tools your team uses daily.</p> <p>The service is offered with the following unit metric: 1000 users.</p>"},{"location":"PaaS/#features-and-advantages_38","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Playbooks \u2192 playbooks allow you to orchestrate work across tools and teams. They are prescribed workflows that support specific digital operations scenarios.</li> <li>Audio calls \u2192 it offers native audio calls on channels.</li> <li>Integrations and customizations \u2192 support for slash commands, bots, and inbound and outbound webhooks; extensive ecosystem of plugins and integrations; extensive APIs for extending functionality or building custom applications.</li> <li>Accessibility \u2192 cross-platform clients (web, desktop, mobile); Deployable behind firewalls/in private, air-gapped environments.</li> <li>Security, Privacy, and Governance \u2192 support for: encryption (in transit, at rest); Access control (Single Sign-On MFA, granular roles and permissions); Governance, privacy, and compliance; Zero Trust policy.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Backend server \u2192 can use MySQL or PostgreSQL as a database) that hosts messages, users, and files.</li> <li>Storage for file attachments, images, etc. \u2192 can be local or cloud-based (S3, MinIO, etc.).</li> <li>WebSocket channels \u2192 for real-time message transmission.</li> <li>Configurable for scalability \u2192 cluster support, high availability, deployment on Kubernetes, isolated networks.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Complete data control \u2192 useful for regulated sectors (finance, public administration, healthcare).</li> <li>Reduced lock-in \u2192 open source/source-available, no dependency on proprietary vendors.</li> <li>Compliance and governance \u2192 audit trail, retention policy, exports for legal and regulatory controls</li> <li>Support for secure remote working \u2192 mobile/desktop access with encryption and strong authentication.</li> <li>Adaptable to different sectors (legal, manufacturing, public administration, tech) thanks to customization options.</li> <li>Extensive APIs and plugins \u2192 extensive integration options with DevOps, CI/CD, ticketing, monitoring.</li> <li>Advanced security \u2192 SSO (SAML, LDAP, OIDC), MFA, encryption in transit and at rest Scalability \u2192 clustering, load balancing, support for enterprise and mission-critical environments.</li> </ul>"},{"location":"PaaS/#database-family","title":"Database Family","text":"<p>Below is the list of services belonging to the Database family:</p> <ul> <li>PaaS SQL - PostgreSQL</li> <li>PaaS SQL - MariaDB</li> <li>PaaS SQL - MS SQL Server EE</li> <li>PaaS SQL - MS SQL Server EE (BYOL)</li> <li>PaaS GraphDB</li> <li>PaaS NoSQL - MongoDB</li> <li>PaaS In Memory - Redis</li> </ul> <p></p>"},{"location":"PaaS/#paas-sql-postgresql","title":"PaaS SQL - PostgreSQL","text":"<p> PostgreSQL client interface </p>"},{"location":"PaaS/#service-description_36","title":"Service Description","text":"<p>The PaaS SQL \u2013 PostgreSQL is a cloud-based managed platform that provides ready-to-use PostgreSQL database instances without requiring the user to install, configure, or maintain the underlying infrastructure. In essence, it delivers PostgreSQL \u201cas a service\u201d, allowing developers and organizations to focus on application development and data management instead of database administration. PostgreSQL in a highly available configuration is a reliable solution for organizations seeking an open source database with performance, security, and scalability. This service is ideal for applications that require reliability without the costs of commercial database solutions.  </p> <p>The service could be used to:</p> <ul> <li>Host and manage relational databases in the cloud.</li> <li>Store and query structured data efficiently.</li> <li>Support applications that need high availability, scalability, and data integrity.</li> <li>Simplify DevOps workflows by automating database management tasks.</li> <li>Integrate easily with other cloud services (analytics, AI, APIs, etc.).</li> </ul> <p>The service is offered per DB instance. Each instance with replication consists of: </p> <ul> <li>4 vCPUs</li> <li>16 GB of RAM</li> </ul>"},{"location":"PaaS/#features-and-advantages_39","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Fully managed service \u2192 semplify provisioning, configuration, patching, and upgrades.</li> <li>Scalability \u2192 vertical and horizontal scaling of compute and storage resources as needed.</li> <li>High availability and reliability \u2192 built-in replication, automatic failover, and multi-zone deployment options.</li> <li>Backup and recovery \u2192 automated backups, point-in-time restore, and disaster recovery capabilities.</li> <li>Security and compliance \u2192 data encryption (in transit and at rest), identity and access management (IAM), network isolation (VPC/Private Link), and compliance certifications (e.g., GDPR, ISO, SOC).</li> <li>Performance optimization \u2192 query optimization, connection pooling, caching, and monitoring tools.</li> <li>Monitoring and alerting \u2192 integration with dashboards and metrics (CPU, memory, I/O, query performance). Integration and extensibility \u2192 compatible with PostgreSQL extensions (e.g., PostGIS, pg_partman, pg_stat_statements). API and CLI tools for management and automation.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Control Plane \u2192 it is the part of the service that manages the lifecycle and orchestration of database instance. Composed by: API, provisioning, configuration, monitoring</li> <li>Data Plane  \u2192 it is the layer where PostgreSQL instances actually run. Each instance can be isolated in a VM, container, or pod, depending on the implementation</li> <li>HA &amp; Resilience \u2192 it ensures that the service remains available even in the event of hardware or software failures. It implements replications, failovers and backups policies.</li> <li>Security layer \u2192 it ensures data protection and access control for respecting of the protection &amp; compliance policies: authN/AuthZ, encryption, firewalls, auditing</li> <li>Observability Layer \u2192 It provides visibility and continuous management of the service, offrering monitoring &amp; operations like metrics, logging, auto-patching.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Cost Efficiency \u2192 no hardware or infrastructure investment. Reduced operational costs: no need for DBA teams to handle maintenance, patching, or scaling manually.</li> <li>Faster Time-to-Market \u2192 database instances can be provisioned quickly through a web interface or API. Ideal for rapid development, prototyping, and product launches. Reduces dependency on infrastructure provisioning cycles.</li> <li>Business agility and scalability \u2192 elastic scaling of resources (CPU, RAM, storage) without downtime. Easily adapts to varying workloads and seasonal demand. Enables agile business models, including microservices and cloud-native architectures.</li> <li>Increased reliability and availability \u2192 High Availability (HA) and automated failover mechanisms ensure continuous uptime. Built-in replication and backup policies protect against data loss. Improves business continuity and reduces downtime risk.</li> <li>Focus on Core Business \u2192 the organization focuses on application development and innovation, not on database administration. Simplifies the technology stack and reduces management overhead.</li> <li>Compliance and Risk Reduction \u2192 the service provider ensures security, patching, and compliance with standards. Reduces risk of configuration errors or unpatched vulnerabilities.</li> <li>Standardization and portability \u2192 based on open-source PostgreSQL, ensuring compatibility and avoiding vendor lock-in. Databases can be exported or migrated easily to other PostgreSQL environments. Supports extensions and features like PostGIS, JSONB, and logical replication.</li> </ul> <p></p>"},{"location":"PaaS/#paas-sql-mariadb","title":"PaaS SQL - MariaDB","text":"<p> MariaDB client interface </p>"},{"location":"PaaS/#service-description_37","title":"Service Description","text":"<p>The PaaS SQL \u2013 MariaDB is a managed Database-as-a-Service (DBaaS) offering that provides fully managed MariaDB database instances in the cloud. It abstracts away the complexity of infrastructure, deployment, and database administration, allowing users to focus on application development rather than operational maintenance. The service handles provisioning, configuration, patching, backups, scaling, monitoring, and high availability of MariaDB databases. The PaaS SQL \u2013 MariaDB service is designed to support:</p> <ul> <li>Web applications and enterprise systems that require a relational SQL database.</li> <li>Developers who need quick and consistent access to production-ready databases without managing servers.</li> <li>Organizations aiming to reduce database maintenance overhead and improve performance, reliability, and security.</li> </ul> <p>Typical use cases:</p> <ul> <li>Backend databases for web portals, CMS, ERP, CRM, or e-commerce systems.</li> <li>Data storage for microservices or APIs.</li> <li>Development and testing environments.</li> <li>Data analytics and reporting using SQL queries.</li> </ul> <p>The service is offered per DB instance. Each instance with replication consists of: </p> <ul> <li>4 vCPUs</li> <li>16 GB of RAM</li> </ul>"},{"location":"PaaS/#features-and-advantages_40","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Fully managed lifecycle \u2192 automated provisioning, configuration, updates, and patching. Backups and restores scheduled and managed by the platform. Monitoring and alerting for performance and availability.</li> <li>High availability &amp; reliability \u2192 native MariaDB replication for redundancy. Automatic failover between primary and replica nodes in case of failure. Point-In-Time Recovery (PITR) for data protection. Backups stored on redundant storage systems.</li> <li>Scalability \u2192 vertical scaling: increase CPU, memory, or storage capacity dynamically. Horizontal scaling: optional read replicas for load distribution. Elastic scaling with minimal downtime.</li> <li>Security \u2192 data encryption at rest and in transit (SSL/TLS). Authentication and authorization with role-based access control. Network isolation via virtual private networks (VPC/VNet). Audit logging for security and compliance.</li> <li>Performance optimization \u2192 built-in query optimization and caching. Configurable parameters (buffers, thread pools) based on service tiers. SSD-backed storage for low-latency I/O. Connection pooling and resource limits to prevent overload.</li> <li>Monitoring and integration \u2192 real-time metrics and dashboards (CPU, I/O, connections, slow queries). Integration with external tools like Prometheus, Grafana, or APM systems. REST API and CLI for automation and DevOps pipelines.</li> </ul> <p>The PaaS SQL MariaDB service is organized into multiple logical layers, each responsible for specific functions within the system.</p> <ul> <li>Control plane (Management Layer) \u2192 this layer manages the lifecycle and orchestration of MariaDB instances.</li> <li>Data Plane (Execution Layer) \u2192 this layer hosts and executes the actual MariaDB database workloads.</li> <li>HA &amp; resilience layer \u2192 ensures fault tolerance and continuity of service.</li> <li>Security &amp; Access layer \u2192 provides protection, compliance, and controlled access.</li> <li>Observability &amp; operations layer \u2192 provides visibility, maintenance, and automation tools for both provider and customer.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Cost efficiency \u2192 no hardware or infrastructure investment. Reduced operational costs: no need for DBA teams to handle maintenance, patching, or scaling manually.</li> <li>Faster Time-to-Market \u2192 database instances can be provisioned quickly through a web interface or API. Ideal for rapid development, prototyping, and product launches. Reduces dependency on infrastructure provisioning cycles.</li> <li>Business agility and scalability \u2192 elastic scaling of resources (CPU, RAM, storage) without downtime. Easily adapts to varying workloads and seasonal demand. Enables agile business models, including microservices and cloud-native architectures.</li> <li>Increased reliability and availability \u2192 High Availability (HA) and automated failover mechanisms ensure continuous uptime. Built-in replication and backup policies protect against data loss. Improves business continuity and reduces downtime risk.</li> <li>Focus on core business \u2192 the organization focuses on application development and innovation, not on database administration. Simplifies the technology stack and reduces management overhead.</li> <li>Compliance and risk reduction \u2192 the service provider ensures security, patching, and compliance with standards. Reduces risk of configuration errors or unpatched vulnerabilities.</li> <li>Standardization and portability \u2192 based on open-source PostgreSQL, ensuring compatibility and avoiding vendor lock-in. Databases can be exported or migrated easily to other MariaDB environments.</li> </ul> <p></p>"},{"location":"PaaS/#paas-sql-ms-sql-server-ee","title":"PaaS SQL - MS SQL Server EE","text":"<p> SQL Server EE client interface </p>"},{"location":"PaaS/#service-description_38","title":"Service Description","text":"<p>The PaaS SQL \u2013 Microsoft SQL Server Enterprise Edition (EE) service is a fully managed relational database platform that delivers the capabilities of Microsoft SQL Server EE in a cloud-based, Platform-as-a-Service (PaaS) model. It provides users with dedicated or shared SQL Server instances, managed and operated by the service provider, while abstracting away all infrastructure management tasks such as provisioning, patching, scaling, backup, and high availability. The service offers enterprise-grade database performance, security, and resilience, optimized for mission-critical workloads and advanced analytics. This service is designed to support enterprise and business-critical applications that require reliable, scalable, and high-performance SQL database functionality without the operational overhead of managing on-premises infrastructure. Typical use cases include:</p> <ul> <li>Core enterprise systems (ERP, CRM, SCM).</li> <li>Business intelligence (BI) and data warehousing workloads.</li> <li>Transactional applications (OLTP) and mixed OLAP/OLTP environments.</li> <li>Data integration and analytics pipelines using SQL Server Integration Services (SSIS) or Analysis Services (SSAS).</li> <li>Applications requiring high availability, disaster recovery, and compliance assurance.</li> </ul> <p>The service is offered per DB instance. Each instance consists of: </p> <ul> <li>8 vCPUs</li> <li>16 GB of RAM</li> </ul>"},{"location":"PaaS/#features-and-advantages_41","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Fully managed service \u2192 managing of provisioning, patching, configuration, version upgrades, monitoring, maintenance, and optimization. Integration with management portals and APIs for self-service database operations.</li> <li>High availability and disaster recovery \u2192 always on Availability Groups (AG) for real-time replication and automatic failover. Built-in geo-replication and multi-zone deployment for business continuity Point-In-Time Restore (PITR) from continuous transaction log backups.</li> <li>Scalability and elasticity \u2192 vertical scaling: adjust compute, memory, and storage resources dynamically. Read replicas: enable workload offloading for reporting or analytics. Elastic pools for cost-effective management of multiple databases with variable load patterns.</li> <li>Enterprise performance and optimization \u2192 advanced query optimization via Query Store, Adaptive Query Processing, and Columnstore Indexes. In-Memory OLTP and Buffer Pool Extension for high-performance transactions. SSD or NVMe-backed storage for low-latency I/O. Intelligent workload tuning and automatic statistics maintenance.</li> <li>Security and compliance \u2192  Transparent Data Encryption (TDE) and always encrypted. Integration with Active Directory (AD) and Azure AD for identity and role management. Row-Level Security, Dynamic Data Masking, and Auditing. Compliance with cyber security standards.</li> <li>Analytics and integration \u2192 support for SQL Server Analysis Services (SSAS) for OLAP cubes and data modeling. SQL Server Integration Services (SSIS) for ETL and data movement. SQL Server Reporting Services (SSRS) for enterprise reporting. Integration with Power BI, Azure Synapse, and other analytics ecosystems.</li> <li>Monitoring and automation \u2192 integrated dashboard and alerting system with real-time metrics on performance, connections, and query activity. Full API and CLI support for automation and DevOps integration. Logs and metrics exportable to external observability tools.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Control plane (Management layer) \u2192 it is responsible for orchestration, automation, and lifecycle management of SQL Server instances. Key Components: Management API / Portal, Provisioning engine, Configuration manager, Monitoring &amp; metrics collector, Billing &amp; subscription manager.</li> <li>Data plane (Execution layer) \u2192 it hosts the actual Microsoft SQL Server EE instances where user databases reside and operate. Key Components: SQL Server instances, Storage subsystem, Networking layer, Backup and recovery service.</li> <li>High Availability &amp; Resilience layer \u2192 ensures the database service remains available and fault-tolerant.  Key Components: Always On Availability Groups (AG), Failover controller, Geo-replication manager, Backup orchestrator.</li> <li>Security &amp; Access layer \u2192 provides protection, compliance, and controlled access to data and administrative functions. Key Components: Authentication &amp; authorization (integration with AD/Azure AD, support for MFA), Encryption Services (TDE, SSL/TLS, and Always Encrypted for data protection), Network Security.</li> <li>Observability &amp; Operations layer \u2192 ensures visibility, performance optimization, and operational maintenance. Key Components: Performance monitoring, Alerting &amp; incident management, Auto-patching System, Maintenance scheduler, Logging system.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced Total Cost of Ownership (TCO) \u2192 eliminates capital expenses for hardware, networking, and software licensing.</li> <li>Faster Time-to-Market \u2192 databases can be provisioned quickly. Preconfigured and optimized SQL Server templates accelerate development and deployment cycles. Ideal for agile, DevOps, and CI/CD environments where rapid iteration is required.</li> <li>Enterprise-grade reliability and availability \u2192 built on SQL Server Enterprise Edition features such as Always On Availability Groups and In-Memory OLTP. Ensures continuous service availability with automatic failover and disaster recovery. Meets strict SLA targets for uptime and data durability.</li> <li>Business agility and scalability \u2192 scale compute, memory, and storage resources up or down without downtime. Supports variable workloads \u2014 from transactional processing to analytics \u2014 under a single service model. Allows businesses to expand globally through geo-replication and multi-region deployments.</li> <li>Focus on core business Value \u2192 offloads infrastructure management and DBA operations to the service provider. Frees internal teams to focus on data strategy, analytics, and business intelligence. Accelerates digital transformation by integrating seamlessly with enterprise and cloud ecosystems (e.g., Power BI, Azure, SAP).</li> <li>Compliance and Governance \u2192 enterprise-grade auditing, encryption, and access control meet global compliance standards. Provider-managed patching and updates reduce security and compliance risks. Supports fine-grained access policies and role-based authorization for regulated industries.</li> </ul> <p></p>"},{"location":"PaaS/#paas-sql-ms-sql-server-ee-byol","title":"PaaS SQL - MS SQL Server EE (BYOL)","text":"<p> SQL Server EE client interface </p>"},{"location":"PaaS/#service-description_39","title":"Service Description","text":"<p>This service allows organizations to utilize their own licenses for MS SQL Server Enterprise Edition, reducing licensing costs while benefiting from fully managed and optimized management in the cloud.  </p> <p>For all the details , please refer to the PaaS SQL - MS SQL Server EE.</p> <p>The service is offered per DB instance. Each instance consists of: </p> <ul> <li>8 vCPUs</li> <li>16 GB of RAM</li> </ul>"},{"location":"PaaS/#features-and-advantages_42","title":"Features and Advantages","text":"<p>For all the details , please refer to the PaaS SQL - MS SQL Server EE.</p> <p></p>"},{"location":"PaaS/#paas-graphdb","title":"PaaS GraphDB","text":"<p> GraphDB client interface </p>"},{"location":"PaaS/#service-description_40","title":"Service Description","text":"<p>The PaaS Graph Database (GraphDB) service, Neo4j-based, is a fully managed, cloud-based graph database platform designed to store, query, and analyze data based on complex relationships and interconnected structures. Unlike traditional relational databases that rely on tables and joins, a GraphDB represents data as nodes (entities) and edges (relationships), allowing for efficient traversal and querying of complex networks \u2014 such as social connections, knowledge graphs, fraud detection systems, and recommendation engines. As a Platform-as-a-Service (PaaS) offering, the GraphDB service automates all operational tasks, including provisioning, configuration, scaling, patching, backups, and monitoring, enabling developers and data scientists to focus solely on building graph-powered applications without managing the underlying infrastructure. The PaaS is intended for organizations and developers that need to manage and query highly connected data with low latency and high flexibility. It provides native graph storage and querying capabilities optimized for real-time relationship exploration, graph analytics, and pattern matching across large datasets. Common use cases include:</p> <ul> <li>Social networks: modeling user interactions, followers, and communities.</li> <li>Recommendation systems: deriving product, content, or connection suggestions based on relationships.</li> <li>Fraud detection: identifying suspicious transaction patterns and entity links.</li> <li>Knowledge graphs: semantic search, ontology management, and enterprise metadata modeling.</li> <li>Network and IT operations: modeling dependencies and topology in complex infrastructures.</li> <li>Master Data Management (MDM): representing relationships between people, organizations, and assets.</li> </ul> <p>The service is offered per DB instance. Each instance consists of: </p> <ul> <li>4 vCPUs</li> <li>16 GB of RAM</li> </ul>"},{"location":"PaaS/#features-and-advantages_43","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Fully managed service \u2192 managing of provisioning, configuration, patching, and scaling of graph database clusters. Continuous monitoring and proactive maintenance. Built-in backup, restore, and snapshot management with defined retention policies.</li> <li>Native graph model support \u2192 supports both property graphs (e.g., Neo4j-compatible) and RDF graphs (semantic web standards). Enables flexible schema or schema-less design, allowing dynamic evolution of data models. Optimized for deep traversal queries, shortest-path calculations, and pattern matching.</li> <li>High performance and scalability \u2192 distributed architecture for horizontal scaling across multiple nodes.In-memory caching and optimized graph storage for high-speed traversals. Load balancing across query engines and replicas to ensure consistent performance. Low-latency graph query execution for complex relationship analysis.</li> <li>High availability and fault tolerance \u2192 clustered deployment with data replication across nodes or availability zones. Automatic failover and leader election for continuous service operation. Configurable consistency levels for balancing performance and data safety. Backup and Point-In-Time Recovery (PITR) options.</li> <li>Advanced Querying and Analytics \u2192 native support for graph query languages such as Cypher, Gremlin, SPARQL, or GraphQL extensions. Integration with graph analytics engines for algorithms like PageRank, community detection, and pathfinding. Full-text search and indexing capabilities for metadata and relationship attributes. Support for APIs and drivers in multiple languages (Python, Java, Node.js, Go).</li> <li>Security and compliance \u2192 encryption of data at rest and in transit (TLS/SSL). Authentication and authorization via IAM integration, role-based access control (RBAC), and fine-grained permissions. Network isolation with private endpoints, firewall rules, and VPC/VNet integration. Audit logging, compliance with GDPR, ISO 27001, and SOC 2 standards.</li> <li>Integration and interoperability \u2192 connectors and APIs for integration with data pipelines, ETL tools, and machine learning platforms. REST, GraphQL, or Bolt endpoints for application access. Integration with BI tools and data visualization frameworks for relationship exploration. Support for data federation and linking external data sources (SQL, NoSQL, RDF stores).</li> </ul> <p>The main components of the service are:</p> <p>Control plane (Management and orchestration layer) \u2192 this layer provides centralized control over the provisioning, configuration, and lifecycle management of GraphDB clusters. Key Components: Management API / Portal; Provisioning engine for automates deployment of graph database clusters across compute nodes; Configuration manager; Metrics &amp; monitoring collector; Billing &amp; quota manager for tracks usage (storage, query operations, nodes) and enforces subscription limits. - Data Plane (Execution layer) \u2192 this layer hosts the actual graph databases and query processing engines that execute user workloads. Key Components: Graph Database engine nodes for executing queries and maintain graph data structures, Storage layer; Query engine that interprets and executes graph query languages (Cypher, SPARQL, Gremlin); Replication layer that synchronizes data across nodes for high availability and consistency; Networking Layer for secure communication via private endpoints and load balancers. - High availability and resilience layer \u2192 ensures service continuity, fault tolerance, and disaster recovery. Key Components: Cluster Manager for coordinating replication, partitioning, and failover across graph nodes; Backup &amp; Recovery Manager that schedules automated backups and handles restoration processes; Failover controller; Geo-replication service that replicates graph data across regions or availability zones for disaster recovery. - Security &amp; Access layer \u2192 responsible for user authentication, authorization, encryption, and compliance management. Key Components: Identity and Access Management (IAM); Encryption services; Access control policies; Audit logging system - Observability &amp; Operations layer \u2192 provides visibility, automation, and operational maintenance for both administrators and users. Key Components: Monitoring system; Alerting &amp; incident management; Logging Service; Auto-patching &amp; Upgrades; Maintenance scheduler that orchestrates backup, cleanup, and optimization tasks.</p> <p>The service offers the following advantages:</p> <ul> <li>Accelerated Time-to-Value \u2192 rapid deployment of fully managed GraphDB clusters without infrastructure setup. Developers can focus on building relationship-driven applications rather than managing database servers. Preconfigured environments and APIs shorten time-to-market for data-intensive projects.</li> <li>Reduced Total Cost of Ownership (TCO) \u2192 eliminates hardware, networking, and software licensing costs. No need for in-house database administration or maintenance. Reduces hidden operational costs associated with upgrades, backups, and monitoring.</li> <li>Business agility and innovation \u2192 enables rapid experimentation with data relationships, graph analytics, and knowledge models. Scales on demand to handle growth in connected datasets. Supports new business capabilities such as recommendation systems, fraud detection, and semantic search without large upfront investment.</li> <li>Improved decision-making and insight discovery \u2192 provides a 360-degree view of data relationships across entities (customers, products, assets, etc.). Supports advanced analytics, predictive modeling, and data visualization. Helps uncover patterns, correlations, and dependencies that are invisible in traditional relational models.</li> <li>High reliability and continuity \u2192 built-in redundancy and replication ensure continuous service availability. Automated backups, failover, and point-in-time recovery minimize downtime and data loss. Meets enterprise-grade SLAs for uptime and durability.</li> <li>Governance, security, and compliance \u2192 managed security, encryption, and audit logging reduce compliance risks. Role-based access and data isolation protect sensitive relationships and metadata. Provider-managed patching and updates ensure continuous compliance with standards.</li> </ul> <p></p>"},{"location":"PaaS/#paas-nosql-mongodb","title":"PaaS NoSQL - MongoDB","text":"<p> MongoDB client interface </p>"},{"location":"PaaS/#service-description_41","title":"Service Description","text":"<p>The PaaS NoSQL MongoDB service provides a fully managed, cloud-native document database platform designed to handle large volumes of unstructured and semi-structured data. It enables organizations to deploy and operate MongoDB clusters without managing infrastructure, scaling, or administrative overhead. Built on the MongoDB engine, the service offers high flexibility in data modeling, seamless horizontal scalability, and advanced features such as replication, sharding, automated backups, and high availability. The service is designed to support modern, data-driven applications requiring high performance, flexibility, and scalability. It is particularly suited for:</p> <ul> <li>Web and mobile applications that require dynamic schemas.</li> <li>IoT and telemetry systems generating high-volume JSON data.</li> <li>Real-time analytics and event processing.</li> <li>Content management systems (CMS) and e-commerce platforms.</li> <li>Big data pipelines and data lakes needing schema evolution and rapid ingestion.</li> </ul> <p>The service is offered per DB instance. Each instance with replication consists of: </p> <ul> <li>4 vCPUs</li> <li>16 GB of RAM</li> </ul>"},{"location":"PaaS/#features-and-advantages_44","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Fully managed environment \u2192 managing of provisioning, configuration, and maintenance of MongoDB clusters. Continuous patching, upgrades, and resource optimization.Service managed via web console, CLI, or API for full lifecycle operations.</li> <li>Flexible data model \u2192 document-oriented schema using JSON/BSON structures. Supports hierarchical and nested data with dynamic schema evolution. Allows storage of complex data without the rigidity of relational tables. Ideal for agile development and microservices architectures.</li> <li>High performance and scalability \u2192 horizontal scaling through automatic sharding across multiple nodes. Vertical scaling by dynamically increasing compute and memory resources. Built-in read/write replication for high throughput and low latency. Intelligent indexing (single field, compound, geospatial, text, wildcard).</li> <li>High availability and resilience \u2192 replication via Replica Sets for automatic failover and self-healing. Multi-zone deployment for fault tolerance and disaster recovery. Point-in-Time Recovery (PITR) and incremental backups ensure data integrity.</li> <li>Security and compliance \u2192 encryption at rest and in transit.Role-Based Access Control (RBAC) and fine-grained permissions.Integration with enterprise Identity and Access Management (IAM) systems. Auditing, logging, and monitoring for compliance.</li> <li>Monitoring and observability \u2192 real-time dashboards for performance, resource utilization, and query profiling. Automated alerts and anomaly detection for proactive issue resolution. Integration with observability tools (e.g., Prometheus, Grafana, ELK Stack).</li> <li>Developer tools and integration \u2192 native support for MongoDB Query Language (MQL). APIs, SDKs, and drivers for major programming languages (Java, Python, Node.js, Go, etc.). Integration with CI/CD pipelines and Infrastructure-as-Code tools (Terraform, Ansible). Support for analytics and visualization via BI connectors and data APIs.</li> <li>Backup, restore, and disaster recovery \u2192 scheduled and on-demand backups with retention policies.Point-in-time recovery to mitigate data loss from logical errors. Geo-redundant replication across regions for disaster recovery.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Control plane \u2192 manages the provisioning, orchestration, scaling, and lifecycle of MongoDB clusters. Handles user authentication, access control, and billing integration. Provides APIs and UI for tenant management, monitoring, and configuration.</li> <li>Data Plane (MongoDB cluster layer) \u2192 comprises Replica Sets for high availability and Shards for distributed data storage. Each shard consists of multiple replica nodes (primary and secondaries). Mongos routers distribute queries intelligently across shards. Ensures horizontal scalability and automatic data balancing.</li> <li>Storage Layer \u2192 based on high-performance SSD or NVMe storage. Supports data encryption, snapshotting, and incremental backup mechanisms. Abstracted via cloud block storage for elasticity and redundancy.</li> <li>Network and security layer \u2192 implements network isolation via Virtual Private Cloud (VPC) or private endpoints. Firewall rules, IP whitelisting, and security groups restrict access. TLS-based encryption secures data in transit between components and clients. - Management and monitoring layer \u2192 provides observability, metrics collection, and alerting. Automated performance tuning and resource optimization. Integrates with logging and monitoring frameworks.</li> <li>Backup and disaster recovery layer \u2192 handles snapshot-based backups, replication, and PITR mechanisms. Automated restore operations from cloud object storage. Supports cross-region replication for business continuity.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced Total Cost of Ownership (TCO) \u2192 eliminates capital investments in servers, storage, and licenses. Shifts database management from internal teams to the provider\u2019s managed service. Reduces operational costs through automation of scaling, patching, and backups.</li> <li>Faster Time-to-Market \u2192 fully managed environment allows databases to be provisioned in minutes. Dynamic schema flexibility accelerates application development. Enables rapid prototyping and iteration, ideal for agile and DevOps workflows.</li> <li>High agility and flexibility \u2192 schema-less document model adapts easily to evolving application requirements. Ideal for businesses managing heterogeneous or semi-structured data sources. Supports frequent data model changes without downtime or migration overhead.</li> <li>Business continuity and reliability \u2192 enterprise-grade high availability with built-in replication and automatic failover.Continuous backups and geo-redundant disaster recovery ensure data resilience. Meets stringent SLAs for uptime and data durability.</li> <li>Scalability and growth enablement \u2192 seamless horizontal scaling allows the service to handle growing data volumes and workloads. Supports global deployments with low latency through distributed clusters. Enables new data-intensive use cases (IoT, analytics, personalization) without redesigning architecture.</li> <li>Compliance and data governance \u2192 managed patching, auditing, and encryption ensure continuous compliance. Data isolation and access control simplify adherence to european laws. Facilitates transparent governance with built-in monitoring and reporting tools.</li> <li>Focus on core business \u2192 frees internal teams from database management and operational complexity. Allows developers to focus on innovation, application features, and user experience. Accelerates delivery of digital services and customer-facing applications.</li> </ul> <p></p>"},{"location":"PaaS/#paas-in-memory-redis","title":"PaaS In Memory- Redis","text":"<p> Redis client interface </p>"},{"location":"PaaS/#service-description_42","title":"Service Description","text":"<p>It is a PaaS DB based on Redis technology (Remote Dictionary Server) that exposes a high-performance in-memory database, primarily used as a cache and database for web and real-time applications.  Redis is a widely used database due to its flexibility and ability to handle a wide range of data types with low latency. The service delivers sub-millisecond data access, advanced caching, session management, message streaming, and data persistence capabilities. As a Platform-as-a-Service (PaaS) offering, it abstracts away the operational complexity of managing Redis clusters \u2014 including provisioning, scaling, patching, failover, and monitoring \u2014 while ensuring enterprise-grade reliability, security, and performance.  </p> <p>The PaaS Redis service is designed for applications that require extremely fast data access, real-time analytics, and low-latency transactions. Typical use cases include:</p> <ul> <li>Application caching to reduce latency and offload backend databases.</li> <li>Session storage for web and mobile applications.</li> <li>Real-time analytics and leaderboards (e.g., gaming, ad tech, telemetry).</li> <li>Message queues and event streaming for distributed systems.</li> <li>Geospatial data processing and time-series data handling.</li> <li>Rate limiting and token management in API gateways.</li> </ul> <p>The service is offered per DB instance. Each instance consists of: </p> <ul> <li>4 vCPUs</li> <li>16 GB of RAM</li> </ul>"},{"location":"PaaS/#features-and-advantages_45","title":"Features and Advantages","text":"<p>The main features of the Paas In Memory Redis are:</p> <ul> <li>In-memory \u2192 data is stored in RAM, ensurig extremely fast access;</li> <li>Persistence \u2192 supports data persistence on disk, preventing data loss in the event of a system reboot;</li> <li>Data type \u2192 variety of data types, allowing for modeling different types of information;</li> <li>Pub/Sub \u2192 supports the publish/subscribe model for real-time communication between applications.</li> <li>Fully managed platform \u2192 managing of provisioning, patching, scaling, and maintenance. High availability clusters with zero-downtime updates. Self-healing orchestration to ensure continuous service delivery. Management via API, CLI, or Web Console.</li> <li>High performance and low latency \u2192 entire dataset stored in-memory for sub-millisecond access. Optimized for real-time operations requiring microsecond response times. Supports high throughput (millions of operations per second). Persistent storage optional for durability.</li> <li>Flexible data structures \u2192 rich data model beyond simple key-value pairs: strings, hashes, lists, sets, sorted sets. Bitmaps, HyperLogLogs, Streams, and Geospatial Indexes. Ideal for complex operations such as counters, queues, and pub/sub messaging.</li> <li>High Availability and disaster recovery \u2192 native Redis Sentinel or Cluster Mode for automatic failover and fault tolerance. Multi-AZ deployment to ensure continuous uptime. Backup and restore capabilities for data persistence and recovery. Optional geo-replication across regions for disaster recovery.</li> <li>Persistence options \u2192 RDB (Redis Database Backup): Snapshot-based persistence for periodic backups. AOF (Append-Only File): Logs every operation for durability and recovery. Hybrid mode combining both mechanisms for balance between speed and reliability.</li> <li>Scalability and elasticity \u2192 horizontal scaling through Redis Cluster sharding. Vertical scaling with dynamic memory and compute adjustments. Linear scalability for both read and write operations. Automatic rebalancing of data across nodes.</li> <li>Security and compliance \u2192 encryption in transit (TLS) and encryption at rest. Role-Based Access Control (RBAC) and user authentication. Integration with Identity and Access Management (IAM) systems. Continuous auditing, logging, and compliance monitoring.</li> <li>Monitoring and observability \u2192 real-time metrics on throughput, latency, and memory usage. Proactive alerts and anomaly detection. Integration with monitoring stacks (Prometheus, Grafana, ELK). Logging for audit trails and performance tuning.</li> <li>Developer Integration and APIs \u2192 compatible with standard Redis clients and libraries. REST and gRPC APIs for automation and DevOps workflows. Integration with CI/CD pipelines and Infrastructure-as-Code tools (Terraform, Ansible). Supports Redis modules (e.g., RedisJSON, RediSearch, RedisGraph, RedisTimeSeries).</li> </ul> <p>The logical architecture of the PaaS Redis service consists of multiple layers designed for automation, scalability, and resilience.</p> <ul> <li>Control plane \u2192 responsible for service orchestration, cluster provisioning, scaling, and lifecycle management. Manages authentication, authorization, metering, and billing. Provides APIs, CLI, and web-based UI for service management.</li> <li>Data Plane (Redis cluster layer) \u2192 Core component that hosts user data in memory. Composed of multiple Redis instances organized as: Master nodes; Replica nodes; Implements sharding for horizontal scalability; Ensures high throughput and low latency for data operations.</li> <li>Storage and persistence layer \u2192 provides optional durable storage for backup and disaster recovery. Utilizes RDB snapshots and AOF logs stored on encrypted block or object storage. Supports automated retention policies and scheduled backups.</li> <li>Networking and security layer \u2192 virtual network isolation using VPC/VNet configurations. TLS-based encryption for client-to-server and inter-node communication. Security groups, IP whitelisting, and firewall rules for controlled access. Optional private endpoints for secure integration with internal systems.</li> <li>Monitoring and Management layer \u2192 aggregates telemetry and performance metrics. Implements logging, tracing, and alerting via monitoring systems. Provides dashboards for capacity planning and SLA tracking.</li> <li>High availability and failover layer \u2192 monitors node health and automatically triggers failover in case of node or zone failure. Uses Redis Sentinel or internal control mechanisms for cluster coordination. Supports synchronous or asynchronous replication for HA and DR.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced Total Cost of Ownership (TCO) \u2192 no capital investment in hardware, software, or cluster management. Reduces operational overhead by automating deployment, scaling, and maintenance. Eliminates the need for specialized in-house Redis administration skills.</li> <li>Faster Time-to-Market \u2192 instant provisioning of Redis clusters enables rapid development and testing. Ready-to-use configurations optimize caching and real-time processing use cases. Enables teams to integrate low-latency data layers into applications in minutes. Accelerates delivery of digital services requiring immediate responsiveness.</li> <li>Improved application performance and user experience \u2192 sub-millisecond response times improve customer satisfaction and engagement. Reduces load on backend databases and APIs through caching and data offloading. Ensures consistent performance during traffic spikes or seasonal demand peaks.</li> <li>Business agility and scalability \u2192 easily scales up or down to accommodate fluctuating workloads. Enables dynamic adaptation to new business requirements without architectural redesign. Supports real-time analytics and streaming for modern, data-intensive applications.</li> <li>Reliability and continuity \u2192 built-in replication and failover mechanisms ensure continuous availability. Automated backups and geo-redundancy support robust disaster recovery. Meets enterprise-grade SLA commitments for uptime and data durability.</li> <li>Compliance and security \u2192 provider-managed encryption, patching, and access control ensure compliance with data security standards. Role-based access and network isolation protect sensitive data in-memory and at rest. Reduces compliance risks through centralized governance and auditing tools.</li> <li>Focus on core business innovation \u2192 frees developers and operations teams from managing infrastructure and cluster administration. Allows organizations to focus on value creation, product innovation, and user experience. Enables integration of Redis-based caching and real-time logic into cloud-native architectures effortlessly.</li> </ul>"},{"location":"PaaS/#networking-family","title":"Networking Family","text":"<p>Below is the list of services belonging to the Networking family:</p> <ul> <li>Paas CDN (Content Delivery Network)</li> <li>PaaS DNS (Domain Name System)</li> <li>Single public IP</li> <li>L7 Load Balancer (regional)</li> <li>Cloud interconnect Gold SW (10 Gbps max throughput) </li> <li>Managed VPN Access Service </li> <li>PaaS Client/Forward Proxy </li> <li>PaaS Reverse Proxy </li> </ul> <p></p>"},{"location":"PaaS/#paas-cdn-content-delivery-network","title":"PaaS CDN (Content Delivery Network)","text":"<p> PaaS CDN (Content Delivery Network) interface </p>"},{"location":"PaaS/#service-description_43","title":"Service Description","text":"<p>The PaaS CDN (Content Delivery Network) service based on Nginx memory cache is a cloud-managed platform designed to accelerate content delivery, reduce latency, and ensure high availability for web applications and digital services. By leveraging Nginx\u2019s high-performance caching capabilities\u2014optimized for in-memory operations\u2014the platform delivers ultra-fast retrieval of static and dynamic content. As a fully managed PaaS offering, it abstracts the complexity of operating CDN infrastructure, providing customers with a scalable, secure, and globally distributed content delivery layer.</p> <p>The service is offered with the following unit metric: 10 Gbps of throughput (inbound &amp; Outbound).</p>"},{"location":"PaaS/#features-and-advantages_46","title":"Features and Advantages","text":"<p>The main features of the service are:</p> <ul> <li>High-Performance In-Memory Caching \u2192 ultra-low latency content delivery powered by Nginx memory cache, ideal for frequently accessed assets.</li> <li>Global Edge Distribution \u2192 multiple distributed PoPs (Points of Presence) to ensure content is served as close to users as possible.</li> <li>Dynamic Content Acceleration \u2192 support for reverse proxy, micro-caching, and intelligent cache rules to optimize dynamic workloads.</li> <li>Load Balancing and Failover \u2192 built-in traffic distribution mechanisms to maintain availability and service continuity.</li> <li>Real-Time Purge and Cache Control \u2192 instant cache invalidation APIs for granular control over content lifecycle.</li> <li>TLS Offloading and Security Filtering \u2192 enhanced security features including HTTPS termination, rate limiting, and request filtering.</li> <li>Centralized Management Interface \u2192 unified portal for configuration, analytics, monitoring, and scaling.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Nginx Edge Nodes \u2192 distributed caching servers running Nginx with optimized memory caching for fast content retrieval.</li> <li>Control and Orchestration Layer* \u2192 cloud-based management system for provisioning, updating, configuring, and scaling all CDN nodes.</li> <li>Global Routing &amp; Load Balancing \u2192 smart routing algorithms directing users to the nearest or fastest-performing PoP.</li> <li>API Gateway &amp; Cache Management Tools \u2192 APIs for programmatic cache purging, cache rules, routing policies, and provisioning.</li> <li>Monitoring &amp; Analytics Engine \u2192 real-time dashboards providing metrics on latency, cache hit ratio, traffic patterns, and health status.</li> <li>Security Layer \u2192 integrated HTTPS, WAF options, rate limiting, and request validation at the edge.</li> </ul> <p>The service offers the following advantages: </p> <ul> <li>Improved User Experience \u2192 faster load times and reduced latency directly enhance customer satisfaction and engagement.</li> <li>Predictable and Lower Operational Costs \u2192 OPEX-based PaaS model avoids infrastructure investment and reduces maintenance burden.</li> <li>Scalable for Growth \u2192 easily supports increasing traffic volume without service interruptions or rearchitecture.</li> <li>Global Reach with Minimal Effort \u2192 organizations can instantly expand content delivery worldwide without deploying additional infrastructure.</li> <li>Increased Service Reliability \u2192 built-in redundancy and failover ensure business continuity even during traffic spikes.</li> <li>High Performance Through Memory Caching \u2192 in-memory content serving dramatically improves throughput and reduces backend load.</li> <li>Flexible Caching Policies \u2192 support for custom rules, micro-caching, selective purging, and dynamic acceleration.</li> <li>Reduced Origin Server Load \u2192 high cache hit ratios prevent unnecessary upstream requests, improving origin server performance.</li> <li>Optimized for Modern Web Architectures \u2192 compatible with APIs, microservices, SPA frameworks, and containerized environments.</li> <li>Secure by Design \u2192 integrated TLS termination, request filtering, rate limiting, and observability tools protect the delivery pipeline.</li> </ul> <p></p>"},{"location":"PaaS/#paas-dns-domain-name-system","title":"PaaS DNS (Domain Name System)","text":"<p> PaaS DNS (Domain Name System) interface </p>"},{"location":"PaaS/#service-description_44","title":"Service Description","text":"<p>The PaaS DSN (Distributed Secure Network) service based on OPNsense provides a cloud-delivered, fully managed network security and routing platform designed for organizations that require scalable, secure, and highly available connectivity. Built on OPNsense\u2019s open-source firewall and security capabilities, this service abstracts infrastructure complexity and offers customers a ready-to-use network environment delivered as a Platform-as-a-Service. The solution centralizes policy management, simplifies deployment, and ensures consistent security enforcement across distributed sites, remote users, and cloud workloads.</p> <p>The service is offered for each DNS Instance unit. </p>"},{"location":"PaaS/#features-and-advantages_47","title":"Features and Advantages","text":"<p>The main features of the service are:</p> <ul> <li>Cloud-managed OPNsense firewall instances \u2192 fully managed virtual appliances with automated updates, monitoring, and lifecycle management.</li> <li>Zero-Trust network access \u2192 policy-based access management for users and devices, enabling secure remote connectivity.</li> <li>High Availability &amp; scalability \u2192 cluster configurations, automated failover and elastic capacity provisioning.</li> <li>Centralized configuration &amp; orchestration \u2192 unified control panel for managing rules, VPNs, routing, and monitoring across multiple nodes.</li> <li>Multi-tenant architecture \u2192 logical separation of environments for partners, business units or customers.</li> <li>Full API integration \u2192 REST API support for automation, CI/CD pipelines and infrastructure-as-code workflows.</li> </ul> <p>The main components of the service are:</p> <ul> <li>OPNsense core platform \u2192 the foundational DNS and security engine, providing routing, filtering, and advanced security modules.</li> <li>Management &amp; orchestration layer \u2192 a cloud-native platform that automates provisioning, configuration, monitoring, and scaling of OPNsense nodes.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced operational ocmplexity \u2192 eliminates the need to manage firewall hardware, updates, and maintenance in-house.</li> <li>Lower total cost of ownership (TCO) \u2192 subscription-based model removes CAPEX and ensures predictble cost planning.</li> <li>Accelerated time-to-value \u2192 rapid deployment and standardized configurations shorten rollout cycles.</li> <li>Improved security posture \u2192 centralized policy enforcement and continuous updates reduce exposure to threats.</li> <li>Flexibility for business growth \u2192 easily add new sites, users, or workloads without re-architecting the network.</li> <li>Consistent and automated ocnfiguration \u2192 reduces human error and ensures uniform security across the organization.</li> <li>API-first approach \u2192  smooth integration with DevOps pipelines and automated deployment systems.</li> <li>Vendor neutral and open source\u2013absed \u2192 avoids vendor lock-in while benefiting from the transparency and flexibility of OPNsense.</li> </ul>"},{"location":"PaaS/#deployment-in-customer-vnet","title":"Deployment in customer VNET","text":"<p>The DNS service is deployed as a virtual appliance within the customer\u2019s VNET. It acts as the authoritative resolver for internal workloads while forwarding queries for external domains to upstream DNS servers. This ensures a single DNS endpoint for all workloads in the VNET, simplifying configuration and management.  </p>"},{"location":"PaaS/#internal-and-external-resolution","title":"Internal and external resolution","text":"<ul> <li>Internal Resolution: the OPNsense DNS Resolver (Unbound) can be configured with local zones and host overrides. Workloads in the VNET can register their names dynamically, enabling seamless resolution of private IP addresses.</li> <li>External Resolution: queries for domains outside the VNET are forwarded to upstream DNS servers (e.g., ISP or public resolvers). Supports DNSSEC validation for secure external lookups.</li> </ul>"},{"location":"PaaS/#dynamic-updates","title":"Dynamic updates","text":"<p>The service supports dynamic DNS updates from workloads in the account, which can automatically register or update their DNS records in the OPNsense DNS Resolver. This ensures that newly deployed or scaled workloads are immediately reachable by name without manual intervention. Dynamic updates are authenticated using secure mechanisms (TSIG keys), preventing unauthorized changes.  </p> <p>Dynamic Updates Flow</p> <ol> <li>Workload acquires IP address<ul> <li>a VM, container, or host in the customer VNET requests an IP lease from DHCP</li> </ul> </li> <li>DHCP assigns lease</li> <li>DNS update request (RFC2136)<ul> <li>The DHCP service or workload sends a signed update message to the OPNsense DNS Resolver (Unbound).</li> <li>Authentication is handled via TSIG keys to ensure only authorized clients can modify records.</li> </ul> </li> <li>Unbound DNS updates zone records<ul> <li>The resolver updates its local zone or forwards the update to an authoritative DNS server, and the A/AAAA records are updated with the new IP address.</li> </ul> </li> <li>Clients can resolve the updated names<ul> <li>Other workloads in the VNET query the OPNsense DNS service.</li> <li>The resolver returns the updated IP address, ensuring connectivity.</li> </ul> </li> </ol> <p> Diagram of the Flow </p> <p></p>"},{"location":"PaaS/#single-public-ip-service","title":"Single public IP Service","text":""},{"location":"PaaS/#service-description_45","title":"Service Description","text":"<p>A PaaS Single Public IP service is a managed cloud networking offering that provides a dedicated, globally reachable public IP address for workloads hosted in the provider\u2019s cloud environment. In this implementation the service enables customers to expose virtual machines, containers, load balancers, or platform services to the Internet using a stable, provider-managed public IP, without requiring them to manage networking infrastructure or routing complexity.</p> <p>The service is offered per number of public IP addresses.</p>"},{"location":"PaaS/#features-and-advantages_48","title":"Features and Advantages","text":"<p>The main features of the service are:</p> <ul> <li>Dedicated public IP assignment \u2192 provides one unique and persistent public IPv4 or IPv6 address. The IP can be assigned to VMs, network interfaces, or load balancers within the cloud environment Ensures stable reachability even if the underlying infrastructure changes.</li> <li>Managed routing and NAT \u2192 the platform automatically manages inbound and outbound routing. Supports 1:1 NAT, DNAT, or SNAT depending on configuration. Simplifies network exposure of private resources, with no need to operate firewalls or routers.</li> <li>High availability and redundancy \u2192 public IPs are served through a highly redundant provider network. Automatic failover ensures continuity even if the underlying host or zone fails. Supports attaching the IP to different resources without service interruption.</li> <li>Flexible binding to cloud resources \u2192 the same public IP can be detached and reattached to: virtual machines, virtual network interfaces, load balancers, application gateways. Enables quick recovery, migrations, and architecture evolution.</li> <li>Integrated security controls \u2192 configurable security groups, ACLs, and firewall rules. Traffic filtering and connection control managed through the cloud portal. Protection against common network threats through provider-level safeguards.</li> <li>Simplified internet exposure \u2192 ideal for publishing: web applications, APIs, VPN gateways, remote management endpoints. No need to configure BGP, DNS routing, or physical network appliances.</li> <li>Monitoring &amp; logging \u2192 platform dashboards show: traffic flows, connection statistics, security events. Useful for troubleshooting and capacity planning.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Provider-managed edge network \u2192 the public IP is routed through Aruba\u2019s redundant edge infrastructure. Anycast or geographically optimized routing ensures low latency and high availability. Backbone interconnects with major Internet exchange points.</li> <li>Virtualized networking layer \u2192 based on SDN-enabled virtual switches and routers. The public IP is associated to a virtual NIC via cloud networking APIs. Provides isolation between tenants and secure segmentation.</li> <li>NAT &amp; Firewall gateway cluster \u2192 a cluster of virtual gateways manages: NAT operations, packet inspection, stateful firewalling, traffic shaping, Fully redundant and automatically scaled by the platform.</li> <li>Control plane \u2192 centralized management system allowing: creation and deletion of public IPs, binding/unbinding to resources, firewall rule management, configuration propagation across zones. Does not handle traffic directly but orchestrates network behavior.</li> <li>Data plane \u2192 distributed packet-processing nodes handle the real traffic. Designed for high throughput, low latency, and multi-zone resilience. Built to ensure performance even under heavy load.</li> <li>Integration with DNS and load balancers \u2192 the public IP can be connected to: DNS A/AAAA records, cloud load balancers, reverse proxies. Enables scalable and flexible application publishing.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Simplified internet exposure \u2192 easily expose VMs, applications, or services to the public Internet. No need to configure routers, gateways, or complex network infrastructure.</li> <li>High availability and resilience \u2192 public IPs are served through a redundant cloud network. Automatic failover ensures continuity if the underlying instance or zone fails. The IP remains reachable even when moving resources.</li> <li>Flexibilty and portability \u2192 the same IP can be detached and reattached to different cloud resources. Enables seamless migration, maintenance, and architecture changes. Supports disaster - - Zero infrastructure management \u2192 no need to deploy or maintain firewalls, NAT appliances, or BGP routers. Managing of routing, redundancy, and capacity at the network edge.</li> <li>Integrated security \u2192 built-in firewall rules, security groups, and access control lists Centralized management through the cloud portal or APIs. Provider-level protection against common network attacks.</li> <li>Cost efficiency \u2192 eliminates the need for purchasing and managing public IP blocks. Reduces operational overhead and network administration costs.</li> <li>Consistent and stable reachability \u2192 the public IP remains persistent, even if internal infrastructure changes. Guarantees stable endpoints for DNS records, APIs, and external integrations.</li> <li>Improved operational agility \u2192 fast provisioning of new public IPs on demand. Immediate configuration changes via self-service interface. Accelerates deployment pipelines and DevOps workflows.</li> <li>Traffic monitoring and visibility \u2192 built-in dashboards and logs for tracking inbound/outbound traffic. Useful for troubleshooting, auditing, and performance optimization.</li> <li>Secure and scalable foundation for cloud services \u2192 works seamlessly with load balancers, DNS records, VPN gateways, and edge services. Supports both small applications and large-scale enterprise architectures.</li> </ul> <p></p>"},{"location":"PaaS/#l7-load-balancer-regional-service","title":"L7 Load Balancer (regional) Service","text":"<p> L7 Load Balancer (regional) Service Overview </p>"},{"location":"PaaS/#service-description_46","title":"Service Description","text":"<p>A PaaS L7 Load Balancer (Regional) is a fully managed platform service that distributes HTTP/HTTPS traffic across backend services (VMs, containers, or applications) within a specific cloud region. It consists of a listener that receives requests on behalf of a set of backend pools and distributes them based on criteria based on application data, thus determining which pools serve a given request. The application infrastructure can therefore be specifically tuned and optimized to serve specific types of content. Based on an OPNsense-like architecture, it provides advanced Layer 7 capabilities such as content-aware routing, SSL offloading, traffic inspection, and application firewalling\u2014without requiring customers to deploy, monitor, or maintain any load-balancing infrastructure.  </p> <p>The service is offered per each balancer instance.</p>"},{"location":"PaaS/#features-and-advantages_49","title":"Features and Advantages","text":"<p>The main features of the service are:</p> <ul> <li>Layer 7 application-aware routing \u2192 inspects and routes traffic based on HTTP/HTTPS attributes: URL paths, hostnames, headers, cookies, query parameters, Enables fine-grained control and intelligent traffic distribution.</li> <li>SSL/TLS termination and management \u2192 offloads TLS/SSL handshake from backend servers. Centralized management of certificates (upload, renewal, rotation). Supports HTTPS redirection, HSTS, and modern cipher suites.</li> <li>Backend load distribution \u2192 supports several load-balancing algorithms: round-robin, least connections, IP hash, weighted distribution. Ensures efficient traffic handling and smooth scaling of applications.</li> <li>Health checks and failover \u2192 performs L7 health checks on backend services (HTTP codes, response payloads). Automatically excludes unhealthy instances and restores them when available. Prevents routing user requests to failed or degraded services.</li> <li>Web Application Firewall (WAF) \u2192 integrated OPNsense-compatible WAF engine. Protects against OWASP Top 10 and common web attacks. Provides rule sets, anomaly scoring, and traffic filtering.</li> <li>URL rewriting and traffic transformation \u2192 rewrite URLs, headers, or cookies. Inject or remove headers for security or routing logic. Useful for legacy system integration or microservices migration.</li> <li>Regional scope \u2192 traffic is handled within a specific cloud region for: predictable latency, compliance requirements, locality of data and workloads. Ideal for regional failover patterns.</li> <li>Logging, monitoring, and metrics \u2192 provides: request/response logs, traffic and error statistics, performance metrics, WAF alerts. Enables effective debugging and performance optimization.</li> <li>Zero infrastructure management \u2192 no need to deploy virtual appliances, firewalls, or proxies. The platform maintains: high availability, patching, upgrades, scaling, failover</li> </ul> <p>The main components of the service are:</p> <ul> <li>Regional load balancing cluster \u2192 a distributed cluster of L7 processing nodes within the chosen region.Provides high availability (active-active or active-standby) \u2192 automatically scales horizontally based on traffic load.</li> <li>OPNsense-based application proxy layer \u2192 built on top of an OPNsense-like architecture: HAProxy or NGINX engine, integrated WAF, layer 7 parsing and filtering. Provides flexibility and robust application-level control.</li> <li>Virtualized networking layer \u2192 integrates with the cloud network fabric. Supports private and public endpoints. Ensures tenant isolation and secure routing to backends.</li> <li>Control plane \u2192 It's coordinates: configuration of listeners, rules, routes, and backends, certificate management, policy updates and propagation, versioning and rollback, API- and UI-based management. Does not handle traffic.</li> <li>Data plane \u2192 processes all HTTP/HTTPS requests. Terminates TLS, applies routing logic, executes WAF rules. Ensures high throughput and low latency.</li> <li>Health check and failover engine \u2192 continuously monitors backend endpoints. Maintains a dynamic view of backend availability. Ensures failover rules are applied in real time.</li> <li>Logging &amp; analytics layer \u2192 collects request logs, WAF events, metrics, and anomalies. Provides dashboards and monitoring tools. Works independently from the data plane to ensure performance.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Improved application availability \u2192 automatic failover prevents downtime. Faulty backends are bypassed instantly.</li> <li>Better performance and lower latency \u2192 efficient L7 traffic distribution within the same region. TLS offloading improves backend performance.</li> <li>Strong security posture \u2192 built-in WAF protects against common web threats. TLS best practices and centralized certificate management.</li> <li>Simplified operations \u2192 fully managed service\u2014no appliance deployment or patching. Easy configuration from UI or APIs. Reduces operational and networking overhead.</li> <li>High flexibility in routing \u2192 content-based routing for modern microservices architectures. Easy to map multiple applications under the same IP/hostname.</li> <li>Cost efficiency \u2192 eliminates need for dedicated load balancer appliances.</li> <li>Consistent user experience \u2192 evenly balances traffic to healthy backends. Ensures predictable application responsiveness.</li> <li>Enhanced observability \u2192 access to detailed logs, metrics, and WAF events. Faster troubleshooting and monitoring.</li> <li>Compliance and regional data control \u2192 all traffic processing remains within a specific geographic region. Helps meet regulatory and data residency requirements.</li> <li>Rapid deployment and DevOps integration \u2192 instant provisioning with minimal configuration. API-driven automation for CI/CD pipelines.</li> </ul> <p></p>"},{"location":"PaaS/#cloud-interconnect-gold-sw-10-gbps-max-throughput","title":"Cloud interconnect Gold SW (10 Gbps max throughput)","text":""},{"location":"PaaS/#service-description_47","title":"Service Description","text":"<p>The PaaS Cloud interconnect gold SW service provides a high-quality, software-defined, private connectivity between a customer\u2019s on-premises infrastructure (or external data centers) and the Aruba cloud environment. It offers dedicated bandwidth tiers, enhanced SLA guarantees, secure routing, and enterprise-grade performance, enabling customers to build hybrid or multi-cloud architectures without deploying physical network appliances or managing complex routing setups. The \u201cGold\u201d tier represents the highest level of availability, performance, and support, while the \u201cSW\u201d component refers to software-based interconnect provisioning, ensuring flexibility, fast activation, and seamless scalability. This service, delivered via hardware or software, is designed to simplify customer application migration with minimal impact on users and workloads. It enables granularity down to the individual IP address during migration, increasing security and minimizing rollback times, if necessary.  </p> <p>The service is offered with the following unit metric: 10 Gbps of throughput.</p>"},{"location":"PaaS/#features-and-advantages_50","title":"Features and Advantages","text":"<p>The main features of the service are:</p> <ul> <li>Private and secure network connectivity \u2192 ensures a private, non-public connection between customer networks and cloud resources. Traffic does not traverse the public Internet, reducing risk and improving performance. Ideal for workloads requiring compliance, isolation, or predictable latency. - Software-defined provisioning (SW) \u2192 fully software-based interconnect setup with no physical circuits required.On-demand provisioning via web console or API. Rapid activation (minutes instead of days or weeks). Flexible reconfiguration without service interruption.</li> <li>High SLA &amp; guaranteed bandwidth (Gold tier) \u2192 provides defined bandwidth tiers with guaranteed throughput. Includes enhanced SLA for: availability, packet loss, latency, jitter. Suitable for mission-critical enterprise applications.</li> <li>Multi-site and multi-zone connectivity \u2192 supports connectivity to multiple Aruba regions or availability zones. Enables redundant hybrid cloud architectures. Facilitates interconnection of distributed workloads.</li> <li>Routing integration \u2192 supports dynamic routing (BGP) or static routing. Automatically adapts to network topology changes. Enables flexible hybrid cloud traffic engineering.</li> <li>Segmentation and isolation \u2192 allows creation of multiple isolated virtual circuits or VLANs. Ideal for separating environments: production, staging, development, partner networks</li> <li>End-to-end encryption \u2192 traffic can be encrypted at the network edge using IPsec or provider-managed encryption. Ensures compliance with data protection standards.</li> <li>Monitoring, logs, and telemetry \u2192 real-time monitoring of: bandwidth usage, packet loss and latency, connection health. Exportable logs for SIEM and analytics systems.</li> <li>No Physical hardware required \u2192 provider manages the entire connectivity layer. No need for physical circuits, routers, or carrier contracts. Reduces complexity and deployment time.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Software-defined interconnect fabric \u2192 centralized SDN layer orchestrating virtual connections. Provides flexible, scalable, multi-tenant connectivity. Allows rapid deployment and reconfiguration.</li> <li>Regional interconnect gateways \u2192 high-availability routing gateways located in Aruba cloud regions. Serve as entry/exit points for private customer traffic. Architected for redundancy and failover.</li> <li>Cloud backbone network \u2192 high-capacity fiber backbone interconnecting Aruba data centers. Ensures low-latency east-west traffic across regions. Supports both primary and backup routes.</li> <li>Security &amp; isolation layer \u2192 strict tenant isolation enforced at: network virtualization layer, routing control plane, traffic segmentation policies. Ensures no cross-tenant visibility.</li> <li>Control plane \u2192 It manages: provisioning of interconnects, routing updates, bandwidth allocation, policy enforcement. Exposed through UI and APIs.</li> <li>Data plane \u2192 handles the actual traffic flow with: guaranteed QoS, deterministic routing, optimized latency paths. Decoupled from monitoring and control tasks.</li> <li>Monitoring &amp; observability layer \u2192 aggregates telemetry from gateways and SDN controllers. Provides dashboards and alerting for performance and reliability.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Enhanced security \u2192 private connection avoids exposure to the public Internet. Supports encrypted tunnels and isolated routing domains.</li> <li>Predictable and high performance \u2192 guaranteed bandwidth and low latency. Stable connectivity ideal for enterprise workloads.</li> <li>Rapid deployment \u2192 software-defined provisioning reduces setup from weeks to minutes. No physical circuits or carrier coordination required.</li> <li>High availability and reliability (Gold SLA) \u2192 redundant gateways, paths, and failover mechanisms built in. Suitable for mission-critical connectivity.</li> <li>Cost efficiency \u2192 eliminates the need for physical interconnects or MPLS lines.</li> <li>Improved hybrid cloud architecture \u2192 seamlessly integrates on-prem infrastructure with cloud workloads. Supports migration, DR, and inter-site communication.</li> <li>Scalability on demand \u2192 quickly adjust bandwidth tiers or add new interconnects. Ideal for growing or fluctuating workloads.</li> <li>Simplified network operations \u2192 centralized management via API/portal. Automated routing and monitoring reduce operational overhead.</li> <li>Better compliance and data governance \u2192 private, regional connectivity supports regulatory requirements. Data paths remain under predictable network control.</li> <li>Optimized application experience \u2192 reduced jitter and packet loss improve performance for: databases, real-time apps, VoIP/UC, latency-sensitive services.</li> </ul> <p></p>"},{"location":"PaaS/#managed-vpn-access-service","title":"Managed VPN Access Service","text":""},{"location":"PaaS/#service-description_48","title":"Service Description","text":"<p>The Managed VPN Access Service provides secure connectivity between customer premises and cloud infrastructure using the OPNsense firewall appliance. It is a fully-automated managed VPN service, meaning customers do not need to manually maintain or patch the underlying system. The service provider ensures continuous updates and security compliance.</p> <p>Key capabilities: - Provisioning via portal and APIs for automation and integration. - Provider-managed patching of the OPNsense appliance and service components. - Multiple VPN connections per virtual network supported. - Flexible tunneling protocols: IPsec, SSL, and WireGuard. - BGP support for improved failover and routing across IPsec tunnels.</p>"},{"location":"PaaS/#features-and-advantages_51","title":"Features and Advantages","text":"<p>The service can be provisioned through the Leonardo\u2019s Secure Cloud Management Portal for quick setup. APIs are available for automated configuration and integration with Infrastructure-as-Code workflows. Declarative configuration files can be used to define VPN tunnels, routing policies, and security contexts.</p> <p>The Managed VPN Access Service supports multiple tunneling protocols over the public Internet, ensuring flexibility, interoperability, and strong security for different use cases. Each protocol offers unique advantages depending on the connectivity scenario.</p> <ul> <li>IPsec VPN (Internet Protocol Security)<ul> <li>Purpose: Industry-standard protocol suite for securing IP communications.</li> <li>Use Case: Commonly used for site-to-site tunnels between customer premises and cloud infrastructure.</li> <li>Features:<ul> <li>Strong encryption (AES, SHA-2, etc.) for confidentiality and integrity.</li> <li>Widely supported across enterprise firewalls, routers, and appliances.</li> <li>Compatible with BGP routing to enable dynamic failover and load balancing across multiple tunnels.</li> </ul> </li> <li>Benefit: Ensures highly secure, standards-based connectivity for enterprise networks.</li> </ul> </li> <li>SSL VPN (Secure Sockets Layer Virtual Private Network)<ul> <li>Purpose: Provides secure remote access for individual users or devices.</li> <li>Use Case: Ideal for remote workforce connectivity, enabling employees to securely access internal applications from anywhere.</li> <li>Features:<ul> <li>Operates over HTTPS, making it firewall-friendly and easy to deploy.</li> <li>Supports client-based and clientless (browser-based) access.</li> <li>Flexible authentication options (certificates, MFA, LDAP/AD integration).</li> <li>Benefit: Simplifies remote access with minimal configuration, while maintaining strong encryption and user authentication.</li> </ul> </li> </ul> </li> <li>WireGuard VPN<ul> <li>Purpose: A modern, high-performance VPN protocol designed for simplicity and speed.</li> <li>Use Case: Suitable for both site-to-site and remote access scenarios where performance and ease of configuration are priorities.</li> <li>Features:<ul> <li>Lightweight codebase, reducing attack surface and improving maintainability.</li> <li>Uses state-of-the-art cryptography (Curve25519, ChaCha20, Poly1305).</li> <li>Faster connection setup and lower latency compared to traditional VPN protocols.</li> <li>Easy configuration with minimal overhead.</li> </ul> </li> <li>Benefit: Delivers secure, efficient, and scalable VPN connectivity, particularly well-suited for modern cloud-native environments.</li> </ul> </li> </ul>"},{"location":"PaaS/#high-availability-and-failover","title":"High Availability and Failover","text":"<p>The service supports High availability State Synchronization (pfsync), enabling VPN session states synchronization (including IPsec tunnels) between VPN service Instances, so active VPN connections continue without interruption during failover. Configuration between instances is synchronized as well with a built in HA sync mechanism that replicates VPN configuration changes from the primary instance to the secondary.</p> <p>The service supports Border Gateway Protocol (BGP) to improve failover across IPsec VPN tunnels, to dynamically reroutes traffic in case of tunnel failure, ensuring uninterrupted connectivity. Multiple VPN connections per virtual network can be configured for redundancy and load balancing.</p>"},{"location":"PaaS/#security-and-compliance","title":"Security and Compliance","text":"<p>Leonardo is fully responsible for patching the VPN protocols and services, offering a secure, compliant environment without customer patching responsibilities.</p> <p></p>"},{"location":"PaaS/#paas-clientforward-proxy","title":"PaaS Client/Forward Proxy","text":""},{"location":"PaaS/#service-description_49","title":"Service Description","text":"<p>The Proxy service is a managed front-facing service designed to retrieve data from a wide range of sources across the internet. It acts as an intermediary between internal users and external services, ensuring that requests are securely handled and filtered before reaching their destination. The service is built on OPNsense, an open-source firewall and routing platform, and is delivered as a fully managed solution. This means that all necessary updates, patches, and maintenance are handled by the provider, allowing IT staff to focus on their applications and users rather than the underlying infrastructure.  </p>"},{"location":"PaaS/#features-and-advantages_52","title":"Features and Advantages","text":"<p>The Proxy service functions as a gateway. When a user inside the organization requests data from an external source, the request is first directed to Proxy. The service evaluates the request against configured rules and policies, determines whether it should be allowed or blocked, and then forwards it to the destination if permitted. Responses from external services are similarly inspected before being passed back to the user. This approach provides several benefits: it ensures that only authorized traffic leaves the network, it prevents malicious content from entering, and it gives administrators visibility into how users interact with external services.  </p> <p>Provisioning and Management </p> <p>Proxy can be provisioned through the Secure Cloud Management Platform, the central portal for managing cloud services. Administrators can deploy the service by selecting the Proxy option within the platform. Provisioning can also be performed through APIs, enabling integration into automated workflows. Once deployed, the service is automatically patched and maintained by the provider. This ensures that the system remains up to date with the latest security fixes without requiring manual intervention.  </p> <p>Authentication Integration </p> <p>Proxy supports integration with Active Directory and OpenID Connect for user authentication. This means that organizations can leverage their existing identity management systems to control access. - With Active Directory, Proxy can validate user credentials against the domain controller, ensuring that only authorized users are able to use the service. - With OpenID Connect, Proxy can redirect users to an identity provider for authentication, then use the returned tokens to grant access. This integration allows organizations to enforce consistent access policies across their environment without duplicating user management. </p> <p>Request Filtering </p> <p>Proxy supports both whitelisting and blacklisting of requests. Administrators can define rules that specify which destinations or types of requests are permitted and which are denied. For example, they may allow access to trusted business applications while blocking requests to known malicious domains. This filtering capability ensures that users can only access approved resources, reducing the risk of data leakage or exposure to harmful content.  </p> <p>Anti-Virus and Anti-Malware Protection </p> <p>Proxy includes integrated anti-virus and anti-malware scanning, typically powered by engines such as ClamAV. All traffic passing through the service can be inspected for malicious payloads, ensuring that harmful files or code are blocked before reaching users. This functionality provides an additional layer of defense, complementing endpoint protection and reducing the likelihood of infections spreading through downloaded content.  </p> <p>Scalability </p> <p>The Proxy service is designed as a fixed-capacity solution. It does not scale dynamically with demand. Administrators should plan usage accordingly, ensuring that the service is deployed in environments where its capacity is sufficient for the expected traffic load.  </p> <p></p>"},{"location":"PaaS/#paas-reverse-proxy","title":"PaaS Reverse Proxy","text":""},{"location":"PaaS/#service-description_50","title":"Service Description","text":"<p>The Managed Reverse Proxy service provides a secure and automated way to control and route traffic between external clients and internal applications. It is built on OPNsense and HAProxy, which is widely recognized for its performance and flexibility in handling web traffic. Delivered as a fully managed solution, Leonardo assumes responsibility for all patching, updates, and maintenance, ensuring that administrators benefit from a hardened and continuously updated platform.  </p>"},{"location":"PaaS/#features-and-advantages_53","title":"Features and Advantages","text":"<p>A reverse proxy sits in front of application servers and receives incoming requests from clients. Instead of exposing servers directly to the internet, the proxy terminates connections, applies configured rules, and forwards requests to the appropriate backend service. This architecture improves security, simplifies certificate management, and enables sophisticated traffic routing. The Managed Reverse Proxy service can be provisioned through the Secure Cloud Management Portal or via APIs. Once deployed, the CSP ensures that the underlying OPNsense system and HAProxy plugin remain patched and secure.  </p> <p>SSL/TLS termination </p> <p>The reverse proxy provides full support for SSL/TLS termination. This means that encrypted client connections are terminated at the proxy, where traffic is decrypted. Certificates can be uploaded and managed directly within the solution, and bound to frontends. </p> <p>A typical frontend definition might look like this:  </p> <pre><code>frontend https_frontend\n    bind *:443 ssl crt /etc/haproxy/certs/\n    mode http\n    option httplog\n</code></pre> <p>Here the proxy listens on port 443, terminates SSL/TLS using the certificate stored in <code>/etc/haproxy/certs/</code>, and then processes traffic in HTTP mode. Once decrypted, traffic can be inspected, filtered, or routed, and then forwarded to backend servers either as plain HTTP or re-encrypted if desired. This centralizes certificate management and reduces the complexity of maintaining certificates across multiple backend servers. HTTP Termination. In addition to SSL/TLS, the reverse proxy also supports HTTP termination. This allows the proxy to handle plain HTTP traffic directly, applying rules and routing logic before passing requests to backend servers. This is useful for internal services or applications that do not require encryption, and it ensures that both encrypted and unencrypted traffic can be managed consistently through the same proxy layer. </p> <p>Server Name Indication (SNI) compatibility </p> <p>The proxy is fully compatible with the Server Name Indication (SNI) extension of TLS. This capability allows the proxy to host multiple SSL/TLS certificates on a single IP address and port. When a client initiates a connection, the proxy uses the hostname provided in the SNI field to select the correct certificate. This makes it possible to serve multiple domains securely from the same proxy instance, a critical feature for organizations hosting multiple applications or services.  </p> <p>For example:  </p> <pre><code>frontend https_frontend\n    bind *:443 ssl crt /etc/haproxy/certs/domain1.pem crt /etc/haproxy/certs/domain2.pem\n    mode http\n</code></pre> <p>When a client connects, HAProxy inspects the SNI field in the TLS handshake and selects the appropriate certificate based on the requested hostname. This allows multiple domains to be served securely from a single proxy instance.  </p> <p>Routing Rules and Traffic Management </p> <p>One of HAProxy\u2019s most powerful features is its ability to define complex routing rules. Administrators can configure rules based on request attributes such as headers, paths, query strings, or even cookies. For example, traffic containing a specific header can be routed to one backend service, while requests with a different header are directed elsewhere. The proxy also supports load balancing strategies, health checks, and content switching. This means that traffic can be distributed across multiple backend servers to improve performance and reliability, or directed to specific servers depending on the nature of the request. The OPNsense HAProxy plugin provides a user-friendly interface for defining these rules, making it possible to implement sophisticated traffic management policies without requiring deep knowledge of HAProxy\u2019s configuration syntax.</p> <p>Below is an example of content switching, where traffic is routed depending on request attributes. For example, administrators may want to send requests with a specific header to one backend, and all other requests to another:  </p> <p><pre><code>frontend https_frontend\n    bind *:443 ssl crt /etc/haproxy/certs/\n    mode http\n    acl api_request hdr(X-Service) -i api\n    use_backend api_backend if api_request\n    default_backend web_backend\n</code></pre> In this configuration: - The <code>acl</code> (access control list) checks whether the request contains the header <code>X-Service: api</code>. - If the header is present, traffic is routed to <code>api_backend</code>. - All other requests are sent to <code>web_backend</code>. </p>"},{"location":"PaaS/#storage-family","title":"Storage Family","text":"<p>Below is the list of services belonging to the Storage family:</p> <ul> <li>Block Storage (1000 GB) - High Density</li> <li>Archive Storage (1000 GB)</li> </ul> <p></p>"},{"location":"PaaS/#block-storage-1000-gb-high-density-service","title":"Block Storage (1000 GB) - High Density Service","text":"<p> Block Storage (1000 GB) - High Density Service interface </p>"},{"location":"PaaS/#service-description_51","title":"Service Description","text":"<p>The PaaS Block Storage (1000 GB) \u2013 High Density service provides enterprise-grade, fully managed block storage volumes designed for virtual machines and cloud workloads hosted on Proxmox platforms. The storage layer is powered by Ceph, a distributed, fault-tolerant, and scalable SDS (Software-Defined Storage) technology that ensures durability, high availability, and efficient capacity utilization. This service offers 1000 GB of high-density block storage, ideal for workloads that require large capacity at optimized cost while still benefiting from redundancy, resiliency, and seamless integration into virtualized cloud environments.</p> <p>The service is offered with the following metrics: 1000 GB for each unit.</p>"},{"location":"PaaS/#features-and-advantages_54","title":"Features and Advantages","text":"<p>The main features of the service are:</p> <ul> <li>Managed block storage volumes (1000 GB) \u2192 provides fully provisioned 1000 GB block devices. Can be attached to Proxmox-based virtual machines. Supports OS disks, application data, databases, and file systems.</li> <li>High-density storage tier \u2192 optimized for workloads requiring large capacity. Uses cost-efficient high-density disks while maintaining reliability. Suitable for: archival data, moderately I/O-intensive applications, backup staging, large datasets that don\u2019t require ultra-high performance.</li> <li>Ceph RBD (RADOS Block Device) integration \u2192 volumes are exposed as Ceph RBD devices, enabling features like thin provisioning, snapshot support, cloning capabilities.</li> <li>High availability and data replication \u2192 data is replicated across multiple Ceph nodes. Ensures durability even in case of disk or node failure. Automatic recovery and self-healing functions enhance resilience.</li> <li>Persistent and Reliable Storage \u2192 volumes maintain data integrity across VM reboots, migrations, or failovers. Ideal for persistent disks in virtualized infrastructures.</li> <li>Seamless VM integration \u2192  managed directly through the Proxmox interface/API. It supports: VM disk attachments and detachments, live migration with attached volumes, dynamic resizing.</li> <li>Performance optimization for large-capacity workloads \u2192 balanced read/write response designed for high-density environments. Ceph intelligently distributes I/O across cluster nodes.</li> <li>Managed service \u2192 No need to manage Ceph clusters, disks, or replicating policies. Handling of: monitoring, maintenance, scaling, upgrades, fault resolution.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Ceph storage cluster \u2192 distributed architecture composed of Object storage nodes monitoring nodes for cluster coordination and manager nodes for cluster insight and APIs. Ensures high availability and horizontal scalability.</li> <li>Proxmox integration layer \u2192 Proxmox integrates directly with Ceph RBDs and provides unified API and management interface for VMs and storage. Allows dynamic allocation of block devices to VMs.</li> <li>Replicated storage pools \u2192 storage pools configured with replication. Ensures redundancy across multiple disks and hosts. Prevents data loss from node or disk failures.</li> <li>Data plane \u2192 handles all I/O operations, including data striping, replication, rebalancing, recovery, snapshot management. Designed for reliability and optimized throughput.</li> <li>Control plane \u2192 Manages Ceph cluster coordination, health monitoring, volume lifecycle, config policies, Proxmox integration.</li> <li>Monitoring and observability \u2192 continuous monitoring of storage utilization, disk health, replication status, I/O performance. Automated alerts ensure proactive issue resolution.</li> <li>Security and isolation \u2192 tenant isolation at storage pool and access level. Encrypted communication between Ceph and Proxmox nodes. Optional disk encryption at rest depending on policy.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>High capacity at optimized cost \u2192 designed for workloads needing large data volume without paying for premium performance tiers.</li> <li>High udrability and fault tolerance \u2192 multi-node replication ensures data remains safe even if disks or machines fail.</li> <li>Fully managed storage infrastructure \u2192 eliminates the need to configure, maintain, or troubleshoot Ceph clusters.</li> <li>Scalable and flexible \u2192 storage grows horizontally without downtime. Additional capacity or block volumes can be provisioned on demand.</li> <li>Seamless integration with Proxmox VM environments \u2192 easy attachment to VMs, live migration support, and simplified administration.</li> <li>Improved operational efficiency \u2192 snapshots, cloning, and thin provisioning speed up development and operations workflows.</li> <li>Consistent performance for high-density workloads \u2192 balanced I/O distribution with predictable storage behavior.</li> <li>Enhanced data protection \u2192 built-in replication, self-healing, and monitoring reduce risk of data loss.</li> <li>Simplified backup and recovery \u2192 volume snapshots enable fast backup operations. Easy rollback to previous storage states.</li> <li>Enterprise-grade reliability \u2192 Ceph\u2019s distributed architecture provides continuous service availability and resilience.</li> </ul> <p></p>"},{"location":"PaaS/#archive-storage-1000-gb-service","title":"Archive Storage (1000 GB) Service","text":"<p> Archive Storage (1000 GB) Service interface </p>"},{"location":"PaaS/#service-description_52","title":"Service Description","text":"<p>The service provides a scalable, low-cost, long-retention storage environment designed for infrequently accessed data. It is built on Proxmox Virtual Environment (PVE) with Ceph as the underlying distributed storage layer. The service enables organizations to store large volumes of archival datasets\u2014such as logs, backups, compliance records, media assets, or scientific data\u2014while ensuring durability, fault tolerance, and controlled retrieval performance.</p> <p>The service is offered with the following metrics: 1000 GB for each unit.</p>"},{"location":"PaaS/#features-and-advantages_55","title":"Features and Advantages","text":"<p>The main features of the service are:</p> <ul> <li>Long-term data retention with policies tailored for infrequently accessed objects or files</li> <li>Distributed, reliable storage through Ceph\u2019s replication or erasure coding.</li> <li>Scalable capacity expansion by adding nodes or OSDs without service interruption.</li> <li>Multi-protocol access via CephFS, RBD, or S3-compatible gateways, depending on deployment.</li> <li>Automated data placement and self-healing mechanisms inherent to Ceph.</li> <li>Role-based access control and integration with existing identity systems (via Proxmox and optional gateways).</li> <li>Monitoring and lifecycle management through Proxmox\u2019s UI and Ceph dashboards.</li> <li>Optional tiering by combining faster Ceph pools with lower-cost archival pools.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Proxmox VE Cluster \u2192 Management layer for nodes, resources, authentication, and integration with Ceph; offers UI, automation tools, and API endpoints.</li> <li>Ceph Cluster:<ul> <li>OSD Nodes: Storage servers providing replicated or erasure-coded archival pools.</li> <li>MON/MGR Nodes: Ceph Monitors and Managers responsible for cluster coordination, state tracking, and health management.</li> <li>CephFS / RBD / RGW: Optional access interfaces to expose archival storage as a filesystem, block device, or S3-compatible object store.</li> </ul> </li> <li>Networking Layer \u2192 High-bandwidth, redundant network for internal Ceph traffic (public and cluster networks) to ensure consistency and performance.</li> <li>Monitoring and Logging Tools \u2192 Proxmox and Ceph dashboards, Prometheus, and alerting integrations.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Cost-efficient retention \u2192 lower TCO for storing large datasets compared to high-performance primary storage.</li> <li>High durability and fault tolerance \u2192 data is protected through Ceph replication or erasure coding, reducing risk of data loss.</li> <li>Horizontal scalability \u2192 capacity and performance can grow incrementally without downtime, supporting evolving storage needs.</li> <li>Vendor independence \u2192 based on open technologies, minimizing lock-in and enabling custom tailoring.</li> <li>Operational simplicity \u2192 unified management from Proxmox with integrated monitoring, lifecycle management, and automation.</li> <li>Flexible access models \u2192 filesystem, block, or object interfaces allow integration with backup systems, archival workflows, and data management tools.</li> <li>Resilience and self-healing \u2192 ceph automatically redistributes and recovers data in case of disk or node failures, reducing administrative overhead.</li> <li>Compliance support \u2192 Suitable for long-term preservation and regulatory retention requirements.</li> </ul> <p></p>"},{"location":"PaaS/#disaster-recovery-process-for-block-and-archive-storages","title":"Disaster Recovery Process for Block and Archive Storages","text":"<p>The PaaS Block Storage service is delivered on a high-density storage architecture powered by Proxmox VE and a Ceph distributed storage cluster. Ceph provides native replication, self-healing and strong data durability. Disaster Recovery (DR) ensures service continuity, data integrity and rapid restoration in case of partial or full site failure.</p> <p>Disaster Recovery (DR) Objectives</p> <ul> <li>RPO (Recovery Point Objective): zero in an Availability Zone failure scenario, as Ceph writes are synchronously replicated across Zones.</li> <li>RTO (Recovery Time Objective): designed to be minimal. Recovery depends on the nature of the failure (node, rack, or site).</li> </ul> <p>DR Protection Levels</p> <ul> <li> <p>Full Availability Zone DR </p> <ul> <li>Block volumes are continuously replicated to a coupled Availability zone through synchronous replication leveraging Ceph stretched cluster and CRUSH maps. In case of complete outage of an Availability Zone, the coupled AZ already contains the RBD images, and workloads can be restored automatically, or by registering the affected compute instances to the live AZ. This allows for 0 RPO and a variable RTO that can span from 0 (automated failover) to minutes if automatic failover is not used.</li> </ul> </li> <li> <p>Full Region DR</p> <ul> <li>Inter-region mirroring can be enabled on a per-volume basis, allowing asynchronous replicas of data from any AZ of a given region to AZ of a paired region.</li> <li>Replication can be continuous or snapshots-based, with a minimum internal between snapshots of one minute.</li> <li>Recovery of impacted services to a new region is orchestrated by Leonard\u2019s Secure Cloud Management Platform where a DR plan.</li> </ul> </li> </ul> <p>Regional DR Process Workflow</p> <ul> <li> <p>Step 1 \u2013 Failure Detection</p> <ul> <li>The underlying storage continuously monitors the state of the storage nodes and cluster.</li> <li>Automatic alerts for: Disk or node failures, Network disruption, Replication degradation, Cluster reaching \u201cHEALTH_WARN\u201d or \u201cHEALTH_ERR\u201d</li> </ul> </li> <li> <p>Step 2 \u2013 Activation of workloads on the paired Region</p> <p>If the failure affects an entire Region:  - Administrators promote mirrored RBD images on the remote Ceph cluster. - Proxmox compute nodes at the DR site attach the promoted RBDs. - Services are restarted according to the failover plan.</p> </li> <li> <p>Step 3 \u2013 Service Validation</p> <ul> <li>Verification that Block Storage volumes are consistent and available.</li> <li>Checks of application logs and integrity validation.</li> </ul> </li> <li> <p>Step 4 \u2013 Failback (Post-Recovery)</p> <ul> <li>Once the primary Region is restored:<ul> <li>Data is synchronized back (reverse RBD mirroring).</li> <li>Primary cluster is reintroduced into production.</li> <li>Normal operations resume.</li> </ul> </li> </ul> </li> </ul>"},{"location":"Price/","title":"Service Price List","text":"<p>This section contains the price lists of the services for each family.</p> <p>For each service, you can choose from three alternative purchase options:</p> <ul> <li>Monthly Subscription with bimonthly payment in arrears;</li> <li>Annual Reserved Subscription with upfront payment upon activation and testing of the service;</li> <li>Three-year Reserved Subscription with upfront payment upon activation and testing of the service.</li> </ul> Family Service Unit Value PAYG (Monthly) 1Y Reserved 3Y Reserved Compute Pool Small (Confidential) Hosts number 3 Host Number (2x 24 Core CPU - 512 GB RAM - 32 TB SSD) 21.586,03 \u20ac 233.129,08 \u20ac 621.677,54 \u20ac Compute Pool Medium (Confidential) Hosts number 6 Host Number (2x 24 Core CPU - 512 GB RAM - 32 TB SSD) 34.560,46 \u20ac 373.252,97 \u20ac 995.341,26 \u20ac Compute Pool Large (Confidential) Hosts number 9 Host Number (2x 24 Core CPU - 512 GB RAM - 32 TB SSD) 47.344,20 \u20ac 511.317,32 \u20ac 1.363.512,84 \u20ac Compute Pool X-Large (Confidential) Hosts number 12 Host Number (2x 24 Core CPU - 512 GB RAM - 32 TB SSD) 62.304,31 \u20ac 672.886,55 \u20ac 1.794.364,13 \u20ac Compute VM Small (Confidential) Resource instance 2 VCPUs, 4 GB RAM per instance 37,25 \u20ac 402,30 \u20ac 1.072,80 \u20ac Compute VM Medium (Confidential) Resource instance 4 VCPUs, 8 GB RAM per instance 72,00 \u20ac 777,60 \u20ac 2.073,60 \u20ac Compute VM Large (Confidential) Resource instance 8 VCPUs, 16 GB RAM per instance 133,00 \u20ac 1.436,40 \u20ac 3.830,40 \u20ac Compute VM X-Large (Confidential) Resource instance 16 VCPUs, 32 GB RAM per instance 413,50 \u20ac 4.465,80 \u20ac 11.908,80 \u20ac Compute Kubernetes Confidential Computing Node worker 15 node workers with 8 GB RAM 10.499,77 \u20ac 113.397,52 \u20ac 302.393,38 \u20ac Price list of the Compute Family Services Family Service Unit Value PAYG (Monthly) 1Y Reserved 3Y Reserved Security Identity &amp; Access Management (IAM) Service concurrent Users 100 concurrent users 454,59 \u20ac 4.909,58 \u20ac 13.092,20 \u20ac Security Key Vault as a Service - Standard Client 500 clients 18.508,98 \u20ac 199.896,94 \u20ac 533.058,50 \u20ac Security Endpoint Protection Endpoint 100 endpoints 7.774,28 \u20ac 83.962,25 \u20ac 223.899,33 \u20ac Security NGFW Platform Throughput (Gbps) 1 1.148,53 \u20ac 12.404,11 \u20ac 33.077,64 \u20ac Security PAM (Privileged Access Management) Number of admin users 10 2.801,62 \u20ac 30.257,50 \u20ac 80.686,66 \u20ac Security Intrusion Prevention System (IPS) Throughput(Gbps) 1 7.541,19 \u20ac 81.444,88 \u20ac 217.186,36 \u20ac Price list of the Security Family Services Family Service Unit Value PAYG (Monthly) 1Y Reserved 3Y Reserved Middleware PaaS API Management Request 500M API request 24.900,56 \u20ac 268.926,08 \u20ac 717.136,23 \u20ac Middleware Functions As A Service (FAAS) VCPU 100 VCPUs 6.315,12 \u20ac 68.203,33 \u20ac 181.875,55 \u20ac Middleware Jboss as a Service Container 4 VCPUs-8GB RAM per container 537,78 \u20ac 5.808,04 \u20ac 15.488,10 \u20ac Middleware Spring boot as a Service Container 16 GB RAM for container 651,62 \u20ac 7.037,54 \u20ac 18.766,76 \u20ac Middleware PaaS Business Process as a Service Istance 8 VCPUs-16 GB RAM per istance 12.755,33 \u20ac 137.757,60 \u20ac 367.353,61 \u20ac Middleware PaaS CMS as a Service User 1000 users 5.722,14 \u20ac 61.799,09 \u20ac 164.797,57 \u20ac Middleware Semantic Knowledge Search Container 8 VCPUs-16 GB RAM per container 244,06 \u20ac 2.635,81 \u20ac 7.028,84 \u20ac Price list of the Middleware Family Services Family Service Unit Value PAYG (Monthly) 1Y Reserved 3Y Reserved Data Protection Backup Platform TB 1 30,52 \u20ac 329,62 \u20ac 879,00 \u20ac Price list of the Data Protection Family Services Family Service Unit Value PAYG (Monthly) 1Y Reserved 3Y Reserved Infra &amp; Ops Platform Multicloud Management Platform Volume Managed &lt;1MEuro or 5 TB RAM 8.621,22 \u20ac 93.109,16 \u20ac 248.291,09 \u20ac Infra &amp; Ops Platform IT infrastructure Service Operations (Logging &amp; Monitoring) GB 1GB for data storage 244,06 \u20ac 2.635,81 \u20ac 7.028,84 \u20ac Infra &amp; Ops Platform PaaS Ticket Management Service Number of Service Desk Operators 50 operators 7.136,65 \u20ac 77.075,77 \u20ac 205.535,38 \u20ac Infra &amp; Ops Platform PaaS Operations Management Concurrent users 25 concurrent users 13.899,53 \u20ac 150.114,91 \u20ac 400.306,42 \u20ac Price list of the Infra &amp; Ops Platform Family Services Family Service Unit Value PAYG (Monthly) 1Y Reserved 3Y Reserved DevSecOps Configuration Manager Managed worker 25 managed workers 494,25 \u20ac 5.337,86 \u20ac 14.234,29 \u20ac DevSecOps Test Automation User 10 automation testers- concurrent, 5 Robots 13.057,79 \u20ac 141.024,08 \u20ac 376.064,22 \u20ac DevSecOps Quality Code Analysis lines codes 1M lines codes 8.486,66 \u20ac 91.655,89 \u20ac 244.415,71 \u20ac DevSecOps DevSecOps As A Service User 100 Users Ultimate/500 Users premium/2000 Free 25.006,90 \u20ac 270.074,54 \u20ac 720.198,78 \u20ac DevSecOps Qualizer DevSecOps Project 10 Projects 10.010,65 \u20ac 108.115,00 \u20ac 288.306,67 \u20ac Price list of the DevSecOps Family Services Family Service Unit Value PAYG (Monthly) 1Y Reserved 3Y Reserved Big Data Data Lake TB 1 TB 25,23 \u20ac 279,00 \u20ac 744,00 \u20ac Big Data Data Lake-Cold TB 1 TB 23,25 \u20ac 251,10 \u20ac 669,60 \u20ac Big Data Business Intelligence Platform User 100 users 8.365,83 \u20ac 90.351,00 \u20ac 240.936,01 \u20ac Big Data PaaS ETL Batch/Real time Processing Worker node 16 vCPU-128 GB RAM per worker 608,48 \u20ac 6.571,54 \u20ac 17.524,11 \u20ac Big Data Event Message Worker node 16 vCPU-128 GB RAM per worker 291,29 \u20ac 3.145,95 \u20ac 8.389,20 \u20ac Big Data Data Governance User 10 users 461,45 \u20ac 4.983,68 \u20ac 13.289,82 \u20ac Price list of the Big Data Family Services Family Service Unit Value PAYG (Monthly) 1Y Reserved 3Y Reserved AI Speech to Text GPU 1 partition H200 2.819,93 \u20ac 30.455,25 \u20ac 81.214,00 \u20ac AI PaaS-AI Audio Analytics GPU 1 GPU partition H200 219,65 \u20ac 2.372,23 \u20ac 6.325,95 \u20ac AI PaaS-AI Video Analytics GPU 1 GPU H200 648,28 \u20ac 7.001,38 \u20ac 18.670,35 \u20ac AI OCR Container 16 GB RAM per container 1.109,42 \u20ac 11.981,77 \u20ac 31.951,40 \u20ac AI Text Analytics/NLP GPU 1 partition H200 393,54 \u20ac 4.250,25 \u20ac 11.334,00 \u20ac AI Translation GPU 1 GPU H200 18.247,86 \u20ac 197.076,90 \u20ac 525.538,40 \u20ac AI AI Search-RAG GPU 1 GPU H200 23.305,31 \u20ac 251.697,33 \u20ac 671.192,88 \u20ac AI AI Platform GPU 1 GPU H200 1.281,30 \u20ac 13.838,03 \u20ac 36.901,40 \u20ac AI AI SLM GPU 1 partition GPU H200 6.896,91 \u20ac 74.486,63 \u20ac 198.631,00 \u20ac AI AI LLM GPU 1 GPU H200 30.824,01 \u20ac 332.899,28 \u20ac 887.731,41 \u20ac Price list of the Artificial Intelligence (AI) Family Services Family Service Unit Value PAYG (Monthly) 1Y Reserved 3Y Reserved Collaboration Instant Messaging Users 1000 users 67.785,44 \u20ac 732.082,73 \u20ac 1.952.220,60 \u20ac Price list of the Collaboration Services Family Service Unit Value PAYG (Monthly) 1Y Reserved 3Y Reserved Database PaaS SQL-PostgreSQL DB Instance 4 vCPUs-16 GB RAM per instance(with replication) 550,42 \u20ac 5.944,50 \u20ac 15.851,99 \u20ac Database PaaS SQL-MariaDB DB Instance 4 vCPUs-16 GB RAM per istance(with replication) 601,71 \u20ac 6.498,45 \u20ac 17.329,20 \u20ac Database PaaS SQL-MS SQL Server EE DB Instance 8 vCPUs-16 GB RAM per instance 4.909,78 \u20ac 53.025,66 \u20ac 141.401,76 \u20ac Database PaaS SQL-MS SQL Server EE (BYOL) DB Instance 8 vCPUs-16 GB RAM per instance 212,27 \u20ac 2.292,49 \u20ac 6.113,31 \u20ac Database PaaS GraphDB DB Instance 4 vCPUs-16 GB RAM per instance 1.873,84 \u20ac 20.237,47 \u20ac 53.966,58 \u20ac Database PaaS NoSQL-MongoDB DB Instance 4 vCPUs-16 GB RAM per istance(with replication) 1.172,65 \u20ac 12.664,62 \u20ac 33.772,33 \u20ac Database PaaS In Memory-Redis DB Instance 4 vCPUs-16 GB RAM per istance 1.873,84 \u20ac 20.237,47 \u20ac 53.966,58 \u20ac Price list of the Database Family Services Family Service Unit Value PAYG (Monthly) 1Y Reserved 3Y Reserved Networking PaaS CDN (Content Delivery Network) Throughput 10 Gbps(inbound &amp; Outbound) 10 566,00 \u20ac 6.112,80 \u20ac 16.300,80 \u20ac Networking PaaS Domain Name System (DNS) DNS Instance 1 3.899,57 \u20ac 42.115,37 \u20ac 112.307,66 \u20ac Networking Single public IP #Public IP 1 4,67 \u20ac 50,40 \u20ac 134,40 \u20ac Networking L7 Load Balancer (regional) Instance 1 994,08 \u20ac 10.736,04 \u20ac 28.629,43 \u20ac Networking Cloud interconnect Gold SW (10 Gbps max throughput) Throughput(Gbps) 10 9.112,76 \u20ac 98.417,78 \u20ac 262.447,40 \u20ac Price list of the Networking Family Services Family Service Unit Value PAYG (Monthly) 1Y Reserved 3Y Reserved Storage Block Storage (1000 GB) - High Density GB 1000 GB 107,24 \u20ac 1.158,24 \u20ac 3.088,65 \u20ac Storage Archive Storage (1000 GB) GB 1000 GB 96,52 \u20ac 1.042,42 \u20ac 2.779,78 \u20ac Price list of the Storage Services Family Service Unit Value PAYG (Monthly) 1Y Reserved 3Y Reserved Hybrid Edge Location-Pool Small (Confidential) Host number 3 Hosts of: 2x24 Core CPU-512 GB RAM-32 TB SSD 21.586,03 \u20ac 233.129,08 \u20ac 621.677,54 \u20ac Price list of the Hybrid Services"},{"location":"Provisioning/","title":"Service Provisioning","text":"<p>In this section you can find information about the provisioning of the services offered, depending on their type.</p>"},{"location":"Provisioning/#creation-of-provisionings","title":"Creation of Provisionings","text":""},{"location":"Provisioning/#provisioning-of-physical-resources","title":"Provisioning of \"Physical Resources\"","text":"<p>Generally, service provisioning is done through the Leonardo Security Cloud Management Platform console. Using the tabs in the console's provisioning functionality, you can view lists of provisionable resources, such as Virtual Machines, Storage, and Kubernetes. The features available for these items are identical; only the parameters entered during creation differ.</p> <p> Tabs for resource creation </p>"},{"location":"Provisioning/#provisioning-of-virtual-machines","title":"Provisioning of Virtual Machines","text":"<p>To start provisioning a resource, click on the corresponding row to view the page containing step 1 of provisioning creation. In this step, it is necessary to select, using the dropdown on the left, the \"target\" subsystem where the resources are to be provisioned. Once selected, an information mirror will be displayed on the right indicating the characteristics of the resource that will be provisioned. To continue, click the \"Next\" button at the bottom right to go to step 2 \"Config\" page.</p> <p> Selection of the \u201ctarget\u201d subsystem, provisioning step 1 </p> <p>On the \"Config\" page of step 2, fill in all mandatory fields in all sections of the form. At the bottom left, click the \"Reset\" button to reset all fields on the page.</p> <p>Instead, on the right, click the \"Submit\" button to go to step 3 \"Plan\".</p> <p> Filling in the resource prediction form fields </p> <p>After clicking the \"Submit\" button, the user is redirected to the \"Plan\" page of step 3 where we can view the provisioning plan sent by Terraform, which indicates all the parameters of the resources that will be configured, and at the bottom, there is a list with a cost perspective.</p> <p> Forecast screen </p> <p>Still from the \"Plan\" page of step 3, at the bottom right, there are three buttons: \"Back\", \"Reset\", and \"Apply\". If you click the \"Back\" button, the user returns to the \"Config\" page of step 2 where parameters can be modified.</p> <p>If you click the \"Reset\" button, the user is redirected to the \"Subscription\" page of step 1 where it is necessary to select a subsystem, and then enter the parameters on the \"Config\" page of step 2.</p> <p>Finally, if you click the \"Apply\" button, the forecast is saved, and the user is redirected to the \"Dashboard\" tab page where the user verifies the presence of the newly created forecast.</p> <p> List of provisionings performed </p>"},{"location":"Provisioning/#provisioning-of-services","title":"Provisioning of \"Services\"","text":"<p>To access the services page, click on the tab that depicts a shelf located in the top menu. After doing this, you will find yourself on the \"Service\" page.</p> <p> List of cards </p> <p>On the page, a list of components called \"Card\" is displayed. Each card refers to a specific type of service; in particular, the following information is displayed:</p> <ul> <li>Service name;</li> <li>Service icon;</li> <li>Type of script used for service provisioning;</li> <li>Service description;</li> <li>\"Subscribe\" button to proceed with service creation.</li> </ul> <p>Depending on the type of service selected, the steps for provisioning change; these will be analyzed in detail below.</p>"},{"location":"Provisioning/#standard-services","title":"\"Standard\" Services","text":"<p>Click the \"Subscribe\" button corresponding to a \"standard\" service. The user will be redirected to step 1 of the service creation page, and all instantiable versions of the service by SCMP will be displayed. In particular, various blocks will be shown, each with a list of configurations:</p> <ul> <li>Name and version of the service that will be instantiated.</li> <li>Name and version of the operating system that will be installed on the machine.</li> <li>Belonging provider on which the service will be provisioned.</li> </ul> <p> Provisioning of a \"standard\" service </p> <p>Select a software version and press the \"Continue\" button; the user is redirected to step 2 of service provisioning.</p> <p>In step 2, it will be necessary to select a subsystem and fill out the form with the details of the chosen subsystem.</p> <p> Configuration of a \"standard\" service </p> <p>After completing all the form fields, click \"Submit\".</p> <p>A request will be sent to the Terraform service, which will validate the activation configuration of the indicated flow and return the result.</p> <p> Service configuration summary </p> <p>Click \"Apply\" to validate the flow and activate the service subscription.</p> <p>The dashboard page will open with the list of all subscribed services and their relative statuses. Specifically, the newly provisioned service will have a \"Running\" status in yellow, and subsequently, depending on the result, the status will also be updated to \"Completed\" in green or \"Error\" in red.</p> <p> Dashboard with the list of all subscribed services and their relative statuses </p>"},{"location":"Provisioning/#custom-services","title":"\"Custom\" Services","text":"<p>Click the \"Subscribe\" button corresponding to a \"custom\" service. The user will be redirected to step 1 of the service creation page where the subsystem can be selected, in which to perform the provisioning, from the dropdown in the center of the page.</p> <p> Provisioning of a \u201cCustom\u201d service </p> <p>By selecting the subsystem, the page updates to proceed to step 2 of service provisioning.</p> <p>In this step 2, it will be necessary to fill out the form with the specific configuration parameters of the selected service.</p> <p> Configuration of a \"custom\" service </p> <p>After completing all the form fields, click \"Launch\".</p> <p>A request will be sent to the Terraform service, which will validate the activation configuration of the indicated flow and return the result.</p> <p> Service configuration summary </p> <p>Click \"Apply\" to validate the flow and start the automatic configuration operations.</p> <p>The dashboard page will open with the list of all subscribed services and their relative statuses.</p> <p>Specifically, the newly provisioned service will have a \"Running\" status in yellow, and subsequently, depending on the result, the status will also be updated to \"Completed\" in green or \"Error\" in red.</p> <p> Dashboard with the list of all subscribed services and their relative statuses </p>"},{"location":"Provisioning/#paas-and-ai-services","title":"\"PaaS\" and \"AI Services\"","text":"<p>Click the \"Subscribe\" button corresponding to a \"PaaS\" service. The user will be redirected to step 1 of the service creation page where it will be necessary to fill out the form with the specific configuration parameters of the selected service.</p> <p> Configuration of a \"PaaS\" service </p> <p>After completing all the form fields, click \"Launch\".</p> <p>The dashboard page will open with the list of all subscribed services and their relative statuses.</p> <p>Specifically, the newly provisioned service will have a \"Running\" status in yellow, and subsequently, depending on the result, the status will also be updated to \"Completed\" in green or \"Error\" in red.</p> <p> Dashboard with the list of all subscribed services and their relative statuses </p>"},{"location":"Provisioning/#modification-of-a-performed-provisioning","title":"Modification of a performed provisioning","text":"<p>For a provisioning that has been carried out and has failed, it is possible to modify it.</p> <p>Provisioning modification is only available for resource types.</p> <p>To start modifying a provisioning, click on a failed forecast.</p> <p> Start modification of a Provisioning </p> <p>After doing so, you will find yourself on the \"Config\" page of step 2 where you can modify the previously entered parameters.</p> <p> Configuration parameters </p> <p> Modification of parameters </p> <p>After modifying the necessary parameters, at the bottom right, click the \"Submit\" button.</p> <p>By doing so, you will find yourself on the \"Plan\" page of step 3, where the forecast is present, and below, the quote table.</p> <p>At the bottom right, click the \"Apply\" button. After clicking the \"Apply\" button, you will find yourself on the \"Dashboard\" tab page.</p> <p>Subsequently, from the \"Dashboard\" page, the user notes that the modification was successful.</p> <p>It is also possible to modify a failed provisioning for other elements managed by SCMP.</p> <p> Provisioning summary and quote table </p>"},{"location":"Reference/","title":"Kubernetes Reference Architecture","text":""},{"location":"Reference/#overview","title":"Overview","text":"<p>This reference architecture describes the recommended baseline design for running containerized applications on Leonardo Cloud Leonardo Kubernetes Service (LKS). It provides a secure, scalable, production-ready foundation aligned with cloud best practices for networking, identity, security, observability, DevOps, and resilience.</p> <p>This baseline architecture is suitable for most production workloads and is the recommended starting point for any Kubernetes deployment on Leonardo Cloud.</p>"},{"location":"Reference/#architecture-components","title":"Architecture Components","text":""},{"location":"Reference/#leonardo-kubernetes-service-lks","title":"Leonardo Kubernetes Service (LKS)","text":"<p>LKS provides a fully managed Kubernetes control plane offering:</p> <ul> <li>High-availability master nodes</li> <li>Automatic patching and upgrades</li> <li>Secure API endpoints integrated with Leonardo Cloud IAM</li> <li>Managed certificates and control-plane hardening</li> <li>Unified lifecycle management (create, scale, upgrade, delete)</li> </ul> <p>Customers interact only with the Kubernetes API; Leonardo Cloud operates and secures the control plane.</p>"},{"location":"Reference/#node-pools","title":"Node Pools","text":"<p>Node pools provide the compute layer and support:</p> <ul> <li>System node pool \u2192 hosts core Kubernetes components</li> <li>Multiple pool types (CPU-optimized, RAM-optimized, GPU-backed)</li> <li>Auto-healing nodes</li> <li>Manual or automatic scaling</li> <li>Managed node image lifecycle</li> </ul>"},{"location":"Reference/#network-architecture","title":"Network Architecture","text":""},{"location":"Reference/#virtual-networks","title":"Virtual Networks","text":"<p>LKS clusters are deployed into a customer-managed Virtual Network (VNet). The recommended configuration includes:</p> <ul> <li>SubnetDescription \u2192 Control-plane subnet</li> <li>Restricted subnet for accessing the Kubernetes API (managed by Leonardo Cloud) \u2192 Node subnet(s)</li> <li>Hosts system and user node pools</li> <li>Ingress subnet</li> <li>Load-balanced entrypoints (public or private) \u2192 Private services subnet</li> <li>Internal services such as databases, caches, message brokers</li> </ul> <p>Pod CIDR and service CIDR must not overlap with customer VNets.</p>"},{"location":"Reference/#pod-and-service-networking","title":"Pod and Service Networking","text":"<p>Leonardo Cloud LKS uses a cloud-integrated CNI supporting:</p> <ul> <li>Stable pod IP allocation</li> <li>Network policy enforcement</li> <li>Native routing within the VNet</li> <li>Egress governance &amp; logging</li> </ul> <p>Service CIDRs provide stable virtual IPs for Kubernetes services.</p>"},{"location":"Reference/#ingress-load-balancing","title":"Ingress &amp; Load Balancing","text":"<p>Customers can expose applications via:</p> <ul> <li>Layer-7 ingress with managed controllers </li> <li>Private internal load balancers</li> <li>Public load balancers*, optionally fronted by a WAF</li> </ul> <p>Ingress provides TLS termination, routing rules, and isolation between environments.</p>"},{"location":"Reference/#identity-access-control","title":"Identity &amp; Access Control","text":""},{"location":"Reference/#leonardo-cloud-iam-integration","title":"Leonardo Cloud IAM Integration","text":"<p>LKS authentication is fully integrated with Leonardo Cloud Identity and Access Management (IAM):</p> <ul> <li>SSO integration with enterprise identity providers</li> <li>Multifactor authentication</li> <li>Workload identities and service principals</li> <li>Role-based API access to cluster endpoints</li> </ul> <p>Authorization uses Kubernetes RBAC and supports fine-grained controls.</p>"},{"location":"Reference/#recommended-rbac-model","title":"Recommended RBAC Model","text":"<p>Typical baseline roles: - Cluster Admins \u2192 full administrative access - Namespace Operators \u2192 developer teams isolated by namespace - Service Accounts \u2192 least-privilege identities for workloads</p> <p>Quota policies and network policies help enforce multi-tenancy boundaries.</p>"},{"location":"Reference/#security-best-practices","title":"Security Best Practices","text":""},{"location":"Reference/#control-plane-security","title":"Control Plane Security","text":"<ul> <li>Fully isolated, managed, and hardened control plane</li> <li>Encrypted API traffic</li> <li>Optional private-only cluster endpoints</li> <li>Automated certificate rotation</li> </ul>"},{"location":"Reference/#node-and-runtime-security","title":"Node and Runtime Security","text":"<ul> <li>Leonardo Cloud hardened node OS image</li> <li>Automatic security and kernel patching</li> <li>Enforcement of Kubernetes Pod Security Standards</li> <li>Optional OPA/Gatekeeper policies</li> <li>Encrypted secrets using KMS integration</li> </ul>"},{"location":"Reference/#network-security","title":"Network Security","text":"<ul> <li>Built-in Kubernetes Network Policies</li> <li>Per-namespace ingress/egress control</li> <li>Integration with Leonardo Cloud Firewall</li> <li>Optional WAF for HTTP(S) ingress</li> </ul>"},{"location":"Reference/#image-security","title":"Image Security","text":"<ul> <li>Scanning in Leonardo Cloud Container Registry</li> <li>Support for image signing &amp; attestation</li> <li>Policy-based enforcement for trusted registries</li> </ul>"},{"location":"Reference/#resilience-business-continuity","title":"Resilience &amp; Business Continuity","text":""},{"location":"Reference/#high-availability","title":"High Availability","text":"<ul> <li>Multi-zone support for node pools (when available)</li> <li>Multiple replicas for control-plane components</li> <li>Pod anti-affinity &amp; topology spread constraints</li> <li>Recommended use of Pod Disruption Budgets (PDBs)</li> </ul>"},{"location":"Reference/#backups","title":"Backups","text":"<p>Customers should:</p> <ul> <li>Use Velero for application-level backups</li> <li>Use Leonardo Cloud Storage snapshots for persistent volumes</li> <li>Perform regular recovery validation</li> </ul>"},{"location":"Reference/#disaster-recovery","title":"Disaster Recovery","text":"<p>For mission-critical applications:</p> <ul> <li>Deploy across multiple clusters or regions</li> <li>Store manifests in Git for reproducible redeployment</li> <li>Use replicated or multi-zone storage classes</li> <li>Enable cross-region backup replication</li> </ul>"},{"location":"Reference/#observability","title":"Observability","text":""},{"location":"Reference/#native-observability-integration","title":"Native Observability Integration","text":"<p>Leonardo Cloud LKS integrates with the Leonardo Cloud Monitor service, supporting:</p> <ul> <li>Node and pod metrics</li> <li>Container and system logs</li> <li>Alerts &amp; dashboards</li> <li>Optional distributed tracing</li> </ul> <p>Observability agents are automatically deployed in the system pool.</p>"},{"location":"Reference/#customer-observability-options","title":"Customer Observability Options","text":"<p>You may deploy:</p> <ul> <li>Prometheus + Grafana</li> <li>Loki / Elasticsearch for logs</li> <li>Jaeger or Tempo for distributed tracing</li> </ul> <p>All can ship logs and metrics to Leonardo Cloud Monitor.</p>"},{"location":"Reference/#devops-gitops","title":"DevOps &amp; GitOps","text":""},{"location":"Reference/#continuous-deployment","title":"Continuous Deployment","text":"<p>LKS supports:</p> <ul> <li>GitOps (Argo CD, Flux CD)</li> <li>CI/CD pipelines (GitHub Actions, GitLab CI, Jenkins, Azure DevOps, etc.)</li> <li>Helm + OCI registry integration</li> <li>Kustomize manifests</li> </ul>"},{"location":"Reference/#recommended-practices","title":"Recommended Practices","text":"<ul> <li>Store manifests in Git (declarative infrastructure)</li> <li>Use GitOps for automated reconciliation</li> <li>Enforce policy-as-code in CI/CD pipelines</li> <li>Separate environments (dev, test, prod) with isolated namespaces and networks</li> </ul>"},{"location":"Reference/#storage-architecture","title":"Storage Architecture","text":""},{"location":"Reference/#storage-classes","title":"Storage Classes","text":"<p>Leonardo Cloud provides multiple storage classes:</p> <ul> <li>General Purpose SSD</li> <li>High-Performance NVMe</li> <li>Replicated Storage for high availability</li> </ul> <p>All support:</p> <ul> <li>Dynamic provisioning</li> <li>Persistent Volume (PV) expansion</li> <li>Snapshots and cloning</li> </ul>"},{"location":"SLA/","title":"Service Level Agreement (SLA)","text":"<p>This section defines the terms, metrics, and service commitments applicable to the services offered and described.</p>"},{"location":"SLA/#availability-calculation","title":"Availability calculation","text":"<p>The Uptime Annual Percentage of the services is determined as follows:</p> <p> Annual Uptime Percentage </p> <p>The Uptime Percentage is calculated as Maximum Available Minutes less Downtime divided by Maximum Available Minutes, where:</p> <ul> <li>\"Maximum Available Minutes\" indicates the total number of minutes per year during which the service is active, excluding any communicated maintenance windows.</li> <li>\"Downtime\" indicates the total accumulated minutes that fall within the Maximum Available Minutes and are not subject to service availability.</li> </ul>"},{"location":"SLA/#service-credits-refunds","title":"Service credits refunds","text":"<p>The Customer is entitled to the following credits refunds in the event of failure to meet the following availability levels:</p> Uptime Percentage Service Credit &lt; 99.90% 5% &lt; 99% 10% &lt; 90% 15%"},{"location":"Security/","title":"Cyber Security Services","text":"<p>This section lists the Cyber Security specifications and services provided by Leonardo Security Operation Centre (SOC).</p>"},{"location":"Security/#security-services-for-detection","title":"Security services for detection","text":""},{"location":"Security/#real-time-security-monitoring-rtsm","title":"Real time Security Monitoring (RTSM)","text":"<p>Real time security incident management services provided by Leonardo Security Operation Centre (SOC)   assure real time notifications about security alarms, behaviour anomalies and potential threats, leveraging best of breed detection platforms capabilities and Leonardo SOC analysts\u2019 skills and knowledge base.</p> <p>Services\u2019 Deliverable</p> <ul> <li>Security alarms real time notification.</li> <li>Periodical reports for misconfigurations and low severity security evidences.</li> <li>Tuning process support.</li> <li>First level analysis and support in security incidents.</li> </ul> <p>Services Included</p> <ul> <li>Real Time Security Monitoring (RTSM) \u2192 delivers continuous monitoring of customer security devices/systems logs in order to quickly identify potentially harmful resources or events. </li> <li>Managed Endpoint Detection &amp; Response (MDR) \u2192 to provide customers with fast and effective  protection for their endpoints, leveraging Endpoint Detection and Response cloud-based technologies.</li> </ul> <p>Benefits</p> <ul> <li>Increases cyber situational awareness and faster identification of compromise whenit occurs.</li> <li>Reduce the impact of security incidents through quicker more informed response.</li> <li>Continuous monitoring of endpoints\u2019 events and activities through advanced analysis.</li> </ul>"},{"location":"Security/#threat-intelligence","title":"Threat Intelligence","text":"<p>The Threat Intelligence Services monitor and analyse large amounts of data, both open source and on the deep and dark web, to identify ongoing cyber-attacks or those being planned. The service also identifies cyber threat actors\u2019 activities and information illegally stolen and published on the web. The solution also provides a comprehensive overview on brand or event sentiment, and guidance on the prevention of cyber frauds.</p> <p>Services\u2019 Deliverable</p> <ul> <li>Periodical or event-based threat  intelligence reports.</li> <li>Tailored Investigation reports on customer request.</li> </ul> <p>Services Included</p> <ul> <li>Data breach \u2192 detects any data loss relating to a specific target of information through real-time monitoring of the network, including scanning of the deep and dark Web. </li> <li>Black market monitoring \u2192 analyses large quantities of information  from open sources, deep and dark Web, in real time, to promptly identify new black markets  and illegal activities on specific  issues of interest. </li> <li>Pre-planned attack \u2192 allows you to identify and predict possible new cyber-attacks more effectively, through real-time analysis of large quantities of information from open sources and    the deep and darknet. </li> <li>Identity fraud detection \u2192 detects unauthorised use of a person\u2019s digital  dentity to carry out illegal activities and/or defamatory actions without the knowledge of, and to the detriment of the  individual.</li> <li>Anti-phishing \u2192 manages the detection of ongoing phishing attacks against the customer, the real-time identification of ongoing fra udtowards their brand and the protection of online reputation.</li> </ul> <p>Benefits</p> <ul> <li>Increases cyber situational prevention of company-owned data loss. </li> <li>Sentiment analysis. </li> <li>Black market related illegal activities identification.</li> <li>Prevention against new planned cyber-attacks. </li> <li>Protection of VIPs\u2019 and Company online reputation. </li> <li>Customer digital identity protection / identity theft identification. </li> <li>Real time detection of cyber frauds and phishing attacks identification.</li> </ul>"},{"location":"Security/#security-services-for-respoding","title":"Security services for respoding","text":""},{"location":"Security/#computer-security-incident-response-team-services","title":"Computer Security Incident Response Team Services","text":"<p>The Computer Security Incident Response Team Services (CSIRT) identify and analyse the most advanced cyber threats capable of bypassing traditional automatic defensive measures, through the identification of root cause, attacker behaviour, relevant artefacts, and compromised assets within the monitored infrastructures. The CSIRT services deeply analyse and react to security incidents, minimising the operational and economic impacts of the security incident as effectively as possible, through the definition of the most rapid and effective incident response strategy. </p> <p>Services\u2019 Deliverable</p> <ul> <li>Artifacts analysis and reports.</li> <li>Containment and mitigation activities.</li> <li>Incident response reports.</li> <li>Remediation and restoration technical support.</li> <li>Security evidences and artifacts.</li> <li>Compromise assessment report </li> </ul> <p>Services Included</p> <ul> <li>Incident Response \u2192 combines specialist capability in incident management and investigation to deliver comprehensive advice and technical analysis in response to any cyber security attack or breach. </li> <li>Malware Analysis \u2192 acquires and classifies suspected malicious files (samples), provides hash control, comparison with known malware, behaviour analysis in order to identify any indicators of compromise and any containment actions to put in place. </li> <li>Threat Hunting \u2192 proactively identifies, isolates and neutralises the most advanced cyber threats that are capable of bypassing traditional automatic defensive measures before they can cause real damage to the organization. </li> <li>Compromise Assessment \u2192 provides the customer with a complete view of the current situation in terms of potential threats or ongoing malicious activities leveraging the capabilities of an Endpoint Detection &amp; Response (EDR) solution.</li> </ul> <p>Benefits</p> <ul> <li>Identification of Indicators of Compromise and any containment actions to put in place.</li> <li>Capability to isolate systems while preserving evidences. </li> <li>Specialised support to carry out the remediation and restoration of systems. </li> <li>Indications regarding the actions needed to mitigate future incidents.</li> </ul>"},{"location":"Security/#penetration-testing-offering-policy-for-managed-services","title":"Penetration Testing Offering Policy for Managed Services","text":"<p>This policy defines guidelines, requirements, responsibilities, and constraints for performing penetration testing on environments managed by the provider under the following service models:</p> <ul> <li>IaaS \u2013 Infrastructure as a Service</li> <li>PaaS \u2013 Platform as a Service</li> <li>CaaS \u2013 Container as a Service</li> <li>Hybrid \u2013 on-premise + cloud environments</li> </ul> <p>The objective is to ensure a controlled, safe, and authorized approach to offensive security activities without compromising service availability or violating cloud governance rules.</p>"},{"location":"Security/#general-principles","title":"General Principles","text":"<ol> <li>Penetration testing activities must be pre-authorized by the provider and conducted in compliance with applicable laws and contractual conditions.  </li> <li>Customers must restrict testing to resources they fully own or administer.  </li> <li>Activities must not compromise the stability of the provider\u2019s core services nor affect other customers.  </li> <li>The policy follows the guiding principle: \"Test only what you own and only in ways that don\u2019t impact other tenants\"</li> </ol>"},{"location":"Security/#penetration-testing-scope","title":"Penetration Testing Scope","text":""},{"location":"Security/#iaas-services","title":"IaaS Services","text":"<p>Allowed: - Vulnerability assessments and penetration testing on:   - Virtual machines, OS configurations, hosted applications   - Virtual network configurations (NSG, firewall, routing)   - Storage, databases, and customer-installed components - Authentication, authorization, and remote access testing on VMs  </p> <p>Not Allowed / Restricted:</p> <ul> <li>Real or simulated DoS/DDoS without explicit agreement  </li> <li>Stress testing shared IaaS platforms  </li> <li>Targeting physical infrastructure, hypervisors, or fabric-level services</li> </ul>"},{"location":"Security/#paas-services","title":"PaaS Services","text":"<p>Allowed:</p> <ul> <li>Testing applications and data deployed by the customer  </li> <li>Security configuration and identity-related tests  </li> <li>API, endpoint, permission, and customer-managed storage validation  </li> </ul> <p>Not Allowed / Restricted:</p> <ul> <li>Attacks on the underlying provider-managed PaaS infrastructure  </li> <li>Attempts to bypass tenant isolation  </li> <li>Tests that may degrade service SLAs</li> </ul>"},{"location":"Security/#caas-container-kubernetes-services","title":"CaaS (Container / Kubernetes) Services","text":"<p>Allowed:</p> <ul> <li>Analysis of customer-owned container images  </li> <li>Testing workloads, microservices, ingress, API, and application-level RBAC  </li> <li>Validation of customer-managed cluster networking  </li> <li>Testing secrets, config maps, and identity integrations  </li> </ul> <p>Not Allowed / Restricted:</p> <ul> <li>Container escape attempts targeting physical nodes  </li> <li>Attacks on the control plane if provider-managed  </li> <li>Testing shared provider-managed components (API server, etc.)</li> </ul>"},{"location":"Security/#hybrid-services","title":"Hybrid Services","text":"<p>Allowed:</p> <ul> <li>Testing customer-owned on-prem components connected to the cloud  </li> <li>End-to-end testing of hybrid integrations (VPN, DirectConnect, ExpressRoute)  </li> <li>Identity, SSO, and cross-domain security validation  </li> </ul> <p>Not Allowed / Restricted:</p> <ul> <li>Saturation or intentional overload of hybrid links  </li> <li>Attacks on cloud infrastructure or provider-managed appliances  </li> </ul>"},{"location":"Security/#types-of-tests-allowed","title":"Types of Tests Allowed","text":"<p>Allowed (with authorization):</p> <ul> <li>Black-box, grey-box, and white-box testing  </li> <li>Authenticated / unauthenticated vulnerability scanning  </li> <li>Application security testing (OWASP Top 10)  </li> <li>Lateral movement testing within customer-owned assets  </li> <li>Privilege escalation and configuration testing  </li> <li>Phishing/social engineering simulations (if contracted)</li> </ul> <p>Prohibited:</p> <ul> <li>Real DoS/DDoS  </li> <li>High-volume port scans  </li> <li>Attacks on physical infrastructure, hypervisors, or shared services  </li> <li>Deployment of active malware in production  </li> <li>Attempts to evade billing or resource management controls  </li> </ul>"},{"location":"Security/#request-and-approval-process","title":"Request and Approval Process","text":"<p>Customers must submit a request at least 10 business days in advance, including: 1. Test scope (assets + service model) 2. Techniques and methodologies 3. Testing window 4. Customer security team contacts 5. Business-related risks  </p> <p>The provider confirms or denies within 5 business days.</p>"},{"location":"Security/#responsibilities","title":"Responsibilities","text":""},{"location":"Security/#customer","title":"Customer","text":"<ul> <li>Ensure tested assets are owned/administered  </li> <li>Restrict testing to the authorized scope  </li> <li>Ensure testing tools do not degrade services  </li> <li>Provide test reports if requested  </li> </ul>"},{"location":"Security/#leonardo","title":"Leonardo","text":"<ul> <li>Validate and authorize the test scope  </li> <li>Monitor infrastructure for unexpected impact  </li> <li>Guarantee tenant isolation  </li> <li>Suspend tests if critical risks arise  </li> <li>Provide SOC/NOC contact during the test window  </li> </ul>"},{"location":"Security/#test-suspension-terms","title":"Test Suspension Terms","text":"<p>The provider may suspend testing if: - Unexpected impacts occur - The customer exceeds authorized scope - Risks emerge for other tenants or infrastructure  </p>"},{"location":"Security/#reporting","title":"Reporting","text":"<p>Customers must provide, upon request: - Executive Summary - List of vulnerabilities - Methods and tools used - Proofs of Concept (PoCs) - Remediation recommendations  </p>"},{"location":"Security/#red-team-exercises","title":"Red Team Exercises","text":"<p>Leonardo provides Red Team exercises on a dedicated infrastructure for each customer. These activities are managed by Leonardo's internal SOC.</p> <p>For any further information, please contact us by opening a support request here: Send an email</p>"},{"location":"Security/#vulnerability-assessments","title":"Vulnerability assessments","text":"<p>Leonardo provides Vulnerability assessments on a dedicated infrastructure for each customer, where the methods and type of execution will be defined.  These activities are managed by Leonardo's internal SOC.</p> <p>For any further information, please contact us by opening a support request here: Send an email</p>"},{"location":"Security/#vulnerability-disclosure-program-and-policy","title":"Vulnerability disclosure program and policy","text":"<p>Regarding disclosure of vulnerabilities discovered by Leonardo, its behavior depends on the context in which they occur. Specifically:</p> <ul> <li>If the vulnerabilities found affect its own infrastructure used to provide services, Leonardo will promptly inform the designated Italian Computer Security Incident Response Team (CSIRT).</li> <li>If the vulnerabilities found affect customer workloads, Leonardo will provide vulnerability assessments on a dedicated infrastructure for each customer, where the methods and type of execution will be defined. For this point, please see the section above regarding the Vulnerability Assessments process.</li> </ul>"},{"location":"Test/","title":"Test Account Requests","text":"<p>This section defines the process for provisioning test accounts requested by customers. The process ensures that customer requests for test accounts are handled in a controlled, timely, and secure manner. It includes request intake, validation, approval, provisioning, and delivery.</p>"},{"location":"Test/#request-submission-process","title":"Request submission process","text":"<p>Below you can view the sequence of the process for requesting a test account by an authorized user.</p> <p>1) The customer sends a request via email to the support address listed here: Send an email</p> <p>The request must include:</p> <ul> <li>Purpose of the test account</li> <li>Number of accounts required</li> <li>Specific access or roles needed</li> <li>Contact details of the requester</li> </ul> <p>2) The request is logged in the ticketing system upon receipt.</p> <p>3) The Service Desk reviews the request to ensure completeness and technical feasibility. If additional information is required, the customer is contacted. The 10-day SLA starts once the request is validated as complete.</p> <p>4) The Technical Team creates the test account(s) and applies:</p> <ul> <li>Minimum required permissions</li> <li>Applicable security policies</li> <li>Expiration settings (if required)</li> </ul> <p>A functionality check is performed to confirm proper access.</p> <p>5) Within 10 business days, the customer receives an email including:</p> <ul> <li>Credentials or activation instructions</li> <li>Overview of assigned permissions</li> <li>Account validity period</li> <li>Contact information for support</li> </ul> <p>The ticket is now then closed.</p>"},{"location":"Test/#limitations","title":"Limitations","text":"<p>The following are some limitations regarding test account requests:</p> <ul> <li>Creation of a maximum of 4 small-scale VMs.</li> <li>Creation of a maximum of 1 K8S cluster.</li> <li>PaaS services can be added on request to the K8S cluster.</li> </ul> <p>Not all PaaS services can be requested in the test environment.</p>"},{"location":"admin/internalDocInfo/GUIDA-EDITOR-ADMIN/","title":"Editor Admin - Guida Completa","text":"<p>Questo documento riunisce in un unico riferimento pratico tutte le note tecniche e funzionali sull'editor admin. Le informazioni provengono dai file di dettaglio presenti nella cartella <code>internalDocInfo</code> e sono state armonizzate per facilitare l'onboarding e l'utilizzo quotidiano.</p>"},{"location":"admin/internalDocInfo/GUIDA-EDITOR-ADMIN/#1-come-utilizzare-leditor","title":"1. Come utilizzare l'editor","text":""},{"location":"admin/internalDocInfo/GUIDA-EDITOR-ADMIN/#11-avvio-e-autenticazione","title":"1.1 Avvio e autenticazione","text":"<ul> <li>Compila i campi utente, repository e token quindi premi \"Start\".</li> <li>L'app inizializza l'editor Markdown, carica la struttura dei file, preleva lo stato del repository e avvia il caching delle immagini.</li> <li>Se una dipendenza non e\u0300 pronta (es. jQuery) l'inizializzazione attende automaticamente finche\u0301 tutto e\u0300 disponibile.</li> </ul>"},{"location":"admin/internalDocInfo/GUIDA-EDITOR-ADMIN/#12-navigazione-dei-file","title":"1.2 Navigazione dei file","text":"<ul> <li>Il pannello laterale mostra la gerarchia dei file in formato ad albero.</li> <li>Le cartelle possono essere aperte o chiuse con un click; <code>preConfiguration</code> appare sotto <code>docs</code> ed e\u0300 chiusa di default.</li> <li>Seleziona un file per caricarlo nell'editor; il file attivo viene evidenziato.</li> </ul>"},{"location":"admin/internalDocInfo/GUIDA-EDITOR-ADMIN/#13-modifica-dei-contenuti-markdown","title":"1.3 Modifica dei contenuti Markdown","text":"<ul> <li>Lavora direttamente nell'editor; le immagini vengono aggiornate in anteprima con percorsi corretti (cache o URL GitHub).</li> <li>Le scorciatoie standard (es. Ctrl+S) salvano il contenuto nel sistema di staging locale senza inviare nulla a GitHub.</li> </ul>"},{"location":"admin/internalDocInfo/GUIDA-EDITOR-ADMIN/#14-gestione-immagini","title":"1.4 Gestione immagini","text":"<ul> <li>Usa \"Carica immagine\" per aggiungere un file: l'immagine entra nello staging locale con preview e metadati.</li> <li>La cache scarica tutte le immagini all'avvio (parallelamente) e le converte in data URL per renderle istantanee.</li> <li>Il pulsante \"Vedi immagini\" mostra una galleria con indicatori di caricamento coerenti.</li> </ul>"},{"location":"admin/internalDocInfo/GUIDA-EDITOR-ADMIN/#15-staging-e-commit","title":"1.5 Staging e commit","text":"<ul> <li>Ogni modifica (file o immagine) compare nel pannello di staging con contatori e azioni di rimozione.</li> <li>Premi \"Commit All\" per inviare tutto in batch: il sistema risolve gli SHA, mostra l'avanzamento e ripete automaticamente gli upload se necessario.</li> <li>Puoi svuotare lo staging o rimuovere elementi singoli prima del commit.</li> </ul>"},{"location":"admin/internalDocInfo/GUIDA-EDITOR-ADMIN/#16-versioni-e-deploy","title":"1.6 Versioni e deploy","text":"<ul> <li>Il modal \"Gestisci versioni\" opera sul branch <code>gh-pages</code>: elenco, selezione multipla ed eliminazione.</li> <li>Il pulsante \"Deploy\" modifica il workflow <code>Automation.yml</code> impostando il flag di esecuzione.</li> </ul>"},{"location":"admin/internalDocInfo/GUIDA-EDITOR-ADMIN/#17-suggerimenti-rapidi","title":"1.7 Suggerimenti rapidi","text":"<ul> <li>Controlla il box di stato del repository per conoscere l'ultimo commit e i pending changes.</li> <li>Gli overlay di caricamento forniscono feedback chiaro durante operazioni lunghe.</li> <li>La modal immagini supporta zoom e chiusura con overlay, pulsante o tasto Escape.</li> </ul>"},{"location":"admin/internalDocInfo/GUIDA-EDITOR-ADMIN/#2-architettura-del-progetto","title":"2. Architettura del progetto","text":"<ul> <li>Il codice e\u0300 suddiviso in moduli specializzati (<code>core</code>, <code>images</code>, <code>repository</code>, <code>files</code>, <code>versions</code>, <code>deploy</code>, <code>events</code>) importati in <code>index.html</code> e coordinati da <code>app.js</code>.</li> <li>Ogni modulo espone funzioni dedicate: gestione inizializzazione, cache immagini, stato repo, albero file, versioni e deploy.</li> <li><code>app.js</code> verifica il caricamento dei moduli e scrive messaggi diagnostici in console.</li> </ul>"},{"location":"admin/internalDocInfo/GUIDA-EDITOR-ADMIN/#3-navigazione-file","title":"3. Navigazione file","text":"<ul> <li><code>addFileToTree</code> e <code>buildFileTree</code> costruiscono la struttura annidata, mentre <code>setupFolderToggle</code> gestisce l'apertura delle cartelle.</li> <li>La UI applica icone, gradienti, hover e animazioni per una navigazione simile a quella di un IDE.</li> <li>I file nuovi vengono aggiunti al tree senza bisogno di ricaricare l'intero repository.</li> </ul>"},{"location":"admin/internalDocInfo/GUIDA-EDITOR-ADMIN/#4-sistema-immagini","title":"4. Sistema immagini","text":"<ul> <li><code>loadImagesList</code> scarica l'elenco delle immagini dal repository GitHub e memorizza i contenuti in <code>window.cachedImages</code>.</li> <li><code>updatePreviewImages</code> intercetta i percorsi relativi (images/, admin/images/, ecc.) e li sostituisce con data URL o con l'URL raw su GitHub, evitando chiamate verso localhost.</li> <li>L'upload avviene con chiamate <code>PUT</code> su GitHub e termina con un refresh della cache.</li> <li>La logica di blocco dei pattern previene richieste errate e garantisce fallback sicuri.</li> </ul>"},{"location":"admin/internalDocInfo/GUIDA-EDITOR-ADMIN/#5-staging-locale","title":"5. Staging locale","text":"<ul> <li><code>stageFileLocally</code> e <code>stageImageLocally</code> aggiungono elementi alle mappe di staging, mantenendo contenuto, SHA originale, metadati e timestamp.</li> <li>Il pannello di staging appare automaticamente al primo elemento e mostra stato \"nuovo\" o \"modificato\".</li> <li><code>commitAllStaging</code> esegue il batch upload: recupera gli SHA correnti, effettua i <code>PUT</code>, traccia progressi e esiti, e aggiorna la cache locale.</li> </ul>"},{"location":"admin/internalDocInfo/GUIDA-EDITOR-ADMIN/#6-esperienza-utente-e-feedback","title":"6. Esperienza utente e feedback","text":"<ul> <li>Le funzioni <code>showLoadingOverlay</code>, <code>updateLoadingProgress</code> e <code>hideLoadingOverlay</code> offrono un overlay con spinner, messaggi e progress live.</li> <li>Le immagini possono essere ingrandite in una modal dedicata con animazioni di apertura e chiusura.</li> <li>Tutte le operazioni critiche (cache, upload, API) mostrano feedback coerente per evitare tempi morti non spiegati.</li> </ul>"},{"location":"admin/internalDocInfo/GUIDA-EDITOR-ADMIN/#7-integrazione-github","title":"7. Integrazione GitHub","text":"<ul> <li>Operazioni critiche: download albero (<code>GET /contents</code>), lettura file (<code>GET /contents/{path}</code>), salvataggio (<code>PUT /contents/{path}</code>), gestione immagini (GET/PUT) e check stato repository (<code>GET /commits</code>).</li> <li>Funzioni opzionali: gestione versioni su <code>gh-pages</code> e toggling del workflow di deploy.</li> <li>Il sistema gestisce automaticamente gli SHA, i retry su conflitto e l'avanzamento delle operazioni.</li> </ul>"},{"location":"admin/internalDocInfo/GUIDA-EDITOR-ADMIN/#8-robustezza-caricamento","title":"8. Robustezza caricamento","text":"<ul> <li><code>initializeApp</code> effettua polling finche\u0301 <code>$</code> non e\u0300 disponibile, quindi registra l'handler <code>$(document).ready</code> e verifica che tutti i moduli siano caricati.</li> <li>Il logging in console facilita il debug di moduli mancanti o dipendenze non ancora pronte.</li> </ul>"},{"location":"admin/internalDocInfo/GUIDA-EDITOR-ADMIN/#9-asset-locali-richiesti","title":"9. Asset locali richiesti","text":"<ul> <li><code>favicon.png</code> (32x32 o 48x48) in <code>docs/it/admin/</code>.</li> <li><code>images/loading.gif</code> (16-32 px) in <code>docs/it/admin/images/</code>.</li> <li>Font Awesome 4.7 (<code>woff2</code>, <code>woff</code>, <code>ttf</code>) in <code>docs/it/admin/fonts/</code> scaricabili da CDN.</li> <li>Dopo aver copiato i file verifica che non appaiano piu\u0300 richieste 404 nel browser.</li> </ul>"},{"location":"admin/internalDocInfo/GUIDA-EDITOR-ADMIN/#10-come-e-stato-costruito-questo-documento","title":"10. Come e\u0300 stato costruito questo documento","text":"<ul> <li>Le sezioni derivano dai file: <code>ALBERATURA_FILE_COMPLETATA.md</code>, <code>CACHE_IMMAGINI_COMPLETATA.md</code>, <code>FIX_CHIAMATE_LOCALHOST_COMPLETATO.md</code>, <code>FIX_JQUERY_UNDEFINED.md</code>, <code>LOADING_E_ZOOM_COMPLETATI.md</code>, <code>MAPPATURA_GITHUB_API.md</code>, <code>MODULARIZZAZIONE_COMPLETATA.md</code>, <code>README-local-assets.md</code>, <code>STAGING_LOCALE_COMPLETATO.md</code>, <code>TEST_PATTERN_BLOCKING.md</code>.</li> <li>Ogni tema e\u0300 stato sintetizzato, deduplicando ripetizioni e aggregando i punti comuni in capitoli verticali.</li> <li>Le istruzioni d'uso (sezione 1) combinano i flussi descritti nei documenti originali in un percorso operativo coerente.</li> </ul>"},{"location":"admin/internalDocInfo/GUIDA-EDITOR-ADMIN/#11-checklist-rapida","title":"11. Checklist rapida","text":"<ul> <li>Autenticazione completata e repo connesso.</li> <li>Albero dei file visibile e <code>preConfiguration</code> sotto <code>docs</code>.</li> <li>Cache immagini caricata (nessuna chiamata localhost).</li> <li>Staging locale popolato dopo modifiche.</li> <li>Overlay di caricamento visibili durante le operazioni lunghe.</li> <li>Asset locali presenti per evitare 404.</li> </ul> <p>Questa guida fornisce una vista completa sia sull'uso quotidiano dell'editor sia sulla sua architettura tecnica, facilitando manutenzione, debug e formazione di nuovi collaboratori.</p>"}]}