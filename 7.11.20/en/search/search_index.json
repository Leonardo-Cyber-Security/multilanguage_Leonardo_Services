{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Leonardo Services","text":"<p>Leonardo provides a collection of managed services which are represented in the following figure by type and sub-type (technically called \"Family\" and \"Sub-family\" respectively).</p> <p> Leonardo Services Overview </p> <p>From a logical-functional perspective, these services can be divided into three macro-categories:</p> <ul> <li>Infrastructure as a Service (IaaS)</li> <li>Container as a Service (CaaS)</li> <li>Platform as a Service (PaaS)</li> </ul> <p>The IaaS and CaaS categories include some services from the \"Compute\" family.  The PaaS category includes services from all other families.</p> <p>The above macro-categories are described below, and for each of them, we provide a description of the services for each family and subfamily.</p>"},{"location":"CaaS/","title":"Container as a Service (CaaS)","text":"<p>The following table lists the services included in the Container as a Service (CaaS) category.</p> FAMILY LIST OF SERVICES Compute Kubernetes Confidential Computing List of families and related CaaS services"},{"location":"CaaS/#compute-family","title":"Compute Family","text":"<p>Below is the list of services belonging to the Compute family:</p> <ul> <li>Kubernetes Confidential Computing</li> </ul>"},{"location":"CaaS/#kubernetes-confidential-computing","title":"Kubernetes Confidential Computing","text":"<p> Kubernetes Confidential Computing Service </p>"},{"location":"CaaS/#services-description","title":"Services Description","text":"<p>This service provides a platform for orchestrating private and secure containers, designed to manage containerized applications in highly regulated environments or with confidentiality requirements. It offers a secure and controlled Kubernetes environment where security is a key aspect of the solution. The operating system on which the solution is based is hardened to minimize the attack surface and potential vulnerabilities. The solution's architectural components utilize mechanisms that ensure data security, including during communication (via encryption mechanisms applied by default to communications between platform components) and for data stored within the platform itself. The platform can be customized to adapt to the specific needs of each organization, ensuring integration with existing enterprise systems and applications.</p>"},{"location":"CaaS/#features-and-advantages","title":"Features and Advantages","text":"<p>Implementation requires a combination of hardware certified for Confidential Computing, a private, security-hardened Kubernetes infrastructure, and a suite of observability and governance tools to maintain complete control over the container lifecycle.</p> <p>Features included:</p> <ul> <li>Data protection \u2192 The operating system is configured to ensure protection at all stages: data in memory, through full disk encryption and key rotation; data in transit, using secure and encrypted communication protocols; and data in use, adopting Confidential Computing practices and secure execution environments.</li> <li>Secure enclaves \u2192 Enforces isolation and encryption, ensuring that only authorized parties can access data.</li> <li>Trusted execution environments (TEEs) \u2192 Adds a secure computing environment, protecting data from external threats.</li> <li>As a managed Kubernetes solution, the customer does not have to worry about managing the infrastructure and its complexity, as the infrastructure layer is managed by Leonardo throughout the service lifecycle.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Security and confidentiality of containerized applications \u2192 end-to-end encryption, confidential computing for workloads, container isolation on dedicated nodes with hardware-based protection, integrated security policies, and advanced RBAC.</li> <li>Centralized cluster control and governance.</li> <li>Scalability and flexibility.</li> <li>Integration with multicloud and legacy environments.</li> </ul>"},{"location":"IaaS/","title":"Infrastructure as a Service (IaaS)","text":"<p>The following table lists the services falling under the Infrastructure as a Service (IaaS) category.</p> FAMILY LIST OF SERVICES Compute Pool Small (Confidential)Pool Medium (Confidential)Pool Large (Confidential)Pool X-Large (Confidential) List of families and related IaaS services <p></p>"},{"location":"IaaS/#compute-family","title":"Compute Family","text":"<p>Below is the list of services belonging to the Compute family:</p> <ul> <li>Pool Small (Confidential)</li> <li>Pool Medium (Confidential)</li> <li>Pool Large (Confidential)</li> <li>Pool X-Large (Confidential)</li> </ul> <p></p>"},{"location":"IaaS/#pool-confidential-services","title":"Pool Confidential Services","text":"<p> Pool Confidential Services </p>"},{"location":"IaaS/#services-description","title":"Services Description","text":"<p>These services enable the provision of Private virtual computing environments (IaaS), i.e., on a pool of physical resources, dedicated and isolated for each individual customer, based on the use of bare metal computing instances. Data from physical resources is encrypted and kept secure throughout all phases of use (at rest, in transit, and in use), leveraging the Confidential Computing paradigm. Depending on the pool of computing resources required for each individual Administration, the most suitable service from the four available types can be selected.</p>"},{"location":"IaaS/#features-and-advantages","title":"Features and Advantages","text":"<p>Private Cloud resources are dedicated exclusively to each customer. The services use secure enclaves based on Trusted Execution Environments (TEEs) based on Confidential Hardware, which offer an advanced level of security for data in use, protecting it during processing. They support advanced encryption of data at rest, in transit, and in use. They use advanced remote attestation systems to verify the correctness of the TEE environment, isolating virtual machine memory from the host operating system and other malicious guests.</p> <p>The services offer the following advantages:</p> <ul> <li>Data security and confidentiality in dedicated environments.  </li> <li>Workload isolation through advanced virtualization.</li> <li>Dedicated firewalls and network micro-segmentation.</li> <li>Automated provisioning and rapid resource management.</li> <li>Comprehensive control and centralized governance: centralized monitoring and auditing for traceability.</li> </ul> <p>Link a Compute Family Link a Pool Confidential Services</p>"},{"location":"PaaS/","title":"Platform as a Service (PaaS)","text":"<p>The following table lists the services included in the Platform as a Service (PaaS) category.</p> FAMILY LIST OF SERVICES Compute Functions as a Service Security Identity &amp; Access Management Service Security Key Vault as a Service Security SIEM as a Service Middleware API Management Middleware Jboss as a Service Middleware Spring boot as a Service Middleware Business Process as a Service Middleware Content Management Systems (CMS) as a Service Middleware PaaS ETL - Batch / Real Time Processing Infra &amp; Ops Platform Multicloud Management Platform-Leonardo SCMP Infra &amp; Ops Platform Control Room as a Service Infra &amp; Ops Platform IT infrastructure Service Operations (Logging &amp; Monitoring) Infra &amp; Ops Platform PaaS Ticket Management Service DevSecOps Configuration Manager DevSecOps Test Automation DevSecOps Quality Code Analysis DevSecOps DevSecOps As A Service DevSecOps Qualizer DevSecOps Big Data Data Lake Big Data Data Lakehouse Big Data Business Intelligence Big Data Batch/Real time Processing Big Data Event Message Big Data Data Governance Artificial Intelligence (AI) Speech to Text Artificial Intelligence (AI) AI Audio &amp; Video Analytics Artificial Intelligence (AI) Optical Character Recognition (OCR) Artificial Intelligence (AI) Text Analytics Artificial Intelligence (AI) Text Translation Artificial Intelligence (AI) AI Search - RAG Artificial Intelligence (AI) AI Platform Artificial Intelligence (AI) Semantic Knowledge Search Artificial Intelligence (AI) AI SLM/LLM Artificial Intelligence (AI) AI workflow Artificial Intelligence (AI) Vector DB Virtual Desktop Infrastructure (VDI) VDI Virtual Desktop Infrastructure (VDI) VDI with GPU support Collaboration Instant Messaging Database PaaS MongoDB Database PaaS Redis Database PaaS Graph DB Network PaaS CDN (Content Delivery Network) Network PaaS Domain Name System (DNS) Network PaaS WAF (Web Application Firewall) Network PaaS Gateway VPN List of families and related PaaS services"},{"location":"PaaS/#compute-family","title":"Compute Family","text":"<p>Below is the list of services belonging to the Compute family:</p> <ul> <li>Functions as a Service</li> </ul>"},{"location":"PaaS/#functions-as-a-service","title":"Functions as a Service","text":"<p> Functions as a Service </p>"},{"location":"PaaS/#services-description","title":"Services Description","text":"<p>FaaS (Function as a Service) is an event-driven system design model running on stateless containers, where developers create, deploy, and execute small, independent functions to perform specific tasks without worrying about the underlying infrastructure. Adopting FaaS allows for standardization of application development and execution by centralizing cross-functional capabilities such as orchestration, automatic provisioning, monitoring, integrated service management, and event-driven flow control. </p> <p>It offers tools to:</p> <ul> <li>centrally manage serverless functions;</li> <li>automate component lifecycle management;</li> <li>enable multi-cloud and hybrid cloud portability;</li> <li>support innovation with GPU runtimes and dedicated AI tools.   </li> </ul> <p>The FaaS platform provisions and scales the underlying resources based on demand. It is ideal for highly dynamic scenarios with variable workloads and integrates seamlessly with microservices and event-based architectures.</p>"},{"location":"PaaS/#features-and-advantages","title":"Features and Advantages","text":"<p>The service goes beyond simply providing an execution engine; it also offers a complete ecosystem, consisting of:</p> <ul> <li>Serverless execution \u2192 stateless functions and event-driven workflows, scalable and available in various programming languages.</li> <li>Portability and independence \u2192 can run on any Kubernetes cluster, across multiple environments, without lock-in constraints.</li> <li>Security and compliance \u2192 data protection and centralized access management.</li> <li>The solution enables organizations to adopt a modern and flexible model, reducing operational complexity and benefiting from a standardized and easily accessible service.</li> </ul> <p>The service is delivered through Apache OpenServerless, an open-source, cloud-agnostic serverless platform based on Apache OpenWhisk as a Function-as-a-Service (FaaS) engine.</p> <p>The service offers the following advantages:</p> <ul> <li>Reduced operating costs \u2192 you only pay for the actual use of features.</li> <li>Flexibility and scalability \u2192 resources adapt to demand.</li> <li>Operational efficiency \u2192 eliminating the need to directly manage servers, patches, and updates.</li> <li>High availability \u2192 built-in redundancy and fault tolerance, ensuring high availability of features even in the event of hardware failures or other interruptions.</li> <li>Accelerated time-to-market \u2192 rapid release of new features without worrying about the infrastructure.</li> <li>Agile development \u2192 focus on code and business logic, not server management.</li> <li>Continuous innovation \u2192 rapid experimentation with new, low-cost services. Competitive advantage in cost and speed compared to traditional hosting models.</li> </ul>"},{"location":"PaaS/#security-family","title":"Security Family","text":"<p>Below is the list of services belonging to the Security family:</p> <ul> <li>Identity &amp; Access Management Service</li> <li>Key Vault as a Service</li> </ul>"},{"location":"PaaS/#identity-access-management-service","title":"Identity &amp; Access Management Service","text":"<p> Identity &amp; Access Management Service </p>"},{"location":"PaaS/#services-description_1","title":"Services Description","text":"<p>The Service provides an essential level of security for identity and access management, ensuring basic protection against unauthorized access. It manages single sign-on access to guarantee access to all protected resources with a single authentication. It supports standard OIDC/OAUTH and SAML protocols for easy integration with applications and products. It enables first-level authentication with username/password and second-level authentication with multi-factor authentication based on Time-based One-Time Password (TOTP) protocols. It manages access authorization to system-protected resources only for users with rights to use them according to the Role-based Access Control (RBAC) and Attribute-based Access Control (ABAC) paradigms. Integration with external user repositories (LDAP or Active Directory) is also available. It manages the user lifecycle and related authorizations via the console.</p>"},{"location":"PaaS/#features-and-advantages_1","title":"Features and Advantages","text":"<p>The main features and functionalities of the service are:</p> <ul> <li> <p>Identity Management</p> <ul> <li> <p>User Management \u2192 creation, modification, and deletion of users; management of user profiles (name, email, custom attributes, roles, etc.); import/export of users from external directories (LDAP, Active Directory).</p> </li> <li> <p>Identity Federation \u2192 integration with external providers via LDAP or Active Directory; two-way or one-way synchronization of users and roles.</p> </li> <li>Account Management UI \u2192 self-service portal for users to update profiles and passwords, manage devices and active sessions, and view permissions.</li> </ul> </li> <li> <p>Access Management</p> <ul> <li>Single Sign-On (SSO) / Single Logout (SLO).</li> <li>Multi-Factor Authentication (MFA).</li> <li>Delegated Authentication (Identity Brokering).</li> <li>Role-Based Authorization (RBAC) and policies.</li> </ul> </li> <li> <p>Protocol and Integration</p> <ul> <li>Support for standard protocols, such as OpenID Connect (OIDC), OAuth 2.0, and SAML 2.0.</li> <li>Official adapters for Java, Spring Boot, WildFly, Node.js, and other applications.</li> <li>Ability to integrate  with API Gateways, microservices, and web frontends.</li> </ul> </li> <li> <p>Security and Management</p> <ul> <li>Session and Token Management.</li> <li>Password Policies.</li> <li>Events and Auditing.</li> <li>Scalability and High Availability \u2192 distributed architecture, with support for clustering and replication.</li> </ul> </li> <li> <p>Extensibility</p> <ul> <li>REST API for automated user, role, and client management.</li> <li>SPI (Service Provider Interfaces) for extending authentication, validation, or provisioning capabilities.</li> <li>Ability to implement custom authenticators or connect to external systems.</li> </ul> </li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Improved overall security \u2192 Centralizing authentication reduces the risk of vulnerabilities distributed across applications.</li> <li>Reduced maintenance and development costs \u2192 A single, centralized platform reduces the complexity and duplication of authentication code across applications.</li> <li>Agility and Scalability \u2192 Increased speed of onboarding new applications thanks to the use of standard protocols (OIDC, SAML, OAuth2).</li> <li>Maintainability and Standardization \u2192 Use of standard protocols (OIDC, SAML, OAuth2) that eliminate proprietary implementations and facilitate interoperability.</li> </ul>"},{"location":"PaaS/#key-vault-as-a-service","title":"Key Vault as a Service","text":"<p> Key Vault as a Service </p>"},{"location":"PaaS/#services-description_2","title":"Services Description","text":"<p>The service provides a secure cloud repository (Vault) for storing and managing credentials and passwords used by cloud applications without having to manually install and manage dedicated IaaS machines.  The service consists of a software platform that enables centralized and automated management of encryption keys, secrets, and certificates, with access controlled by identity-based authentication and authorization methods. It also allows organizations to significantly simplify key lifecycle management, ensuring centralized control while leveraging the native cryptographic capabilities of KMS providers.</p>"},{"location":"PaaS/#features-and-advantages_2","title":"Features and Advantages","text":"<p>The main features and functionalities of the service are:</p> <ul> <li>Secure Secret Storage \u2192 Key/value secrets are stored in Key Vault As A Service in encrypted form, ensuring their integrity in the event of unauthorized access to raw storage.</li> <li>Dynamic Secrets \u2192 Key Vault As A Service can generate secrets on demand to allow users and/or applications to access different systems.</li> <li>Data Encryption \u2192 Key Vault As A Service can encrypt and decrypt workloads running on the PA infrastructure without archiving them, managing the entire lifecycle of the cryptographic material used in the encryption process.</li> <li>Leasing and Renewal \u2192 Key Vault As A Service associates a lease with each key or secret managed, which will result in its automatic revocation upon expiration and which can be renewed by clients through the integrated APIs provided by the platform.</li> <li>Revocation \u2192 Key Vault As A Service has integrated support for revoking keys and secrets, which can be revoked individually or in bulk (e.g., all keys of a specific user), for example in case of compromise.</li> </ul> <p>The service is provided using Hashicorp Vault technology.  The service offers high availability and geographic replication. The main workflow of Key Vault as a Service consists of four phases:</p> <ul> <li>Authentication \u2192 The process by which a client provides information that Key Vault as a Service uses to determine the authenticity of the requester. Once the client is authenticated, the system generates a token that is associated with the relevant policy.</li> <li>Validation \u2192 Validation occurs through trusted third-party sources, such as Active Directory, LDAP, and Okta.</li> <li>Authorization \u2192 The client is then associated with the Key Vault as a Service security policy, which consists of a set of rules that define which API endpoints a user, machine, or application is allowed or denied access to with its token.</li> <li>Access \u2192 Key Vault as a Service then grants access to keys and encryption features, secrets, and certificates.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Risk reduction \u2192 thanks to automatic key rotation and secret lifecycle management, it increases the protection of sensitive data, simplifies regulatory compliance and reduces the risk of human errors.</li> <li>Operational efficiency and cost reduction \u2192 less internal management, automation and standardization, scalability without hardware investment.</li> <li>Optimized time-to-market \u2192 developers focus on code, not key management; also enables secure applications to be delivered faster, improving agility and innovation.</li> <li>Improved trust and reputation \u2192 audit and traceability to demonstrate secure secret management to stakeholders or customers.</li> <li>Cryptographic and standardized compliance \u2192 can be configured to use FIPS (Federal Information Processing Standards) validated cryptographic modules, ensuring that all encryption, signing, HMAC and key derivation operations comply with the standards.</li> </ul>"},{"location":"PaaS/#middleware-family","title":"Middleware Family","text":"<p>Below is the list of services belonging to the Middleware family:</p> <ul> <li>PaaS API Management</li> <li>Jboss as a Service</li> <li>Spring boot as a Service</li> <li>PaaS Business Process as a Service</li> <li>PaaS CMS as a Service</li> <li>PaaS ETL - Batch / Real Time Processing - 1 worker</li> </ul>"},{"location":"PaaS/#paas-api-management","title":"PaaS API Management","text":"<p> PaaS API Management </p>"},{"location":"PaaS/#services-description_3","title":"Services Description","text":"<p>It is a platform of tools and services that facilitates the management, control, monitoring, and protection of APIs (Application Programming Interfaces) without having to manually implement all the components.  The service typically offers:</p> <ul> <li>API gateways to route and secure traffic;</li> <li>Authentication and authorization: Rate limiting and throttling to control consumption;</li> <li>Logging and observability: Integration with security and DevOps systems.</li> </ul> <p>The API manager facilitates API lifecycle management, including aspects such as creation, version management, deprecation, and retirement, to ensure backward compatibility, allowing developers to gradually migrate to new versions without disrupting existing applications. The API manager allows you to define and enforce policies, such as usage limits, quota management, custom authentication, data transformations, and caching. These policies allow you to control API behavior and ensure compliance with security requirements and guidelines. The API Manager can integrate with other systems and tools, such as identity and access management (IAM) systems, performance monitoring systems, data analytics systems, and security gateways. This integration expands the API Manager's functionality and integrates it into the ecosystem of existing applications and services.</p>"},{"location":"PaaS/#features-and-advantages_3","title":"Features and Advantages","text":"<p>The main features and functionalities of the service are:</p> <ul> <li>API Publishing \u2192 the API Manager offers tools for publishing APIs, allowing developers or authorized users to access them. For optimal use, clear and comprehensive documentation is provided describing how to use the APIs, which endpoints are available, which parameters are requested, and how to interpret the responses.</li> <li>Access Control \u2192 the API Manager manages the authentication and authorization of users who wish to use the APIs. This allows you to control who can access the APIs and with what permission levels. The API Manager can adopt authentication mechanisms such as access tokens, API keys, or digital certificates to ensure API security.</li> <li>Monitoring and Analytics \u2192 the API Manager offers tools for monitoring API performance, such as the number of requests, response times, and errors. This information allows developers and administrators to monitor API usage, identify any performance issues, and take corrective action.</li> </ul> <p>The architecture, based on Kong technology, is divided into several key components that interact to provide comprehensive functionality to users:</p> <ul> <li>Front-end \u2192 administration clients and graphical interfaces (Admin GUI, Dev Portal) accessible via browser or dedicated applications, which allow users to configure services, manage users, and monitor metrics in real time.</li> <li>Back-end Kong Control Plane \u2192 manages configurations, policies, plugins, and API orchestration.</li> <li>Back-end Data Plane \u2192 routes user requests to back-end services, applying security rules, transformations, caching, and rate limiting. - Database \u2192 stores configurations, users, roles, statistics, and logs. Supports replication and high availability capabilities to ensure resilience and business continuity</li> <li>Integrations \u2192 supports integrations with development tools, CI/CD, monitoring systems, and project management platforms, allowing Kong to be incorporated into existing enterprise workflows.</li> <li>Security and Authentication \u2192 offers advanced security options, including multi-factor authentication, support for enterprise protocols (OIDC, SAML, LDAP), and granular access control, ensuring data protection and compliance with corporate standards.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced time to market \u2192 APIs can be published and managed quickly without building the infrastructure from scratch.</li> <li>Flexibility and scalability \u2192 the platform grows with business needs, supporting traffic spikes or new integrations without disruption.</li> <li>Reduced operating costs \u2192 no hardware or maintenance investments: infrastructure management is delegated to the PaaS provider.</li> <li>API monetization \u2192 ability to create API-driven business models (e.g., exposing APIs to partners or customers with pricing plans).</li> <li>Enhanced security and compliance \u2192 secure management of APIs and traffic between services, with authentication, authorization, and rate limiting policies, protecting the infrastructure from unauthorized access.</li> <li>Open ecosystem \u2192 Facilitates partnerships and innovation thanks to an API-ready and standardized infrastructure.</li> </ul>"},{"location":"PaaS/#jboss-as-a-service","title":"Jboss as a Service","text":"<p> Jboss As A Service </p>"},{"location":"PaaS/#services-description_4","title":"Services Description","text":"<p>The service is based on an open source platform for running and managing Enterprise Java applications, designed to offer reliability, scalability, and flexibility in modern environments.  It allows to run Java EE/Jakarta EE applications and microservices, providing a robust environment for business logic, data persistence, and transaction management. It allows to manage the application lifecycle, including deployment, updates, rollbacks, and centralized configuration, ensuring secure and repeatable processes. Thanks to its modular architecture, compatibility with cloud environments, and rich integration with automation and security tools, it represents a strategic solution for companies seeking efficiency, innovation, and operational control.</p>"},{"location":"PaaS/#features-and-advantages_4","title":"Features and Advantages","text":"<p>JBoss offers a robust, high-performance, and secure environment for developing and managing enterprise applications, providing a stable foundation for the growth and evolution of enterprise systems. The main features and functionalities of the service are:</p> <ul> <li>Security and Compliance \u2192 manages security, authentication, authorization, and data protection.</li> <li>Web Services \u2192 JAX-RS, JAX-WS, creation and management of RESTful and SOAP APIs for service integration.</li> <li>Microservices Management \u2192 MicroProfile, a set of specifications optimized for developing microservices-based applications. Includes features such as configuration, resiliency, monitoring, and metrics.</li> </ul> <p>The architectural components of the service are as follows:</p> <ul> <li>Front-end \u2192 administration interfaces (Web Console, CLI) accessible via browser or terminal, which allow administrators to manage configurations, deployment, resources, and monitoring.</li> <li>Back-end \u2192 the server core manages application execution, request processing, resource management (datasources, JMS queues, batch, etc.), and integration with external systems via resource adapters and connectors.</li> <li>Database \u2192 integrates with relational and NoSQL databases via configurable datasources, used by applications for data persistence.</li> <li>Security and Authentication \u2192 offers an advanced security subsystem for authentication, authorization, encryption, and auditing. It supports authentication via LDAP, Kerberos, SSO, and integration with external identity providers, ensuring secure access that complies with corporate standards.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced time to market \u2192 application lifecycle automation, centralized management, and easy integration with DevOps pipelines reduce development and release times, accelerating response to market needs.</li> <li>Reduced operating costs \u2192 centralized resource management and the platform's modularity optimize the use of existing infrastructure, reducing waste and operating costs.</li> <li>Security posture \u2192 security policies can be defined and applied consistently across all applications, reducing risk and ensuring regulatory compliance.</li> <li>Faster innovation \u2192 management tools (CLI, Web Console, REST API) and automated deployment and configuration processes reduce the operational burden on IT teams.</li> <li>DevOps integration \u2192 integrated CI/CD pipelines for build and deployment.</li> </ul>"},{"location":"PaaS/#spring-boot-as-a-service","title":"Spring boot as a Service","text":"<p> Spring boot as a Service </p>"},{"location":"PaaS/#services-description_5","title":"Services Description","text":"<p>This service allows you to use Spring Boot, an open-source framework for Java application development, as a managed service. It is designed to simplify the development of production-ready Java applications by providing a platform that eliminates much of the manual configuration required by the traditional Spring framework and reduces the need for server provisioning and dependency management. With a preconfigured environment optimized for the Spring Boot framework, the service allows teams to focus on developing business features, reducing release times and costs. It integrates with DevOps tools and leading cloud services, offering scalability, managed updates, and continuous monitoring.</p>"},{"location":"PaaS/#features-and-advantages_5","title":"Features and Advantages","text":"<p>The main features and functionalities of the service are:</p> <ul> <li>Automatic environment provisioning \u2192 automatic configuration of Java runtime (JDK), integrated application server, and Spring Boot framework. No need to manually configure build environments or containers. Simplified deployment \u2192 ability to directly upload a JAR or source code (e.g., via Git, API, or CI/CD pipeline).</li> <li>Scalability \u2192 horizontal (replication) and vertical (CPU/RAM resources) scaling managed by the PaaS based on load.</li> <li>Integrated monitoring and logging \u2192 access to runtime metrics (CPU, memory, latency, throughput); centralized logs (stdout/stderr) accessible via console or API; integration with BI tools (Prometheus, Grafana, etc.).</li> <li>Configuration and secret management \u2192 centralized configuration (environment variables, Spring Cloud Config, or Vault); secure management of credentials, tokens, and keys. Integrated support services \u2192 easy connection to managed databases (PostgreSQL, MySQL, MongoDB); support for messaging (RabbitMQ, Kafka), caching (Redis), and storage; automatic service binding via environment variables or injection.</li> <li>DevOps integration \u2192 support for CI/CD pipelines; continuous deployment (Continuous Deployment) and automatic rollbacks; compatibility with tools such as GitHub Actions, Jenkins, GitLab CI.</li> <li>Security and isolation \u2192 each application is isolated (namespace, container, or dedicated VM); HTTPS/TLS by default, identity management, and integration with authentication systems (OAuth2, SSO).</li> </ul> <p>The solution is based on the following architectural layers:</p> <ul> <li>Infrastructure layer \u2192 provides the hardware and virtual resources needed to run application containers (Compute nodes, Storage, Networking, Security layer); automatic provisioning via IaC (Infrastructure as Code).</li> <li>Orchestration layer (Platform Runtime) \u2192 manages the lifecycle of Spring Boot containers, from deployment to monitoring, ensuring availability, replication, and load balancing</li> <li>Application layer (Spring Boot Runtime) \u2192 Spring Boot runs within a container; supports Actuator endpoints for health checks and metrics; exposes HTTP/REST APIs on predefined and configurable ports</li> <li>Management layer and PaaS services \u2192 web dashboard or CLI to manage applications, versions, and resources. REST API for automation (deployment, scale, logs, metrics). Integration with external logging and monitoring systems.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced time to market \u2192 Deployment automation and simplified environment management allow applications to be brought into production more quickly.</li> <li>Reduced operating costs \u2192 No hardware or maintenance investments: infrastructure management is handled for the customer.</li> <li>Observability and monitoring \u2192 Preconfigured tools to track performance, errors, and response times.</li> <li>Guaranteed security \u2192 Automatic patch and update management.</li> <li>Environment consistency \u2192 Same environments for development, testing, and production.</li> <li>Microservices support \u2192 Simplified management of distributed architectures.</li> </ul>"},{"location":"PaaS/#business-process-as-a-service","title":"Business Process as a Service","text":"<p> Business Process as a Service </p>"},{"location":"PaaS/#services-description_6","title":"Services Description","text":"<p>It is a comprehensive Business Process Management (BPM) platform that helps companies model and automate complex processes, improve productivity and service quality, and ensure control, traceability, and flexibility in an integrated and scalable environment. It combines workflow automation, application integration, and performance monitoring in a single solution. The goal is to improve operational efficiency, reduce execution times, and ensure process consistency across the organization. It facilitates collaboration between business users and IT during the creation, management, validation, and deployment of customized process and decision automation solutions. Business users can modify business logic and business processes without requiring assistance from IT staff.</p>"},{"location":"PaaS/#features-and-advantages_6","title":"Features and Advantages","text":"<p>The main features and functionalities of the service are:</p> <ul> <li>Process Modeling &amp; Simulation \u2192 allows business analysts and developers to collaborate on process definition using a standard language (BPMN 2.0) with drag-and-drop tools.</li> <li>Process Automation &amp; Orchestration \u2192 allows for the automation of repetitive tasks and decision rules.</li> <li>Human Workflow Management \u2192 automatic assignment of tasks based on roles, priorities, and workloads. Intuitive user portal for completing, delegating, or commenting on tasks.</li> <li>Monitoring, Reporting &amp; Optimization \u2192 real-time dashboard for performance analysis based on KPIs and SLAs, reporting, optimization recommendations through predictive analytics, and historical data.</li> <li>Security &amp; Governance \u2192 integrated authentication with LDAP/Active Directory. Granular roles for users and groups (process owner, approver, admin). Complete audit trail for compliance and traceability. Version control and approvals prior to deployment.</li> <li>Cloud &amp; DevOps Integration \u2192 offered as a managed cloud service. Integration with CI/CD pipelines and DevOps tools.</li> </ul> <p>The service, based on IBM technology, is organized into the following integrated modules that cover the entire process lifecycle\u2014from modeling to performance measurement.</p> <ul> <li>Process Designer \u2192 Visual process modeling tool.</li> <li>Process Center \u2192 Centralized repository and collaborative environment, allows you to manage multiple versions of processes, reuse common components, and collaborate across multiple teams.</li> <li>Process Server \u2192 Process execution engine. Manages both human and automated tasks.</li> <li>Process Portal \u2192 User portal for receiving, executing, or approving tasks.</li> <li>Performance Data Warehouse (PDW) \u2192 Performance collection and analysis system, stores process execution data and enables historical analysis and real-time monitoring.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li> <ul> <li>Operational efficiency and cost reduction* \u2192 automation and reduction of manual and repetitive tasks, resulting in reduced personnel costs, errors, and inefficiencies.</li> </ul> </li> <li>Transparency and control \u2192 end-to-end visibility. Each process is tracked in real time. Increases accountability and control.</li> <li>Quality and standardization \u2192 consistent and compliant processes. Ensures processes are always executed consistently, reducing deviations and variability.</li> <li>Compliance and auditability \u2192 complete traceability for audits and regulatory compliance. Every step and decision is documented, facilitating internal controls and regulatory compliance</li> <li>Monitoring and observability \u2192 integrated dashboards and analytics.</li> </ul>"},{"location":"PaaS/#content-management-systems-cms-as-a-service","title":"Content Management Systems (CMS) as a Service","text":"<p> Content Management Systems (CMS) as a Service </p>"},{"location":"PaaS/#services-description_7","title":"Services Description","text":"<p>The service, based on Wordpress, provides comprehensive and versatile tools for creating and managing websites and blogs based on CMS (Content Management System) solutions, which are cloud-based Content Management Systems (CMS) delivered as a service, without having to install or maintain software on your own server. It offers a centralized system that allows for scalable, integrable, and multi-channel content management, with consumption-based costs and no infrastructure overhead. This allows users to focus solely on content creation and management, while the platform handles hosting, maintenance, and updates.</p>"},{"location":"PaaS/#features-and-advantages_7","title":"Features and Advantages","text":"<p>The main features and functionalities of the service are:</p> <ul> <li>Website creation \u2192 content publishing.</li> <li>Content management (CMS) \u2192 ability to create, edit, and delete content.</li> <li>Intuitive user interface \u2192 easy content access.</li> <li>Customization via themes and plugins \u2192 layout management and use of plugins for customization</li> <li>SEO-friendly \u2192 search engine visibility.</li> <li>Flexibility and scalability \u2192 adaptability based on needs.</li> <li>Open Source and Community \u2192 collaboration with the online community.</li> <li>Accessibility \u2192 tools to improve readability, contrast, keyboard navigation, and compliance with accessibility standards for users with disabilities.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Accelerated time to market \u2192 rapid launch of websites and apps.</li> <li>Reduced operating costs \u2192 no servers or internal maintenance. High availability and resilience.</li> <li>Support for omnichannel strategies (web, mobile, e-commerce, IoT).</li> <li>Ability to operate in multiple markets with multilingual websites.</li> <li>Simplified collaboration for distributed teams.</li> <li>Continuous innovation at no additional cost \u2192 new features released by the provider.</li> <li>Native integration with cloud services (CRM, analytics, AI, CDN).</li> <li>Front-end/back-end separation \u2192 freedom to use modern frameworks (React, Vue, Angular, etc.).</li> </ul>"},{"location":"PaaS/#paas-etl-batch-real-time-processing","title":"PaaS ETL - Batch / Real Time Processing","text":"<p> PaaS ETL - Batch / Real Time Processing </p>"},{"location":"PaaS/#services-description_8","title":"Services Description","text":"<p>It is a platform that provides a set of tools for processing, integrating, quality-checking, and preparing data from heterogeneous sources stored in the Data Lake, both in real time and in batch mode. It offers a user-friendly graphical interface for designing and implementing data integration workflows using a visual approach, following the ETL (Extract \u2013 Transform \u2013 Load) approach. This reduces the complexity of data integration and allows users to focus on business logic rather than programming code. It supports a wide range of data sources, including relational databases, files, web applications, cloud, web services, and more. This makes it extremely flexible for data integration in a variety of contexts. It also offers data quality management tools, allowing users to clean, standardize, and enrich their data to ensure its accuracy and reliability.</p>"},{"location":"PaaS/#features-and-advantages_8","title":"Features and Advantages","text":"<p>The main features and functionalities of the service are:</p> <ul> <li>Heterogeneous and large-scale data processing \u2192 It supports a large number of data sources in batch and streaming mode (for example, datasets stored on HDFS, S3, ADLS Gen2, and GCS in CSV, Parquet, Avro, and other formats, as well as RDBMS via JDBC or all popular NoSQL, Apache Kafka, and more).</li> <li>It is natively integrated with the Data Lake and Batch/Real-Time Processing PaaS of the Big Data family.</li> <li>It allows to implement complex data pipelines \u2192 leveraging the parallel and distributed computing capacity provided by a Spark cluster.</li> <li>It provides an interactive mode to debug flows and explore data easily and intuitively.</li> <li>It guarantees the maximum scalability necessary to meet the needs of organizations of any size, from small businesses to large enterprises.</li> </ul> <p>The main architectural components of the service are as follows:</p> <ul> <li>Visual ETL Architecture \u2192 provides various blocks that allow you to visually design an ETL, ELT, and ELL pipeline. It allows you to read, write, and modify data from different sources, interfacing with the Data Lake and Monitoring module, and can use the Processing module for data-intensive processing.</li> <li>Apache Spark \u2192 Open-source parallel processing framework that supports in-memory processing to improve the performance of applications that analyze Big Data.</li> <li>JupyterLab \u2192 Interactive notebook-based development environment designed primarily for working with data, scientific calculations, and machine learning. It supports writing and executing interactive code in languages \u200b\u200bsuch as Python, R, or Julia.</li> <li>NodeRed \u2192 Visual, low-code development environment for creating applications that connect devices, web services, APIs, and systems.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Support for data-driven strategies, faster and more informed decisions \u2192 centralized data for service customization (e.g., real-time analytics for marketing, IoT, e-commerce, etc.) and ready-to-use pipelines without complex development. </li> <li>Greater focus on core business \u2192 development and IT teams do not have to worry about technical maintenance, as it is managed. - Reduced operating costs and service scalability \u2192 no infrastructure to manage; support for large data volumes (batch) or continuous flows (streaming); automation of extraction, transformation, and loading processes with real-time scheduling or triggers; same framework for historical data and real-time flows.</li> <li>Integration with cloud ecosystem (data warehouse, data lake, BI, AI/ML).</li> <li>Guaranteed security and compliance (encryption, access, audit logs).</li> <li>Integrated monitoring \u2192 metrics, alerts, and centralized logging for ETL pipelines.</li> </ul>"},{"location":"PaaS/#infra-ops-platform-family","title":"Infra &amp; Ops Platform Family","text":"<p>Below is the list of services belonging to the Infra &amp; Ops Platform family:</p> <ul> <li>Multicloud Management Platform - Leonardo SCMP</li> <li>Control Room as Service</li> <li>IT infrastructure Service Operations (Logging &amp; Monitoring)</li> <li>PaaS Ticket Management Service</li> <li>PaaS Ticket Management Service (ITSM)</li> <li>PaaS Ticket Management Service (ADD-ON ITOM)</li> </ul>"},{"location":"PaaS/#multicloud-management-platform-leonardo-secure-cloud-management-platform-scmp","title":"Multicloud Management Platform - Leonardo Secure Cloud Management Platform (SCMP)","text":"<p> Multicloud Management Platform - Leonardo Secure Cloud Management Platform (SCMP) </p>"},{"location":"PaaS/#services-description_9","title":"Services Description","text":"<p>Secure Cloud Management Platform (SCMP) is a Multicloud management software platform, designed by Leonardo, for governance, lifecycle management, brokering, and resource automation in hybrid and multi-cloud environments. It offers a self-service portal with a unified service catalog, governance, and customizable dashboards and reports to monitor infrastructure performance and costs. The platform allows to orchestrate, monitor, and control usage, costs, and workflow performance in complex or hybrid multi-cloud environments. It integrates seamlessly with leading Enterprise Cloud Service Providers, On-premise resource virtualization and edge computing systems. It can also manage self-service provisioning of resources: e.g., virtual machines (VMs), storages, clusters, containers, services, complex applications (such as blueprints), or entire application stacks (IaaS, PaaS, CaaS).  </p>"},{"location":"PaaS/#features-and-advantages_9","title":"Features and Advantages","text":"<p>The service offers the following key features:</p> <ul> <li>High compatibility and integration \u2192 integration with major CSPs (AWS, Azure, GCP, Oracle, etc.), virtualization and on premise vendors and systems (VMware, OpenStack, HPE, Nutanix, Hyper-V, bare metal, PXE provisioning), and container orchestration systems (Kubernetes). Integration with third-party systems (e.g., ERP) to offer process automation.</li> <li>High level of granularity and customization \u2192 the platform offers various graphical views for monitoring and reporting, to meet the needs of each user and team. You can choose whether to have aggregate views and reports by system/subsystem, or by element type or individual element.</li> <li>Performance and cost monitoring \u2192 through integrated, unified, and intuitive dashboards, users can monitor the current and forecasted status of systems, subsystems, and related resources in terms of resource usage and generated costs. Views can be presented in graphical form with custom tables or graphs, or through the creation of reports, which can be exported in various formats or sent to users periodically. The platform manages the monitoring of aggregate and/or resource/team/cloud costs and enables predictive cost analysis (what-if analysis) to identify waste, comply with recommendations (e.g., resizing, rightsizing), implement budget guardrails, etc.</li> <li>Self-Service Catalog and Item Provisioning \u2192 authorized users can create and manage their own catalog to orchestrate and manage the various elements within it. For example, an authorized user can deploy new infrastructure resources (e.g., VMs, storage resources, network resources, etc.) to the desired CSPs, launch or modify standard or custom services, pre-configured environments, and blueprints (both proprietary and IaC).</li> <li>Multicloud security monitoring \u2192 thanks to compatibility with existing security systems and appliances (e.g., SIEM, Key Vaults, Remote attestation for confidential computing, etc.), you can centrally manage your organization's security posture, detecting any vulnerabilities, discrepancies, or non-compliance on the systems or resources monitored by the platform.</li> <li>Data and User Security Management \u2192 the platform does not process customer data, but only the use of CSP services and/or resources. Identity and access management (IAM) mechanisms are foreseen with the implementation of MFA and RBAC authentication logics, compliant with the principle of least privilege, to regulate access to IT resources and related information based on roles, responsibilities and authorization levels.</li> </ul> <p>The main components are:</p> <ul> <li>Abstraction Layer (ABS) \u2192 lowest platform layer that executes operational workflows towards integrated CSPs.</li> <li>Resource Layer/Manager (RM) \u2192 highest platform layer responsible for executing user requests. It is composed of the following modules:<ul> <li>Costs: module responsible for managing and displaying resource costs.</li> <li>Security: module responsible for managing and displaying security policies and resource compliance status.</li> <li>Monitoring: module responsible for managing and displaying resource usage metrics.</li> <li>Inventory and Catalog: modules responsible for managing and displaying all allocated and available resources.</li> <li>Provisioning: module responsible for the automation and provisioning logic of resources and other services. Tenant: Module responsible for multi-tenant service management and external operational requests</li> </ul> </li> <li>Persistence Layer \u2192 NoSQL database (MongoDB) used by the RM to store normalized data retrieved from the respective ABS submodules.</li> <li>Integration and Communication Layer \u2192 facilitates and orchestrates asynchronous information communication between the ABS and RM modules of the system; allows the ABS submodules to interact with the various APIs of the respective CSPs and external systems</li> <li>Security and Authentication Layer \u2192 access management and encryption of sensitive data from provider systems.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Simplify the management of heterogeneous and complex IT infrastructures \u2192 centralizes resource management across multiple clouds or hybrid infrastructures, simplifying visibility, management, and control of distributed resources.</li> <li>Scalability and flexibility \u2192 identifies the most suitable IT services and resources at the time, continuously adapting to business needs.</li> <li>Cloud expense optimization \u2192 enables constant monitoring and optimization of current and forecasted IT infrastructure expenses.</li> <li>Agility and speed \u2192 on-demand resource allocation and automation of daily operations (e.g., resource management, configuration, scaling) reduces provisioning times and the workload for IT groups.</li> <li>Faster and more informed decisions \u2192 guides IT development strategy with a data-driven approach.</li> <li>Reduced time to market \u2192 reduces the time required to develop and deploy new applications, improving time to market and accelerating response to market needs.</li> <li>Improves the reliability of services and processes \u2192 governance, security, and compliance policies can be centrally managed, ensuring that Resources are protected and regulations are complied with.</li> <li>IT Operations Support \u2192 can be integrated with IT service management (ITSM) and IT operations automation tools (such as Ansible, Chef, SaltStack), improving service quality and reducing manual errors.</li> </ul>"},{"location":"PaaS/#control-room-as-service","title":"Control Room as Service","text":"<p> Control Room as Service </p>"},{"location":"PaaS/#services-description_10","title":"Services Description","text":"<p>The service, developed by Leonardo, involves the adoption of a next-generation platform that aims to provide a comprehensive and innovative response to large urban centers, police forces, large utilities, and organizations that monitor and manage critical infrastructure. This platform is a multi-source, multi-environment system for aggregating, analyzing, and processing data in near real time across multiple application domains. It can leverage existing and installed sensor networks, such as security cameras, hydrogeological detection systems, or fire prevention systems, integrating data with open sources such as social networks, drone monitoring, and satellite data. It can also utilize artificial intelligence algorithms to produce real-time information. This way, operators in the command center and in the field can make decisions quickly and effectively via Leonardo's professional communications networks (DMR, TETRA, and 5G).</p>"},{"location":"PaaS/#features-and-advantages_10","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Integration with heterogeneous and multimodal sources \u2192 the platform enables the integration, interaction, and acquisition of data from various heterogeneous and diverse sources, systems, sensors, or other existing and third-party objects (e.g., on-board cameras on air and ground vehicles, satellite images, IoT sensors, social media, applications, etc.), enabling complete and versatile situational awareness.</li> <li>Intelligent processing \u2192 the system integrates various appropriate Big Data and AI algorithms to create a real-time or predictive decision support system. Georeferencing \u2192 The acquired information, once appropriately normalized and processed, can be displayed and localized on different levels of cartographic maps for a unified view of the situation.</li> <li>Simplified interaction with operators \u2192 the information and detected events are displayed to control operators in a graphical and personalized manner (e.g., alert and notification management), enabling intuitive and simplified interaction.</li> <li>Coordination with Communication systems \u2192 allows you to integrate and coordinate field resources by leveraging the radio network (RIM/DMR) or mobile networks (DMR, TETRA, and 5G).</li> <li>Activity tracking \u2192 the tracking system records and archives all detected and displayed activities (maintenance, training, events).</li> </ul> <p>Architecturally, the platform has a microservices software architecture composed of multiple layers:</p> <ul> <li>Integration layer \u2192 includes all sensors and subsystems that acquire information from the field and is capable of performing initial processing according to domain-specific logic.</li> <li>Core layer \u2192 the core of the system, where data and events from the integration layer are collected via a microservices infrastructure and made available to the various processing engines to generate the overall situation.</li> <li>Presentation layer \u2192 based on an innovative graphical interface designed to present information to the operator in a simple, comprehensive, and effective manner. The use of a GIS (Geographic Information System) allows for the georeferencing of all information and activities, including interactions with integrated subsystems.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Improved risk management and business continuity \u2192 reduced response times to incidents and crises, increased overall organizational resilience.</li> <li>Cost optimization \u2192 centralizing monitoring activities reduces the need for distributed resources across the territory and improves planning and resource utilization.</li> <li>Improved image and reputation \u2192 rapid and coordinated response capabilities, more transparent and timely external communication.</li> <li>Data-driven strategic decisions \u2192 continuous collection of spatial data (weather, traffic, IoT sensors, social monitoring), historical and predictive analysis to support long-term investments and planning.</li> <li>Compliance and governance \u2192 Compliance with regulations on safety, civil protection, the environment, or infrastructure management. Complete audit trail and traceability of decisions and interventions.</li> <li>Integrated and real-time monitoring \u2192 Integration of heterogeneous sources, centralized visualization in static or dynamic maps, automatic notifications and configurable alerts for anomalies or critical events.</li> <li>Efficient operational coordination \u2192 can enable multi-agency collaboration (e.g., law enforcement, civil defense, utility companies, etc.) and create standardized procedures for event management.</li> <li>Shorter problem resolution time \u2192 thanks to the details provided (tracing, distributed diagnosis, code, database, and network visibility).</li> <li>Automation and artificial intelligence \u2192 automatic recognition of patterns or anomalies (e.g., through video analytics or generative AI), automatic generation of intervention or escalation plans, improving forecasting and response capabilities over time.</li> <li>Traceability and reporting \u2192 complete recording of events, decisions, and actions taken.</li> </ul>"},{"location":"PaaS/#it-infrastructure-service-operations-logging-monitoring","title":"IT infrastructure Service Operations (Logging &amp; Monitoring)","text":"<p> IT infrastructure Service Operations (Logging &amp; Monitoring) </p>"},{"location":"PaaS/#services-description_11","title":"Services Description","text":"<p>This is an Application Performance Monitoring (APM) service that monitors and controls infrastructure performance supporting applications (e.g., latency, errors, service availability) and workloads deployed in the PSN cloud environment. It provides centralized collection and analysis across various infrastructure elements: Servers and VMs, Containers and orchestrators, Cloud providers, and Network. It provides AI-based analytics to prevent and resolve issues before they impact users.</p>"},{"location":"PaaS/#features-and-advantages_11","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Full-stack observability \u2192 connects detected infrastructure metrics with application metrics. For example, if an app slows down, Dynatrace shows whether the cause is a code, database, container, or network issue.</li> <li>AI-based analysis (Davis AI) \u2192 the Davis AI engine automatically analyzes data, detects anomalies, and identifies the root cause, reducing noise (fewer unnecessary alerts) to only relevant events. Predictions on resource saturation and future performance (capacity planning).</li> <li>Real-time monitoring \u2192 Interactive and customizable dashboards. Automatic topology mapping (service map) showing how applications and services are connected to the underlying infrastructure resources.</li> <li>Automation and remediation \u2192 integration with cloud providers (AWS, Azure, GCP, OCI), orchestrators (Kubernetes, OpenShift, VMware Tanzu), DevOps tools (Jenkins, Ansible, Terraform, GitOps), and ITSM/ticketing (ServiceNow, Jira). Ability to automate corrective actions, such as scaling containers, restarting services, and applying patches.</li> <li>Multi-cloud and hybrid support \u2192 supports brownfield environments (existing) without requiring code changes.</li> </ul> <p>The main components of the service are:</p> <ul> <li>OneAgent \u2192 installed software agent for automatic metric collection (CPU, RAM, I/O, network, storage), end-to-end transaction tracing between services, log and runtime event capture, process monitoring, and automatic dependency detection.</li> <li>ActiveGate \u2192 manages secure communication between OneAgent and the Dynatrace platform for data compression and encryption, reducing network load in distributed environments, and integration with cloud environments (AWS, Azure, GCP) and external APIs.</li> <li>Dynatrace Cluster \u2192 receives, stores, and processes data from OneAgents, applies analysis and correlation algorithms, ensures scalability, and provides APIs and integration tools (ITSM, CI/CD, DevOps tools).</li> <li>Davis AI \u2192 AI engine for real-time anomaly analysis, automatic root cause analysis, capacity and performance forecasting, and reduced false positive alerts.</li> <li>Dynatrace Web UI / Mobile App / API \u2192 interfaces for user interaction, providing: dashboards. Customizable; topological views (Smartscape); dynamic dependency maps between hosts, services, and applications; access via REST API and SDK for integration with DevOps pipelines, ITSM, and automation tools.</li> <li>Extensions and Integrations \u2192 connect Dynatrace to third-party services and tools</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced operating costs \u2192 thanks to automation and the ability to prevent outages Improved user experience \u2192 user session monitoring, frontend/backend performance analysis, and continuous optimization.</li> <li>Increased productivity for development, operations, and DevOps teams \u2192 thanks to clear insights, automatic root cause analysis, and less time spent diagnosing problems.</li> <li>Improved decision-making for management \u2192 visibility into application KPIs, business metrics, and customer impact, enabling more targeted investments.</li> <li>Support for sustainability goals \u2192 measurement and optimization of cloud resource usage, reducing infrastructure waste.</li> <li>Full-stack observability \u2192 metrics, traces, logs, user sessions; Correlation between frontend/backend/infrastructure components.</li> <li>Automatic detection of dependencies and dynamic topologies (services, hosts, containers, microservices) through automatic discovery.</li> <li>Shorter time to resolution \u2192 thanks to the details provided (tracing, distributed diagnosis, code, database, network visibility).</li> <li>Continuous infrastructure monitoring</li> <li>Built-in governance and security capabilities \u2192 policies, vulnerability visibility, runtime monitoring, compliance.</li> <li>Scalability and high availability \u2192 resilient infrastructure, automatic failovers, and multi-zone deployment in secure clouds to ensure always-on reliability.</li> </ul>"},{"location":"PaaS/#paas-ticket-management-service","title":"PaaS Ticket Management Service","text":"<p> Ticket Management Service </p>"},{"location":"PaaS/#services-description_12","title":"Services Description","text":"<p>The service offers tools for managing user requests, incidents, related problems, and the entire ticketing cycle. Intelligent automation: integrated AI functions (classification, knowledge suggestion, sentiment, and draft generation) reduce manual workload and speed up resolution. Self-service and multi-channel: users can open tickets via the portal or email and view their status. This promotes a good user experience. Integration with assets, services, and configuration: It can connect to the service catalog, CMDB, and asset management, making ticketing part of a broader IT management ecosystem.</p>"},{"location":"PaaS/#features-and-advantages_12","title":"Features and Advantages","text":"<p>The service, based on Matrix42, features a modular architecture, with components covering the user interface, workflow/automation engine, integration with external systems, databases, and reporting. It offers the following main features:</p> <ul> <li>Incident and Service Request Management \u2192 allows for the logging, classification, and resolution of incidents and service requests via a portal, email robot, or Service Desk agent.</li> <li>Self-Service Portal and Service Catalog \u2192 the portal allows users to request services, check ticket status, view announcements, and view knowledge/FAQs. Workflow, Automation, and Low-Code Platform \u2192 offers a visual workflow builder (drag &amp; drop) with no coding required to automate processes such as approvals, escalations, and ticket assignment.</li> <li>Integrated Artificial Intelligence \u2192 the \"AI Assist\" module automatically suggests ticket category, impact, and urgency, analyzes user sentiment (\"user mood\"), and suggests knowledge base articles or similar tickets (\"resolution helper\").</li> <li>SLA Monitoring, Reporting, and Dashboards \u2192 analyzes support processes, KPIs, and provides visibility into service desk performance.</li> <li>Customization, Roles, and Permissions \u2192 Supports the definition of user roles, granular permissions, filters, custom views, and dedicated dashboards. agents/managers.</li> </ul> <p>The main components of the service are:</p> <ul> <li>UUX (Unified User Experience): the platform's UI component, which unifies the web interface (\"low-code solution\") for users, agents, and administrators.</li> <li>SolutionBuilder: A low-code/\"no-code\" module for configuring/modifying layouts, views, data models, and interfaces. Allows interface and data customization without (much) code. - Workflow Studio / Designer / Worker Engine: components for defining, managing, and executing workflows and automations.</li> <li>Database and storage: the platform uses multiple databases (e.g., \"Master\" database for operational data, \"Data Warehouse\" for analysis/reporting, \"History Database\" for logs and change history), typically on Microsoft SQL Server + Analysis Services + Reporting Services.</li> <li>Integration / API / Data providers: the platform supports integration with Active Directory/Azure AD, external databases, REST API, SOAP, flat files, and SQL for reading/writing.</li> <li>Flexible deployment: it can be delivered on-premise, in a public cloud, a private cloud, or a hybrid (\"Cloud your way\") to adapt to compliance, scalability, and geographic requirements.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced operating costs \u2192 thanks to process automation and a reduction in manual tasks, fewer repetitive interventions and a lower cost per ticket. Increased support team productivity \u2192 thanks to workflow automation, the use of AI (for automatic classification, suggestions, pre-populated responses), and self-remediation, the manual burden on IT operators is reduced. The self-service portal and knowledge base enable self-resolution of many user issues.</li> <li>Support for business decisions \u2192 integrated reports and dashboards provide KPIs on average response times, resolution, ticket volumes by category, and seasonal trends.</li> <li>Improved user experience \u2192 users can open tickets, monitor status, and find solutions independently, reducing frustration and wait times. Furthermore, it fosters a collaborative and efficient environment between users and support teams, with agents viewing the same status in real time.</li> <li>Improved control and governance of IT services \u2192 provides a comprehensive view of assets, users, and services, supporting regulatory compliance and service level agreement (SLA) monitoring in a documented and traceable manner.</li> <li>Native integration with the IT ecosystem \u2192 possible integrations with SSO systems (e.g., Active Directory/Azure AD), UEM, Asset Management, Change Management, IT monitoring, HR systems, and others via API, reducing information silos and improving data quality.</li> </ul>"},{"location":"PaaS/#devsecops-family","title":"DevSecOps Family","text":"<p>Below is the list of services belonging to the  DevSecOps family:</p> <ul> <li>Configuration Manager</li> <li>Test Automation</li> <li>Quality Code Analysis</li> <li>DevSecOps As A Service</li> <li>Qualizer DevSecOps</li> </ul>"},{"location":"PaaS/#configuration-manager","title":"Configuration Manager","text":"<p> Configuration Manager Service) </p>"},{"location":"PaaS/#services-description_13","title":"Services Description","text":"<p>The service, based on Red Hat Ansible Automation Platform, is a comprehensive automation solution for managing IT infrastructure, simplifying operations, and accelerating development and deployment processes. It is a platform that acts as a powerful and flexible configuration manager, helping organizations automate repetitive or manual tasks, implement complex configurations, and orchestrate workflows centrally and securely through a declarative and automated approach, ensuring consistency and improving overall operational efficiency and compliance.</p>"},{"location":"PaaS/#features-and-advantages_13","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Declarative automation \u2192 use of playbooks to clearly describe the desired state of resources. Support for role-based automation, reuse, and modular configurations.</li> <li>Centralized execution management \u2192 task orchestration via Ansible Controller with scheduling, auditing, and notifications. Dashboards and reporting for real-time monitoring of automations.</li> <li>Integration with DevOps pipelines \u2192 support for CI/CD tools (Jenkins, GitLab, GitHub Actions, OpenShift Pipelines). Automatic execution of playbooks in response to events or code commits. Credential and secret management. Integration with Red Hat Ansible Vault, CyberArk, HashiCorp Vault, and other secret managers.</li> <li>Scalability and multi-tenancy \u2192 support for multi-organization environments with role and access segregation. Distributed execution via containerized Automation Execution Environments.</li> <li>*Compliance and security * \u2192 full operation logging and Role-Based Access Control (RBAC)-based access control. Compliance with corporate and regulatory security standards.</li> </ul> <p>The service uses an agentless architecture and YAML-based playbooks to define, deploy, and maintain desired system states across various infrastructure components, including servers, networks, storage, and cloud resources. The main components of the service are:</p> <ul> <li>Automation Controller \u2192 Web interface and REST API for centralized automation management. Orchestration engine that coordinates playbook execution.</li> <li>Automation Execution Environments (EE) \u2192 standardized containers containing the Ansible runtime, modules, plugins, and specific dependencies. They enable portability and consistency of execution across different environments.</li> <li>Automation Hub \u2192 private repository for distributing content collections (modules, roles, plugins). It promotes reuse and version control of Ansible content.</li> <li>Automation Mesh \u2192 distributed architecture for scalable job execution on remote nodes or in the cloud. Ensures reliability and load balancing of automations</li> <li>Inventory and Credential Store \u2192 defines target systems (servers, VMs, containers, network devices, cloud services). Securely manages access credentials for each target or environment. APIs and Integrations \u2192 RESTful API for integration with external monitoring, ticketing, or orchestration systems.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced operating costs \u2192 automating repetitive and manual tasks reduces the time spent on system management and maintenance.</li> <li>Increased reliability and service quality \u2192 standardized and automated configurations reduce inconsistencies between environments (dev, test, prod).</li> <li>Scalability of IT business \u2192 the platform grows with the organization, managing hundreds or thousands of nodes without linear staff growth.</li> <li>Improved IT compliance and governance \u2192 all changes are tracked and documented, ensuring transparency and compliance with regulations and corporate policies.</li> <li>Increased productivity and collaboration \u2192 DevOps, IT Operations, and Security teams can work on a single shared platform, reducing organizational silos.</li> <li>End-to-end automation \u2192 from operating system configuration to application deployment, patch management, and ongoing maintenance.</li> <li>Standardization and repeatability \u2192 playbooks ensure consistent configurations and easy reuse of automation code.</li> <li>Centralized and secure management \u2192 a single interface (Controller) for orchestrating jobs, managing inventories, credentials, and access policies (RBAC). Secure management of credentials and secrets (Vault), centralized auditing, and support for enterprise authentication (LDAP, SSO, OAuth).</li> <li>Distributed scalability \u2192 job execution can be distributed across multiple nodes, improving performance and resilience.</li> <li>Complete visibility and traceability \u2192 dashboards and analytical reports allow you to monitor the effectiveness of automations and resource usage.</li> </ul>"},{"location":"PaaS/#test-automation","title":"Test Automation","text":"<p> Test Automation Service) </p>"},{"location":"PaaS/#services-description_14","title":"Services Description","text":"<p>The service is designed to automate software testing activities, with the goal of improving quality, reducing release times, and increasing development process efficiency. The solution uses the UiPath RPA (Robotic Process Automation) platform to automate software testing (functional, regression, API, user interface). It was created to support both IT and business teams in the continuous validation of applications, digital processes, and RPA robots to increase testing efficiency and ensure software integrity. It supports Agile and DevOps approaches with Continuous Testing to ensure code changes do not introduce new defects. Centralized monitoring: Test results are collected and displayed in a single interface, facilitating monitoring and analysis via UiPath Test Manager and extensible with dashboards on UiPath Insights.</p>"},{"location":"PaaS/#features-and-advantages_14","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Test automation for applications \u2192 test automation for web, desktop, mobile, and API applications. Support for cross-browser and cross-platform testing. Reuse of RPA components \u2192 automations developed in UiPath Studio can be reused as test cases. This reduces test creation time and costs.</li> <li>Test Manager \u2192 centralized tool for planning, executing, and monitoring tests. Dashboard with KPIs and integrated reporting.</li> <li>DevOps Integration \u2192 integration with CI/CD tools (Azure DevOps, Jenkins, GitLab, etc.). Ability to run tests in software release pipelines.</li> <li>Scalability \u2192 tests can be deployed to UiPath robots in parallel, reducing execution times.</li> <li>Automated Continuous Testing \u2192 \"Shift-left\" approach: quality is validated from the early stages of development. Ensures fewer bugs in production.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Studio / Studio Pro \u2192 Development environment (IDE) for creating automated tests, similar to creating RPA workflows.</li> <li>Orchestrator \u2192 for scheduling, deploying, and running tests at scale.</li> <li>Test Manager \u2192 for managing requirements, organizing test suites, collecting metrics and reporting.</li> <li>Robotic Test Execution \u2192 UiPath robots become \"digital testers,\" running tests autonomously.</li> <li>Testing Robots \u2192 Specialized test execution robots; support testing frameworks such as NUnit, MSTest, and Junit.</li> <li>Insights \u2192 Manages the creation of dashboards for monitoring various testing processes; allows you to calculate the return on investment of initiatives.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced software release times \u2192 thanks to faster and more continuous testing cycles.</li> <li>Improved software quality \u2192 fewer bugs in production and reduced maintenance costs.</li> <li>Reduced manual testing costs \u2192 less time spent on manual testing and more focus on strategic testing.</li> <li>High Return on Investment (ROI) \u2192 thanks to a single automation and testing platform.</li> <li>IT-business alignment \u2192 greater reliability and traceability of results.</li> <li>Support for Agile and DevOps CI/CD approaches with continuous validation.</li> <li>Reduced risk of regressions \u2192 more confident release of new features.</li> <li>Multi-level test automation (UI, API, mobile, desktop, SAP, Salesforce).</li> <li>Controlled scalability \u2192 assigned resources can be scaled horizontally or vertically to meet performance and operational needs.</li> <li>Multi-platform support (Web, Mobile, Mainframe, API, Enterprise systems).</li> </ul>"},{"location":"PaaS/#quality-code-analysis","title":"Quality Code Analysis","text":"<p> Quality Code Analysis Service) </p>"},{"location":"PaaS/#services-description_15","title":"Services Description","text":"<p>The service, based on SonarQube, offers public administrations a robust static code analysis tool, supporting software quality and integration into CI/CD processes. Thanks to its architecture and ability to integrate into the continuous development and analysis cycle, it enables the development of high-quality software and fully supports DevSecOps initiatives. The service also enables in-depth source code security analysis, detecting known vulnerabilities, injections, poor cryptographic practices, uncontrolled access, and potential exploits. Integrating directly into CI/CD pipelines or through supported DevOps platforms, it analyzes source code against a broad set of quality rules, covering aspects such as code maintainability, software reliability, and application security.</p>"},{"location":"PaaS/#features-and-advantages_15","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Static code analysis \u2192 automatically scans source code with over 5,000 predefined or customizable rules. Supports over 30 languages.</li> <li>Quality gates \u2192 defines minimum quality thresholds (e.g., zero critical bugs, zero vulnerabilities, code coverage &gt; 80%). If the code does not meet the criteria, the build is blocked, preventing the release of \"dirty\" software.</li> <li>Bug and vulnerability Detection \u2192 highlights issues that could cause runtime errors or security risks. Integration with OWASP Top 10, CWE, and SANS security rules.</li> <li>Code smells &amp; debt \u2192 identify development practices that reduce readability or increase technical debt. Calculates an indicator of the time required to \"clean up\" the code.</li> <li>Test coverage \u2192 measures the percentage of code covered by unit tests. Helps identify critical untested areas.</li> <li>DevOps integration \u2192 can be integrated into CI/CD processes. Provides immediate feedback to developers throughout the development cycle</li> <li>Reporting and dashboards \u2192 interactive dashboards with KPIs on quality, security, and maintainability. Historical trends to monitor code quality evolution over time</li> <li>Multi-branch &amp; Pull request analysis \u2192 analysis of specific branches and pull requests for immediate feedback before merging.</li> </ul> <p>The main components of the service are:</p> <ul> <li>SonarQube server \u2192 core module of the service, responsible for running analyses, applying static verification rules, and centralized results management. It includes: analysis engine, quality gate engine, rule repository, user and permissions management, and RESTful APIs.</li> <li>Database \u2192 stores analysis results, active rules, and project history. Supports PostgreSQL, Oracle, SQL Server, and MySQL.</li> <li>SonarScanner \u2192 code analysis tool. It can be run locally by developers or integrated into CI/CD pipelines.</li> <li>CI/CD Integration \u2192 plugins and APIs available for Jenkins, Azure DevOps, GitLab CI, GitHub Actions, Bamboo, and TeamCity.</li> <li>Security and Governance \u2192 Authentication via LDAP, Active Directory, SAML, and OAuth. Granular roles (Admin, Project Admin, Developer, and Viewer).</li> <li>Web portal \u2192 browser-accessible user interface that allows developers, QA, team leaders, and analysts to view detailed project metrics and quality indicators, consult and manage Quality Gates, and view aggregated dashboards and reports at the project portfolio level. The portal is secure, multi-user, and configurable via granular roles and permissions.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Lower risk of bugs in production and reduced maintenance costs \u2192 more reliable and stable software, cleaner and more maintainable code.</li> <li>Compliance with security standards \u2192 regulatory and audit support.</li> <li>Increased customer/stakeholder trust \u2192 software perceived as more secure and robust.</li> <li>Long-term Return On Investment (ROI) \u2192 less time and resources spent on late fixes.</li> <li>Increased team productivity \u2192 less rework, more focus on new features.</li> <li>Support for Agile and DevOps approaches \u2192 the service enables the Clean as You Code approach and automates quality and security checks, reducing time to remediation thanks to immediate feedback to developers.</li> <li>Improved software quality \u2192 through the systematic application of quality rules, the service helps improve code maintainability and readability. Technical debt management \u2192 estimate the time to fix issues.</li> </ul>"},{"location":"PaaS/#devsecops-as-a-service","title":"DevSecOps As A Service","text":"<p> DevSecOps As A Service) </p>"},{"location":"PaaS/#services-description_16","title":"Services Description","text":"<p>The service, based on Gitlab, offers an integrated environment for the complete management of the software development lifecycle according to the DevSecOps approach and practices, providing the tools needed for collaboration, development, testing, security, and software release in a single integrated environment. The service aims to support organizations in introducing application development, release, and management processes characterized by automation, security, and compliance, thus promoting the creation of reliable digital solutions aligned with required quality standards. It allows you to manage projects and repositories, control source code versions, automate CI/CD pipelines, and collaborate efficiently with development teams.</p>"},{"location":"PaaS/#features-and-advantages_16","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Git repositories \u2192 represent the collection point for source code. They enable versioning, change tracking, and collaboration across multiple development teams.</li> <li>CI/CD pipeline \u2192 automation of build, test, and release phases. They reduce manual errors, speed delivery times, and ensure process repeatability.</li> <li>Security Integration (DevSecOps) \u2192 automatic scans of code (SAST), dependencies (SCA), container images, and infrastructure configurations. Early identification of vulnerabilities and tracking of remediation directly within development workflows.</li> <li>Artifact and Container Management \u2192 centralized storage of build artifacts and container images. Support for secure and controlled deployment across the various phases of the environment (development, testing, production).</li> <li>Monitoring and governance \u2192 dashboards to view code quality, security, and project status. Role-based access controls and integration with identity management systems to ensure compliance and accountability.</li> </ul> <p>The main components of the service are:</p> <ul> <li>GitLab core platform \u2192 this is the core of the platform and encompasses its main features: a web interface, API, database, and team collaboration tools.</li> <li>Git repository \u2192 a service dedicated to managing Git repositories. It handles code versioning and timely tracking of all changes.</li> <li>CI/CD Engine GitLab Runner \u2192 a service responsible for executing CI/CD jobs defined within pipelines, automating build, test, and deployment processes.</li> <li>Artifact registry \u2192 a module dedicated to managing and archiving artifacts generated during CI/CD pipelines, such as packages, container images, and libraries. It ensures traceability, security, and reuse of software components.</li> <li>Test Management \u2192 a component that supports the structured management of testing activities, enabling the planning, execution, and monitoring of test cases to ensure software quality throughout the development lifecycle.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced time to market \u2192 thanks to automation and integrated pipelines.</li> <li>Reduced operating costs \u2192 a single platform instead of multiple separate tools.</li> <li>Increased team productivity \u2192 thanks to centralized collaboration. </li> <li>High Return On Investment (ROI) \u2192 reduced rework and post-release remediation.</li> <li>Increased stakeholder trust \u2192 more secure code and faster releases.</li> <li>Native security integration \u2192 integrated DevSecOps capabilities. Ensures compliance with corporate and regulatory policies.</li> <li>Integrate project management with native tools (issue boards, milestones, etc.).</li> <li>Centralize source code and CI/CD pipeline management.</li> <li>Foster collaboration between technical and project teams.</li> <li>Increase team productivity through process automation.</li> </ul>"},{"location":"PaaS/#qualizer-devsecops","title":"Qualizer DevSecOps","text":"<p> DevSecOps As A Service) </p>"},{"location":"PaaS/#services-description_17","title":"Services Description","text":"<p>Leonardo's Qualizer service is a platform designed to meet the needs for visibility, control, and continuous improvement of the software lifecycle throughout the development cycle, in accordance with the DevSecOps and Agile approach. It offers a centralized tool for analyzing, observability, and governance of software quality. The service allows you to aggregate data from various sources, security, monitoring, and testing tools, integrating them into a user dashboard (portal) that clearly and graphically displays various interactive metrics and insights.</p>"},{"location":"PaaS/#features-and-advantages_17","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Ingestion \u2192 automatically collects data from the main tools used in development processes, such as code management systems, continuous integration tools, and software quality and security analysis. The collected data is processed and made available for consultation and analysis.</li> <li>Data processing \u2192 processes the data collected by the ingestion module, normalizes it, and extracts key metrics. The data is structured and made highly accessible via dashboards.</li> <li>Project management \u2192 this module allows you to configure and organize projects within the service. It allows organizations to specify which products, pipelines, and tools they wish to monitor and associate useful information for navigation and management with each project.</li> <li>Analytics engine \u2192 the service provides summary and analytical views that aggregate the collected information and present it clearly and understandably (e.g., DevOps performance metrics; code security status; code quality; number of tests performed; percentage of tests passed).</li> <li>Presentation layer \u2192 data is made available through dashboards that allow for the analysis and continuous monitoring of key metrics.</li> </ul> <p>The Qualizer service is cloud-native and based on a containerized microservices system. This architecture allows Qualizer to be flexible, resilient and secure, with the ability to adapt to different technological scenarios. At a logical level, the architecture is divided into the following main components:</p> <ul> <li>Core modules \u2192 each service module (e.g., ingestion, project management, data processing) is implemented as an independent microservice, orchestrated in a Kubernetes/OpenShift environment to ensure high availability and functional isolation.</li> <li>Database for storing collected data \u2192 data acquired from external systems is stored in a centralized database, which is then processed and normalized to support efficient metrics processing, interactive consultation, and dashboard generation.</li> <li>Integration via REST API \u2192 the service interacts with external platforms through standard APIs, enabling continuous data collection.</li> <li>Messaging broker \u2192 the service uses a Kafka-based messaging system to ensure decoupling between modules, support high event loads, and facilitate horizontal scalability.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced time to market \u2192 thanks to automation and integrated pipelines.</li> <li>Reduced operating costs \u2192 a single platform instead of multiple separate tools.</li> <li>Increased team productivity \u2192 thanks to collaboration between developers and security specialists, aligning objectives and timelines.</li> <li>High Return On Investment (ROI) \u2192 reduced rework and post-release remediation.</li> <li>Increased stakeholder trust \u2192 more secure code and faster releases.</li> <li>Centralized security management \u2192 vulnerabilities detected by various scanning tools are collected, normalized, and tracked in a single location, facilitating the work of security teams and reducing the risk of omissions.</li> <li>Reduced remediation time \u2192 thanks to immediate visibility of vulnerabilities, Qualizer accelerates the process of taking charge and resolving issues. - Continuous improvement based on collected metrics \u2192 through standardized dashboards and indicators, the service allows you to objectively measure team and project performance.</li> <li>Unified dashboard for quality, security, and deployment monitoring.</li> </ul>"},{"location":"PaaS/#big-data-family","title":"Big Data Family","text":"<p>Below is the list of services belonging to the Big Data family:</p> <ul> <li>Data Lake - 1TB</li> <li>Data Lakehouse</li> <li>Business Intelligence</li> <li>Batch/Real time Processing - 1 Worker</li> <li>Event Message</li> <li>Data Governance</li> </ul>"},{"location":"PaaS/#data-lake-1tb","title":"Data Lake - 1TB","text":"<p> Data Lake Service) </p>"},{"location":"PaaS/#services-description_18","title":"Services Description","text":"<p>It provides a ready-to-use platform developed by Leonardo that has all the features developers, data scientists, and analysts need to easily archive data of all sizes, shapes, and velocities. It allows for the ingestion of a wide range of heterogeneous data sources (structured, semi-structured, and unstructured), from various internal and external sources within the organizations (relational databases, files, web applications, cloud, web services, etc.), and of various classification types. It integrates with the Processing/ETL module for accessing data and metadata for the necessary processing or normalization, and with the Data Governance module for managing data access and managing data security and protection.</p>"},{"location":"PaaS/#features-and-advantages_18","title":"Features and Advantages","text":"<p>Data Lake is the foundation for all Big Data services; without it, other services cannot be activated. It was designed based on, and with full wire-protocol compatibility with, Amazon's renowned cloud storage product (Simple Storage Service). This enables the scalability needed to manage data volumes in the petabyte range (and beyond) typical of the Big Data world, while ensuring maximum interoperability and compatibility with languages, libraries, and products compatible with the S3 protocol. Data Lake's capabilities are based on a horizontally scalable infrastructure, capable of supporting heavy read and write loads, ensuring consistent performance even in scenarios characterized by large amounts of data and intensive throughput.</p> <p>The development technology is based on MinIO, an object storage solution fully compatible with the S3 protocol. The application layer is built on distributed object storage, which in turn relies on an underlying block storage layer, which can be implemented either bare metal or using software-defined solutions. The overall architecture is based on containers orchestrated by a resource manager based on an enterprise-class Kubernetes distribution. Resource management and container orchestration are based on the Red Hat Openshift platform. To meet the most stringent security requirements, data encryption is implemented using keys stored on HSM devices. This will be made possible by interfacing with the KMS module common to all PaaS services.</p> <p>The service offers the following advantages:</p> <ul> <li>Compliance and governance \u2192 supports versioning, auditing, encryption (AES-256), and integration with identity management systems.</li> <li>Flexibility and scalability \u2192 supports horizontal scalability; ideal for companies with rapidly growing data or multi-petabyte storage needs.</li> <li>Rapid time to market \u2192 allows you to quickly deploy new analytical applications or data pipelines without worrying about underlying management.</li> <li>Simplified management \u2192 teams don't need to worry about technical maintenance. There's no need to configure clusters, load balancers, manual replication, or complex monitoring; it offers native monitoring and alerting tools.</li> <li>Reduced operating costs \u2192 the service is built with open source standards and compatible with S3, thus reducing licensing costs compared to proprietary solutions.</li> <li>High availability and resilience \u2192 integrated replication and support for erasure coding ensure data resilience and business continuity.</li> <li>Optimized performance \u2192 designed for high-performance object storage, with high throughput and low latency. Ideal for real-time analytics and intensive ML/AI workloads.</li> <li>Interoperability \u2192 S3 API compatibility allows for easy integration of existing applications. Supports multi-protocol access.</li> <li>Automation and DevOps-friendly \u2192 it enables continuous updates without downtime and simplified backup management.</li> </ul>"},{"location":"PaaS/#data-lakehouse","title":"Data Lakehouse","text":"<p> Data Lake Service) </p>"},{"location":"PaaS/#services-description_19","title":"Services Description","text":"<p>The solution, based on Cloudera's Open Data Lakehouse, helps organizations perform rapid analytics on all data, both structured and unstructured, at scale. It eliminates silos and enables teams to collaborate on the same data using their preferred tools. It allows for the ingestion of a wide range of heterogeneous data sources (structured, semi-structured, and unstructured), from various internal and external sources within the organizations (relational databases, files, web applications, cloud, web services, etc.), and of various classification types. It integrates with the Processing/ETL module for accessing data and metadata for the necessary processing or normalization, and with the Data Governance module for managing data access and managing data security and protection.</p>"},{"location":"PaaS/#features-and-advantages_19","title":"Features and Advantages","text":"<p>It is composed of three modern data architectures:</p> <ul> <li>Open Data Lakehouse \u2192 enables multifunctional analytics on both streaming data and data stored in a cloud-native object store across hybrid and multi-cloud environments.</li> <li>Unified Data Fabric \u2192 centrally orchestrates disparate data sources intelligently and securely.</li> <li>Data Mesh \u2192 helps eliminate data silos by distributing ownership to cross-functional teams while maintaining a common data infrastructure.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Shared Data Experience (SDX) \u2192 it combines centralized security, governance, traceability, and enterprise-grade management capabilities with shared metadata and a data catalog.</li> <li>Data HUB \u2192 it allows users to deploy analytics clusters across the entire data lifecycle as elastic IaaS experiences.</li> <li>Data Services \u2192 they are containerized analytical applications through which users can deploy clusters similar to those possible in Data Hub, but with the added benefit of being delivered as a Platform as a Service (PaaS) experience.</li> <li>Cloudera Data Warehouse (CDW) \u2192 it uses the combination of Apache Impala and Apache Iceberg to offer broader coverage than traditional data warehouses (it stores both data and metadata in the data lake, leading to a range of benefits).</li> <li>Cloudera Machine Learning (CML) \u2192 a machine learning workflow solution that supports the entire data science lifecycle, designed to use containers for efficient data engineering and machine learning tasks.</li> <li>Data Catalog \u2192 it offers a centralized and scalable way to democratize data access across the entire Data Lakehouse. Management Console \u2192 provides a single interface to support the operation of users, environments, and analytical services that support each Data Lakehouse.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Compliance and governance \u2192 supports versioning, auditing, encryption (AES-256), and integration with identity management systems.</li> <li>Flexibility and scalability \u2192 supports horizontal scalability; ideal for companies with rapidly growing data or multi-petabyte storage needs.</li> <li>Rapid time to market \u2192 allows you to quickly deploy new analytical applications or data pipelines without worrying about underlying management.</li> <li>Simplified management \u2192 teams don't need to worry about technical maintenance. There's no need to configure clusters, load balancers, manual replication, or complex monitoring; it offers native monitoring and alerting tools.</li> <li>Reduced operating costs \u2192 the service is built with open source standards and compatible with S3, thus reducing licensing costs compared to proprietary solutions.</li> <li>High availability and resilience \u2192 integrated replication and support for erasure coding ensure data resilience and business continuity.</li> <li>Optimized performance \u2192 designed for high-performance object storage, with high throughput and low latency. Ideal for real-time analytics and intensive ML/AI workloads.</li> <li>Interoperability \u2192 S3 API compatibility allows for easy integration of existing applications. Supports multi-protocol access.</li> <li>Automation and DevOps-friendly \u2192 it enables continuous updates without downtime and simplified backup management.</li> </ul>"},{"location":"PaaS/#business-intelligence","title":"Business Intelligence","text":"<p> Data Lakehouse Service) </p>"},{"location":"PaaS/#services-description_20","title":"Services Description","text":"<p>The solution offers a platform with a suite of Business Intelligence tools based on Microsoft's Power BI, enabling organizations to analyze and visualize data to gain strategic insights. It transforms raw data into interactive reports and visually appealing dashboards, facilitating data-driven decision-making. Users can connect to a wide range of data sources, including SQL and NoSQL databases, files, cloud services like Azure, and many others. It supports integration with other Microsoft products, such as Office 365 and SharePoint, improving collaboration and information sharing within the organization. Useful for: - centralizing business data from heterogeneous sources (ERP, CRM, databases, Excel, cloud services). - analyzing and visualizing data through interactive dashboards and dynamic reports. - enabling data-driven decision-making at all levels of the organization. - automating report updates and distribution without manual intervention. - ensuring security and governance of analytical data in a controlled environment. - facilitating collaboration between analysts, managers, and end users through online sharing.</p>"},{"location":"PaaS/#features-and-advantages_20","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Data collection and integration \u2192 over 500 connectors for databases (SQL, Oracle, SAP, etc.), cloud services (Azure, Salesforce, Google Analytics, etc.), and local files.</li> <li>Data transformation (ETL) \u2192 allows you to extract, clean, and transform data before loading it into the analytical model.</li> <li>Data modeling \u2192 creation of relational models and complex calculations using the DAX (Data Analysis Expressions) language.</li> <li>Analysis and visualization \u2192 customizable charts, KPIs, maps, and visuals, with automatic data updates.</li> <li>Collaboration and sharing \u2192 publishing and sharing of reports and dashboards via web or mobile app.</li> <li>Automation and refresh \u2192 automatic updating of datasets, even in real time.</li> <li>Security and governance \u2192 centralized management of users, roles, and access based on Azure Active Directory.</li> <li>AI and advanced analytics \u2192 integrated generative AI capabilities and automatic analysis of trends or anomalies.</li> <li>Microsoft 365 integration \u2192 reports can be integrated directly into enterprise collaboration apps.</li> <li>Cloud scalability (PaaS) \u2192 managed and scalable infrastructure.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Gateway \u2192 it enables secure connections between on-premises data and Power BI cloud services. It supports integration with numerous identity providers (e.g., Azure AD) and manages connections and queries to on-premises data.</li> <li>Service \u2192 it manages the creation, publishing, and sharing of reports and dashboards, data refresh, and querying data stored in the cloud.</li> <li>Report Server \u2192 it offers similar functionality to Power BI Service, allowing users to publish, share, and view reports within their on-premises environment.</li> <li>Dataflows \u2192 they allow you to create and manage ETL (Extract, Transform, Load) data pipelines directly within Power BI. These dataflows support the integration and transformation of data from numerous sources to create consolidated data models.</li> <li>Desktop \u2192 it is the client application used for creating reports and data models. Available for Windows, it allows users to connect to numerous data sources, run queries, and create advanced visualizations.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Faster and better decisions \u2192 real-time or near-real-time access to data, intuitive visualizations, and drill-down into information, enabling more informed decisions.</li> <li>Increased productivity and speed of insight \u2192 automated creation/reporting, self-service dashboards, and easy sharing enable business users to act faster.</li> <li>Reduced total cost of ownership (TCO) and lower costs \u2192 managed infrastructure and reduced need for on-premise infrastructure reduce overall costs.</li> <li>Increased collaboration and a data-driven culture \u2192 dashboard sharing, integration with other tools, and ease of use promote adoption among non-technical users.</li> <li>Access anywhere and from different devices \u2192 availability via cloud, mobile apps, and remote access allows users to work on the move or from different locations.</li> <li>Extensive data integration \u2192 support for numerous connectors to on-premise and cloud sources, enabling consolidation of disparate data.</li> <li>Efficient data preparation and modeling \u2192 integrated tools enable ETL, modeling, and complex calculations.</li> <li>Interactive and self-service visualization \u2192 intuitive, drag-and-drop interface and pre-built templates allow non-technical users to build reports independently.</li> <li>Security, governance, and compliance \u2192 Features such as encryption and auditing support access control and compliance. Infrastructure scalability and flexibility.</li> </ul>"},{"location":"PaaS/#batchreal-time-processing-1-worker","title":"Batch/Real time Processing - 1 Worker","text":"<p> Batch/Real time Processing Service) </p>"},{"location":"PaaS/#services-description_21","title":"Services Description","text":"<p>It is a platform that provides a set of tools for processing, integrating, quality-checking, and preparing data from heterogeneous sources stored in the Data Lake, both in real time and in batch mode. It offers a user-friendly graphical interface for designing and implementing data integration workflows using a visual approach, following the ETL (Extract \u2013 Transform \u2013 Load) approach. This reduces the complexity of data integration and allows users to focus on business logic rather than programming code. It supports a wide range of data sources, including relational databases, files, web applications, cloud, web services, and more. This makes it extremely flexible for data integration in a variety of contexts. It also offers data quality management tools, allowing users to clean, standardize, and enrich their data to ensure its accuracy and reliability.</p>"},{"location":"PaaS/#features-and-advantages_21","title":"Features and Advantages","text":"<p>The main features and functionalities of the service are:</p> <ul> <li>Heterogeneous and large-scale data processing \u2192 It supports a large number of data sources in batch and streaming mode (for example, datasets stored on HDFS, S3, ADLS Gen2, and GCS in CSV, Parquet, Avro, and other formats, as well as RDBMS via JDBC or all popular NoSQL, Apache Kafka, and more).</li> <li>It is natively integrated with the Data Lake and Batch/Real-Time Processing PaaS of the Big Data family.</li> <li>It allows to implement complex data pipelines \u2192 leveraging the parallel and distributed computing capacity provided by a Spark cluster.</li> <li>It provides an interactive mode to debug flows and explore data easily and intuitively.</li> <li>It guarantees the maximum scalability necessary to meet the needs of organizations of any size, from small businesses to large enterprises.</li> </ul> <p>The main architectural components of the service are as follows:</p> <ul> <li>Visual ETL Architecture \u2192 provides various blocks that allow you to visually design an ETL, ELT, and ELL pipeline. It allows you to read, write, and modify data from different sources, interfacing with the Data Lake and Monitoring module, and can use the Processing module for data-intensive processing.</li> <li>Apache Spark \u2192 Open-source parallel processing framework that supports in-memory processing to improve the performance of applications that analyze Big Data.</li> <li>JupyterLab \u2192 Interactive notebook-based development environment designed primarily for working with data, scientific calculations, and machine learning. It supports writing and executing interactive code in languages \u200b\u200bsuch as Python, R, or Julia.</li> <li>NodeRed \u2192 Visual, low-code development environment for creating applications that connect devices, web services, APIs, and systems.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Support for data-driven strategies, faster and more informed decisions \u2192 centralized data for service customization (e.g., real-time analytics for marketing, IoT, e-commerce, etc.) and ready-to-use pipelines without complex development. </li> <li>Greater focus on core business \u2192 development and IT teams do not have to worry about technical maintenance, as it is managed. - Reduced operating costs and service scalability \u2192 no infrastructure to manage; support for large data volumes (batch) or continuous flows (streaming); automation of extraction, transformation, and loading processes with real-time scheduling or triggers; same framework for historical data and real-time flows.</li> <li>Integration with cloud ecosystem (data warehouse, data lake, BI, AI/ML).</li> <li>Guaranteed security and compliance (encryption, access, audit logs).</li> <li>Integrated monitoring \u2192 metrics, alerts, and centralized logging for ETL pipelines.</li> </ul>"},{"location":"PaaS/#event-message","title":"Event Message","text":"<p> Event Message Service) </p>"},{"location":"PaaS/#services-description_22","title":"Services Description","text":"<p>It provides a platform developed by Leonardo for developing real-time applications and data pipelines and acts as a message broker, providing publish-subscribe functionality. It increases the scalability and resilience of existing applications by decoupling architectural components using a reactive approach based on asynchronous interactions. The platform can scale horizontally and provide ordered message delivery capabilities. Like other Big Data PaaS modules, the solution is based on containerized resources orchestrated via Kubernetes. It enables near-real-time analytical processes through streaming and facilitates the implementation of IoT use cases.</p>"},{"location":"PaaS/#features-and-advantages_22","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>A useful tool for implementing reliable data exchanges between different components.</li> <li>Ability to partition messaging workloads as application requirements change.</li> <li>Real-time streaming for data processing.</li> <li>Native support for data/message playback.</li> <li>Integration with the Batch/Stream Processing module.</li> <li>Web interface for monitoring: Brokers Topics/Messages, Consumers, ACLs.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Apache Kafka-based solution \u2192 publish-subscribe messaging platform built to manage real-time data exchange for streaming, distributed pipelining, and replay of data feeds for fast, scalable operations.</li> <li>Broker-based solution that operates by maintaining data streams as records within a cluster of servers.</li> <li>Topic \u2192 addressable abstraction used to show interest in a given data stream (series of records/messages).</li> <li>Partitions \u2192 topics can be divided into a series of order queues called partitions. </li> <li>Persistence \u2192 server clusters that durably maintain records/messages as they are published. </li> <li>Producers \u2192 defines which topic/partition a given record/message should be published to. </li> <li>Consumers \u2192 entities that process records/messages</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Faster time-to-market \u2192 New applications can be integrated rapidly via events, accelerating the development of new products and features.</li> <li>Greater agility \u2192 Facilitates the creation of modular and scalable services without major changes to the existing system.</li> <li>Reduced risk of operational failures \u2192 PaaS often includes SLAs, monitoring, backup, and redundancy, reducing the risk of downtime or data loss.</li> <li>Faster, more informed decisions \u2192 Real-time analytics for marketing, IoT, and e-commerce.</li> <li>Predictable costs \u2192 Reduces the risk of over-provisioning or unexpected maintenance costs.</li> <li>Scalability \u2192 Support for large event volumes without performance degradation</li> <li>High availability and fault tolerance</li> <li>Simplified management \u2192 No need to manage clusters, patches, software upgrades, or complex configurations</li> <li>Optimized Performance and Latency \u2192 Compression, batching, and automatic topic management improve performance</li> <li>Security and Compliance \u2192 Authentication, authorization, and encryption in transit and at rest are managed by the provider.</li> </ul>"},{"location":"PaaS/#data-governance","title":"Data Governance","text":"<p> Data Governance Service) </p>"},{"location":"PaaS/#services-description_23","title":"Services Description","text":"<p>A service developed by Leonardo that provides a platform with a single, secure, and centralized point of reference for data control. Leveraging search and discovery tools and connectors to extract metadata from any data source, it simplifies data protection, analysis, and pipeline management, as well as accelerating ETL processes. It allows you to automatically analyze, profile, organize, link, and enrich all metadata, implement algorithms for automatic metadata and relationship extraction, and support regulatory and data privacy compliance with intelligent data lineage tracking and compliance monitoring. It simplifies data search and access and verifies its validity before sharing it with other users. It enables the production of data quality data (a measure of data condition based on factors such as accuracy, completeness, consistency, and reliability). It allows you to oversee data error resolution efforts and maintain compliance with internal audits and external regulations. It provides immediate support for the detection and classification of personal data and other sensitive data.</p>"},{"location":"PaaS/#features-and-advantages_23","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Data Search &amp; Discovery \u2192 Automatic exploration of Data Lake datasets for (meta)data that can enrich or deepen knowledge of the information held.</li> <li>Data &amp; Metadata Catalog \u2192 Extraction of information that makes the data searchable.</li> <li>Data Lineage \u2192 Tracking the entire data lifecycle, from source to destination.</li> <li>CL/Audit \u2192 Allows for robust granular data access permission management and auditing of data usage (this means being able to answer the question \"Who accessed what data and when?\" at any time).</li> </ul> <p>The service use a tool of Data Hub that extends the concept of a data catalog by offering data discovery, data observability, and data governance functions. It integrates natively with other architecture components, adding all the features that are particularly useful for achieving compliance objectives, such as privacy, security, and process quality management. This tool allows you to verify changes made to data within the catalog over time, distinguishing the various sources that have populated the Data Lake, the type of data entered (personal data, financial data, etc.), and identifying data that is sensitive to specific laws or compliance procedures, whether internal or external to the organization. Data integration within DataHub occurs primarily in two ways: - PUSH \u2192 automatically within third-party applications such as Airflow, Apache Spark, Great Expectations, etc. - PULL \u2192 manually by the developer prior to loading the data into the data lake via dedicated REST APIs.</p> <p>The service offers the following advantages:</p> <ul> <li>Improved governance and compliance \u2192 Complete data traceability (\"data lineage\") to demonstrate compliance with GDPR, ISO, or industry regulations.</li> <li>Increased data trust \u2192 Certainty about the data's provenance, how it has been transformed, and how up-to-date it is. </li> <li>Reduced risks and operational costs \u2192 Fewer duplications, inconsistencies, and \"orphaned\" datasets. Reduced time wasted searching or validating data.</li> <li>Accelerating time to market \u2192 Easily discover and reuse existing datasets, reducing reliance on technical teams.</li> <li>Greater focus on core business \u2192 Teams no longer need to worry about technical maintenance.</li> <li>Centralized catalog and metadata \u2192 Provides an active data catalog with technical and operational metadata. Automatically integrate with Big Data systems (Kafka, Hive, Spark, Databricks, etc.).</li> <li>Automated Data Lineage \u2192 Automatically tracks end-to-end data flows from ingestion to transformations, all the way to consumption (dashboard, API, ML).</li> <li>Native APIs and integrations \u2192 Exposes APIs and plugins for continuous integration with orchestration, observability, quality, and security tools.</li> <li>Access and Security Policy Management \u2192 Centralizes access policies based on roles and classifications. Improves data security without fragmenting rules across services.</li> <li>Automation and Self-Service \u2192 Fosters a self-service data discovery model for data engineers and data scientists.</li> <li>Scalability and modern architecture \u2192 Microservices architecture and Metadata Graph.</li> </ul>"},{"location":"PaaS/#artificial-intelligence-ai-family","title":"Artificial Intelligence (AI) Family","text":"<p>Below is the list of services belonging to the Artificial Intelligence (AI) family:</p> <ul> <li>Speech to Text</li> <li>AI Audio &amp; Video Analytics</li> <li>OCR</li> <li>Text Analytics</li> <li>Text Translation</li> <li>AI Search - RAG</li> <li>AI Platform</li> <li>Semantic Knowledge Search</li> <li>AI SLM/LLM</li> <li>AI workflow</li> <li>Vector DB</li> </ul>"},{"location":"PaaS/#speech-to-text","title":"Speech to Text","text":"<p> Speech to Text Service) </p>"},{"location":"PaaS/#services-description_24","title":"Services Description","text":"<p>This service provides an advanced speech-to-text model for transcribing audio files into text, trained on a vast dataset of audio and text in various languages \u200b\u200busing neural AI (deep learning) models specialized in automatic speech recognition (ASR). The service is optimized for English transcription, but can also recognize and transcribe speech in other languages, still returning the text in English. Furthermore, it can automatically identify the spoken language and supports automatic speech translation. It is useful for automatically transcribing conversations, interviews, meetings, call centers, podcasts, or videos; supporting chatbots and voice assistants, translating voice into text understandable by NLP or AI systems; indexing and analyzing audio content (semantic search, sentiment analysis, data mining); and digitizing voice archives and official minutes, ensuring accuracy and traceability.</p>"},{"location":"PaaS/#features-and-advantages_24","title":"Features and Advantages","text":"<p>This is a whisper-based service that provides an API layer and an SDK for integration with existing applications. All tasks are represented as a sequence of tokens that the model predicts, unifying and optimizing the speech processing pipeline.</p> <p>The service offers the following main features:</p> <ul> <li>Automatic Speech Recognition (ASR) \u2192 converts speech to text in real time or from audio files (WAV, MP3, MP4, FLAC, etc.). Multilingual support. Advanced Neural Accuracy \u2192 uses sequence-to-sequence Transformer models, trained for a wide range of speech processing tasks, such as multilingual speech recognition, speech translation, and language identification.</li> <li>Multilingual Recognition and Machine Translation</li> <li>Real-time Transcription (Streaming) Batch Processing</li> <li>Temporal Segmentation \u2192 returns start/end timestamps to synchronize text and audio (useful for subtitles or editing).</li> <li>Text Cleanup and Normalization \u2192 automatically corrects punctuation, capitalization, and formatting.</li> <li>Accent and Ambient Noise Support \u2192 is robust against background noise, poor microphones, and natural (non-studio) speech.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Whisper engine (ASR Core) \u2192 transformer neural model trained on millions of hours of audio-text data.</li> <li>Language detection module \u2192 automatically identifies the language of the speech.</li> <li>Post-processing &amp; text normalization \u2192 corrects the transcription, inserts punctuation, and adds consistent formatting.</li> <li>Optional translation layer \u2192 uses a Neural Machine Translation (NMT) model to translate the transcription into another language. </li> <li>Storage and logging \u2192 stores results, metadata, and logs for auditing and analysis. </li> <li>Integration layer (API / SDK) \u2192 interface for external apps, dashboards, or AI pipelines.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced operating costs \u2192 automate the transcription of audio, meetings, interviews, and minutes without requiring dedicated staff.</li> <li>Increased staff productivity \u2192 automatic transcription saves hours of work.</li> <li>Accelerated document processes \u2192 minutes, interviews, meetings, or consultations can be transcribed and distributed in real time, improving administrative efficiency.</li> <li>Accessibility and inclusion \u2192 generate subtitles and text from audio/video content, improving accessibility for people with hearing impairments and multilingual communication.</li> <li>Data-driven decisions (Voice Analytics) \u2192 voice transcriptions become analyzeable text data, supporting data-driven decisions.</li> <li>Improved customer experience \u2192 chatbots, contact centers, and digital assistants become more effective by recognizing voice and responding naturally.</li> <li>High linguistic accuracy \u2192 the service, based on Transformer architecture, guarantees more precise transcriptions even in the presence of accents, noise, or natural speech.</li> <li>Structured and interoperable output \u2192 output in standard formats (JSON, TXT, SRT, VTT, DOCX) easily integrated with databases or document workflows.</li> <li>Model updates \u2192 managed and ongoing model updates, improving accuracy and reducing errors over time.</li> <li>High performance and low latency \u2192 processing in milliseconds for live streams, seconds for large files.</li> <li>Multimodal AI support \u2192 can be combined with Text Analytics, Translation, and Text-to-Speech services to create complete speech pipelines (e.g., transcription + translation + synthesis).</li> <li>Service scalability \u2192 allows you to simultaneously manage thousands of speech streams by providing and managing the necessary infrastructure.</li> </ul>"},{"location":"PaaS/#ai-audio-video-analytics","title":"AI Audio &amp; Video Analytics","text":"<p> AI Audio &amp; Video Analytics Service) </p>"},{"location":"PaaS/#services-description_25","title":"Services Description","text":"<p>These are two services, separate but integrable when necessary, developed by Leonardo.</p> <p>The AI Audio Analytics PaaS provides a ready-to-use platform that, thanks to AI-based algorithms on audio sources, allows the identification of unique features from audio streams using preloaded AI models. These features allow the identification of a person's voice, noises, and possible anomalies in the monitored environment.  </p> <p>The AI Video Analytics PaaS is a ready-to-use platform with pre-trained algorithms that leverage computer vision techniques, capable of processing and understanding visual information present in two-dimensional images or video sequences.</p>"},{"location":"PaaS/#features-and-advantages_25","title":"Features and Advantages","text":"<p>The AI \u200b\u200bAudio Analytics platform can work with signals produced in the field from various audio sources, overcoming the \"curse of dimensionality\" problem caused by the high-dimensionality of the phenomenon through the use of unsupervised and supervised approaches. These approaches dynamically identify an optimal set of features to identify similarities between signals for the same event/process and differences between signals for different events/processes. The output of these processes can then be treated as characteristics in statistical detection methods, but they rely heavily on the analyst's understanding of a possible link between the signal and the process/event being detected. The AI \u200b\u200bAudio Analytics solution is primarily composed of the following tools: - Swagger UI \u2192 a collection of HTML, CSS, and JavaScript assets automatically generated from the documentation, which must comply with the OpenAPI standard. - ML models \u2192 algorithms for extracting information from audio sources for:     - Speaker identification: an ML model capable of identifying the speaker using voice characteristics.     - Audio anomaly insight: an ML model capable of detecting sound anomalies in production or cyclical systems.     - Environment classification: an ML model capable of identifying and classifying audio tracks. - FastAPI framework \u2192 a modern, fast (high-performance) web framework for building APIs with Python.</p> <p>The AI \u200b\u200bVideo Analytics platform includes subsystems: preprocessing, image analysis, and image interpretation. The service can perform video analysis while optimizing computation time through the use of single-pass convoluted networks, which analyze all parts of the image in parallel and simultaneously, eliminating the need for sliding windows. The AI \u200b\u200bVideo Analytics solution is primarily composed of the following tools: - ML models \u2192 algorithms for extracting information from video sources.     - Object detector: recognizes and locates people and objects within a given frame by extracting metadata containing classification and spatial location     - Spacial counter: an extension of the Object Detector model, it can also process a single-shot counting for each object class for each frame     - Object counter: capable of both locating people and objects and obtaining a count of the detected objects.</p> <p>The service offers the following advantages:</p> <ul> <li>Improved security and compliance \u2192 automatic detection of anomalous behavior, intrusions, or risky situations. Support for compliance policies and audits based on video/audio evidence.</li> <li>Improved customer experience \u2192 analysis of tone of voice, emotions, and wait times for improved quality of service and customer interactions.</li> <li>Reduced operating costs \u2192 automated continuous monitoring of environments, processes, and media flows, resulting in optimized human resources and response times.</li> <li>Data-driven decisions \u2192 media content becomes a source of structured and analyzable data for visual and audio insights that can be integrated into Business Intelligence systems.</li> <li>Innovation and new business models \u2192 enable new services such as retail analytics, behavioral marketing, intelligent security, and event monitoring for competitive advantage and market differentiation.</li> <li>Scalability and simplified management \u2192 management of resources, workloads, and updates.</li> <li>Integrated advanced analytics \u2192 ready-to-use features, e.g. Facial recognition, object detection, speech-to-text, voice sentiment, anomaly detection.</li> <li>Real-time and batch processing \u2192 analysis of live streams or recorded media archives, thanks to the integration of Processing PaaS.</li> <li>Multi-format and multi-source support \u2192 compatibility with various formats (MP4, AVI, WAV, RTSP, etc.) and heterogeneous devices (cameras, microphones, sensors).</li> <li>Integrated security and privacy \u2192 stream encryption, access control.</li> <li>Operational monitoring and insights.</li> </ul>"},{"location":"PaaS/#optical-character-recognition-ocr","title":"Optical Character Recognition (OCR)","text":"<p> Optical Character Recognition (OCR) Service) </p>"},{"location":"PaaS/#services-description_26","title":"Services Description","text":"<p>The services offer innovative computer vision capabilities, enabling the transformation of visual content containing text into processable digital content. It is useful for analyzing images, reading text, and detecting faces with predefined image tagging, text extraction with Optical Character Recognition (OCR), and responsible facial recognition. The OCR component (reading printed or handwritten text) is integrated as a REST API or client library that allows you to send images/documents and obtain text extraction from them. It is useful in multiple scenarios: automatic text extraction from images and vice versa, document processing (e.g., scanning PDFs, form images, extracting written or printed text), and process automation (e.g., data acquisition from forms, invoices, intelligent archiving, full-text search in image content). The service can be offered using two technologies: - Basic with Google Tesseract OCR. - Standard with Microsoft AI Azure Vision.</p>"},{"location":"PaaS/#features-and-advantages_26","title":"Features and Advantages","text":"<p>The main features of the Google Tesseract OCR-based service are:</p> <ul> <li>Text recognition \u2192 recognizes printed or written text in over 100 languages</li> <li>Multi-language models \u2192 can process mixed languages \u200b\u200b(e.g., English + numbers + symbols)</li> <li>Multiple image input \u2192 supports PNG, JPEG, TIFF, BMP, PDF (via external libraries such as pdfimages).</li> <li>Page layout analysis \u2192 recognizes text blocks, columns, paragraphs, direction, and orientation. Multiple output formats.</li> <li>Model training &amp; fine-tuning \u2192 ability to train models on specific fonts or languages \u200b\u200b(with dedicated datasets).</li> <li>Image enhancement \u2192 supports skew correction, binarization, thresholding, and deskewing.</li> </ul> <p>The main components of the Google Tesseract OCR-based service are:</p> <ul> <li>API Layer \u2192 Exposes REST endpoints for loading images or URLs.</li> <li>Compute Layer \u2192 Runs the Tesseract engine in scalable containers.</li> <li>Storage Layer \u2192 Stores image input and text output.</li> <li>Processing Layer \u2192 OCR engine and image management.</li> <li>API Layer \u2192 Exposes REST endpoints for loading images or URLs.</li> <li>Monitoring &amp; Logging \u2192 Performance monitoring and call logging.</li> <li>Security Layer \u2192 API and data protection.</li> </ul> <p>The main features of the Azure Vision AI-based service are:</p> <ul> <li>Printed and handwritten text extraction \u2192 text is returned in blocks/lines/words with spatial coordinates and confidence scores.</li> <li>Multilingual and mixed script support \u2192 supports numerous international languages \u200b\u200band scripts. It can recognize mixed modalities (printed text + handwritten text) in a single image. - Different input modalities and APIs \u2192 Input single images (JPEG, PNG, BMP) or documents (PDF, TIFF) up to specific limits. Local execution possible via Docker containers.</li> </ul> <p>The main components of the Azure Vision AI-based service are:</p> <ul> <li>Client Layer \u2192 It can be a web app, a microservice, or an automated workflow. It sends images via HTTP POST API or via SDK.</li> <li>API Gateway and Identity Management.</li> <li>AI Vision Service \u2192 The heart of the system, hosting AI vision models for text recognition; the \"Read\" OCR engine is optimized for complex documents.</li> <li>Storage and Temporary Pipeline \u2192 During processing, images are temporarily stored. The results are then returned as JSON output or saved to defined resources (e.g., Data Lake, DB, or Cognitive Search).</li> <li>Integration and Automation \u2192 The results can be sent or processed for document workflows, full-text indexing and search, data analysis and Big Data, archiving, notifications, or vertical applications.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Lower document management costs \u2192 fewer staff dedicated to data entry and fewer errors that generate correction costs or disputes.</li> <li>Paperless transformation \u2192 enables the complete digitalization of archives and paper flows, reducing paper consumption and physical space.</li> <li>Faster and more traceable workflows \u2192 Scanned documents become immediately accessible data and can be integrated into management systems.</li> <li>Traceability and compliant archiving \u2192 Facilitates compliant digital archiving, improving compliance management (GDPR, electronic preservation).</li> <li>Extensive support \u2192 Native support for dozens of languages \u200b\u200band formats (e.g., PDF, JPEG, PNG, TIFF, scanned documents).</li> <li>Standard formats \u2192 The extracted text is immediately usable in management or analytics systems.</li> <li>Real-time and batch processing \u2192 Analysis of live streaming or recorded multimedia archives, thanks to the integration of Processing PaaS.</li> <li>Managed maintenance and updates \u2192 the infrastructure, security, and updates of AI models are managed.</li> </ul>"},{"location":"PaaS/#text-analytics","title":"Text Analytics","text":"<p> Text Analytics Service) </p>"},{"location":"PaaS/#services-description_27","title":"Services Description","text":"<p>The Text Analytics PaaS solution,  developed by Leonardo, provides a ready-to-use NLP (Natural Language Processing) platform capable of extracting structured and interpretable information from unstructured texts, enabling quantitative and qualitative analyses that would be time-consuming and difficult to perform manually. The system can identify entities (people, places, organizations, etc.), translations, key concepts, and sentiment from text to identify and extract opinions from text. Multilingual support.</p>"},{"location":"PaaS/#features-and-advantages_27","title":"Features and Advantages","text":"<p>The solution can perform various types of analysis, including:</p> <ul> <li>Entity Extraction (NER) \u2192 recognizes the names of people, companies, places, products, dates, etc.</li> <li>Sentiment analysis \u2192 understands whether the text expresses a positive, negative, or neutral opinion.</li> <li>Theme and Topic detection \u2192 identifies key concepts in the text.</li> <li>Language Detection \u2192 detects the language in which a text was written.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Swagger UI \u2192 Collection of HTML, CSS, and JavaScript assets automatically generated from the documentation, which must be compliant with the OpenAPI standard.</li> <li> <p>ML Models \u2192 List of ready-to-use pre-trained models, including:</p> <ul> <li>Key Phrase Extraction: extracts salient parts of text.</li> <li>Language Detection: infers language from text.</li> <li>Named Entity Recognition: extracts real-world entities from text, such as the names of people, places, data, companies, etc.</li> <li>Sentiment Analysis: recognizes sentiment from text.</li> </ul> </li> <li> <p>FastAPI Framework \u2192 Modern, fast (high-performance) web framework for building APIs with Python.  </p> </li> </ul> <p>Model creation workflow: 1. Data acquisition \u2192 obtains raw text data from various sources to create a robust dataset for NLP tasks. 2. Text preprocessing \u2192 includes several steps to refine the raw text data for meaningful analysis and model training (e.g., text cleaning) Text, tokenization, stopword removal, normalization). 3. Feature Engineering \u2192 transforms raw textual data into numerical features that machine learning models can understand and effectively use to capture semantic meaning, contextual information, and word relationships. 4. Modeling &amp; Evaluation \u2192 the heart of the pipeline, where models are applied and evaluated using various approaches (heuristics, ML, Deep Learning, etc.) to comprehensively measure model performance from both a technical and practical perspective. 5. Deployment \u2192 marks the transition of the developed model from the development environment to a production environment, followed by continuous monitoring and adaptation to ensure lasting performance and relevance.</p> <p>The service offers the following advantages:</p> <ul> <li>Better understanding for users and service consumers \u2192 analyzes feedback, reviews, chats, and surveys to extract sentiment.</li> <li>Data-driven decisions \u2192 transforms unstructured text into quantifiable insights that can be displayed in dashboards.</li> <li>Reduced operational costs \u2192 automates text comprehension, significantly reducing human overhead.</li> <li>Reduced operational costs \u2192 automates text comprehension, significantly reducing human overhead.</li> <li>Automation and scalability \u2192 analyzes large volumes of text from heterogeneous sources.</li> <li>Faster time to market \u2192 simple integration via API with third-party systems and applications.</li> <li>Multilingualism and semantic support \u2192 understands meanings, synonyms, and context (not just keywords).</li> </ul>"},{"location":"PaaS/#text-translation","title":"Text Translation","text":"<p> Text Analytics Service) </p>"},{"location":"PaaS/#services-description_28","title":"Services Description","text":"<p>Multilingual translation service using AI-based machine translation (NMT) technologies to enable rapid and accurate translation of text from the source language to the target language in real time. The service draws inspiration from the human brain not only for its neural structure, but also for its ability to adapt, learn from new experiences, and interact with users. The result is a so-called human-in-the-loop approach, a cycle in which machine and human continuously support each other, providing exceptional translation quality and process efficiency that surpasses previous approaches. The service can be offered in two ways: - Solution developed by Leonardo. - Solution developed by Azure.</p>"},{"location":"PaaS/#features-and-advantages_28","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Neural Machine Translation (NMT) \u2192 uses deep neural networks for more natural and contextual translations than statistical models.  </li> <li>Real-time translation \u2192 streaming translation for chat, call centers, multilingual apps, or conferences.  </li> <li>Document translation \u2192 translation of complete files (DOCX, PDF, TXT, HTML, etc.) while maintaining layout and formatting.  </li> <li>Custom translation \u2192 training of custom AI models with glossaries and datasets specific to the industry or company.  </li> <li>Automatic language recognition \u2192 automatically detects the source language before translation.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Translator REST API \u2192 main endpoint for sending text, receiving translations, or metadata (languages, glossaries).</li> <li>AI NMT Engine \u2192 proprietary neural engine based on Transformer networks (similar to GPT) for contextual translations.</li> <li>Custom Translator \u2192 portal + API for training models with custom datasets.</li> <li>Document translation API \u2192 service dedicated to batch file translation (integration with Blob Storage).</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>International expansion \u2192 allows you to easily communicate with customers, suppliers, and citizens of different languages, enabling access to new markets or linguistic communities.</li> <li>Reduced translation time and costs \u2192 automates the translation of texts, documents, and communications, reducing reliance on human translators and accelerating publication workflows.</li> <li>Multilingual process automation \u2192 integrates translation directly into digital processes, eliminating manual tasks and downtime.</li> <li>Improved access to information and knowledge \u2192 International content (reports, technical documents, studies) becomes immediately accessible in local languages.</li> <li>Accuracy thanks to neural translation models (NMT) \u2192 Neural translation engines understand context and produce more natural-sounding texts than older statistical models.</li> <li>Multiformat support \u2192 automatic translation of texts, documents (PDF, DOCX, HTML), and data streams in real time.</li> <li>Linguistic customization \u2192 ability to train custom models with glossaries or corporate terminologies for more consistent translations.</li> <li>AI Model Updates \u2192 Constantly updating the included neural models, improving accuracy and language support without manual intervention.</li> </ul>"},{"location":"PaaS/#ai-search-rag","title":"AI Search - RAG","text":"<p> AI Search - RAG Service) </p>"},{"location":"PaaS/#services-description_29","title":"Services Description","text":"<p>AI Search-RAG is a system developed by Leonardo for automatically generating answers to user-generated questions using context and information from reliable data sources. It can be integrated into environments requiring a virtual assistant capable of responding using reliable, contextualized information. The system generates answers by first searching for relevant information or passages from a reliable external knowledge base using AGENTIC RAG (Retrieval-Augmented Generation) techniques. This service allows for better contextualization of the search, further improving the quality and accuracy of the generated answers compared to traditional text-based RAGs. AI Search allows individuals and organizations to quickly access relevant, contextualized information through a simple and intuitive graphical interface built on a chat model, improving efficiency and productivity through advanced intelligent search tools.</p>"},{"location":"PaaS/#features-and-advantages_29","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Activation of the Big Data PaaS Data Lake service \u2192 to meet object storage needs.</li> <li>Use of appropriately optimized Large Language Models and Embeddings \u2192 to provide value to specific contexts and for specific users.</li> <li>User authentication \u2192 integrates with existing security protocols. Understands natural language \u2192 provides coherent and complete answers, retrieving multimodal information from knowledge expressed as text and audio. Supports multilingual models</li> <li>Feedback collection \u2192 after a query is resolved, AI Search collects user feedback</li> <li>Document segmentation by user</li> </ul> <p>The main components of the service are:</p> <ul> <li>Model Repository \u2192 at a minimum, a virtual assistant and an embedding model are required.</li> <li>Vector Database and Search Engine \u2192 it uses a vector database that stores vector representations (embeddings) of the input data, allowing documents and information to be retrieved based on their meaning (semantic search). It also uses a traditional search engine (lexical search) that operates on text and metadata, performing searches based on keywords and structured criteria (e.g., BM25, FT-IDF).</li> <li> <p>Document Manager \u2192 responsible for retrieving documentation from a specific repository and indexing it in the vector database for use in user queries. AI Search is composed of three layers:</p> </li> <li> <p>Data layer \u2192 represents the database and the primary source of information.</p> </li> <li>Analysis layer \u2192 responsible for all processing, analysis, and generation of answers to user queries. It includes the Retriever and the Generator, responsible for retrieving the most relevant information and creating coherent and personalized responses, respectively.</li> <li>User layer \u2192 interface through which the user interacts directly with the service, offering the ability to query the knowledge base, view answers with referenced sources, manage documents, and provide feedback.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Access to up-to-date knowledge \u2192 answers always based on the most recent internal and external documents.</li> <li>Reduced operational costs \u2192 less time spent on manual searches and repetitive support.</li> <li>Improved customer/employee experience \u2192 relevant, clear, personalized answers.</li> <li>Increased competitiveness \u2192 leverages proprietary knowledge, not just public knowledge.</li> <li>Risk mitigation \u2192 reduces errors and hallucinations, increasing the relevance of output to user questions.</li> <li>Upgradability without retraining \u2192 simply update the database/document repository, not the LLM.</li> <li>Hybrid vector search \u2192 combines semantic search with traditional text search.</li> <li>Model efficiency \u2192 LLM-based host model oversees activities and decisions and supervises other, simpler agents (LLM).</li> <li>Traceability and transparency \u2192 sources cited to support the answer can be displayed.</li> <li>Bias reduction \u2192 thanks to the indexing of the text on a vector DB, the LLM conductor will receive as input a context relevant to the questions asked by the users.</li> </ul>"},{"location":"PaaS/#ai-platform","title":"AI Platform","text":"<p> AI Platform Service) </p>"},{"location":"PaaS/#services-description_30","title":"Services Description","text":"<p>The AI \u200b\u200bPlatform PaaS service developed by Leonardo uses AI technologies (machine learning and deep learning) to provide domain experts (data scientists, data analysts, and AI engineers) with a collaborative platform to create, track, use, and monitor ML models simply and intuitively, yet reliably and efficiently. The service provides a ready-to-use platform capable of easily managing the entire lifecycle of ML models. The solution is certified, managed, and maintained by the provider. The platform can be enhanced using, in addition to the Data Lake service, other technologies made available by the Big Data PaaS. The services are designed to ensure digital sovereignty through deployment on secure national infrastructure, with a particular focus on latency and optimization of computational resources.</p>"},{"location":"PaaS/#features-and-advantages_30","title":"Features and Advantages","text":"<p>The platform is capable of managing the lifecycle of ML models through the following phases:</p> <ul> <li>Data processing \u2192 which will be optimized if the Big Data PaaS Data Governance and Processing Engine services are activated for the extraction, transformation, and loading of datasets into the AI \u200b\u200bPlatform.</li> <li>Model training and evaluation process \u2192 through a JupyterLab on the AI \u200b\u200bplatform. - Model tracking and saving process. </li> <li>Model management process \u2192 through the model registry provided by the MLOps tool.</li> <li>Model serving process \u2192 for the creation of Docker images ready for deployment on any target system. These can be tested directly on the platform through the swagger describing the inference service.</li> </ul> <p>The solution is primarily composed of the following custom tools:</p> <ul> <li>JupyterLab \u2192 allows the creation and sharing of web scripts in JSON format using a Notebook, which follow a schema and an ordered list of input/output cells. The created Jupyter documents can be exported as HTML, PDF, Markdown, or Python documents.</li> <li> <p>Mlflow \u2192 allows for the lifecycle management of ML models. It simplifies the complex procedures for implementing machine learning. Consisting of:</p> <ul> <li>MLflow Tracking: records and tracks metrics and artifacts (models plus their dependencies) of the training process.</li> <li>MLflow Model Registry: stores models in a centralized registry to collaboratively manage the entire model lifecycle.</li> <li>DBMS Metadata: stores all metadata in a relational database to track all development flows of a given ML model.</li> <li>Object Storage: stores all developed models and their dependencies to facilitate the subsequent model serving process in production.</li> </ul> </li> <li> <p>Model Serving \u2192 facilitates the deployment of ML models at scale in production environments through the creation of Docker images.</p> </li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced initial and operational costs \u2192 there is no need to invest in hardware infrastructure (GPU, cluster, server, storage, etc.), thus reducing maintenance, upgrade, and security costs.</li> <li>Scalability \u2192 the service can scale compute and storage resources based on model complexity or data volume.</li> <li>Faster time to market \u2192 models can be developed, tested, and deployed much faster thanks to pre-built tools and pipelines.</li> <li>Focus on business value \u2192 domain experts can focus on model research and development, increasing team productivity and efficiency.</li> <li>Easy integration with other services \u2192 trained models can be quickly integrated with other services (API management, Business Intelligence, Data Lake, etc.) to create complete AI-driven solutions.</li> <li>Automated model lifecycle management \u2192 native MLOps support for model versioning, performance monitoring, and automatic retraining.</li> <li>Managed and optimized environment \u2192 the execution environment is preconfigured with ML libraries, with security updates and patches managed by the provider.</li> <li>Integrated monitoring and logging \u2192 training metrics, logs, and results are tracked to easily diagnose convergence or overfitting issues.</li> <li>Simplified deployment \u2192 creating Docker images for model inference allows for simplified deployment to any target system.</li> </ul>"},{"location":"PaaS/#semantic-knowledge-search","title":"Semantic Knowledge Search","text":"<p> Semantic Knowledge Search Service) </p>"},{"location":"PaaS/#services-description_31","title":"Services Description","text":"<p>A service developed by Leonardo that provides a ready-to-use platform that makes information contained within the information assets easily accessible, using a semantic search engine capable of interpreting natural language queries in different languages. It considers the search context, word variations, and synonyms to find relevant results from a semantic database for a given domain based on a user's natural language query. The service allows for the management of content in various formats (Word documents, PDFs, PowerPoint presentations, emails, images, etc.) through an upload service capable of inferring and processing the document type. The tool is able to filter and select the most relevant information for the user through the use of an NLP (Natural Language Processing) model, also allowing complete navigation of the indexed document. The services are designed to ensure digital sovereignty through deployment on a secure national infrastructure, with a particular focus on latency and optimization of computational resources. It allows users to enter feedback on individual results returned by the search engine, in order to take into account domain knowledge to better refine the results provided by the system.</p>"},{"location":"PaaS/#features-and-advantages_31","title":"Features and Advantages","text":"<p>The platform bases its semantic search methodology on a database of carefully selected internal information sources, as well as on feedback from system users. This way, the results produced will prove significantly more effective, as the output of an IT tool will be combined with the assessments of domain experts. The platform will allow users to:</p> <ul> <li>Submit natural language queries in different languages.</li> <li>Reduce information search times, which will no longer be based on manual consultation of documentation, but will instead benefit from the efficiency of AI</li> <li>Optimize the tool and share the experiences of individual operators through the feedback system.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Client App \u2192 user-friendly frontend through which users can interact to submit questions in different languages, find documents relevant to the question, narrow the search field through relevant metadata, submit feedback, and index their documents by uploading one or more files.</li> <li>FastAPI Framework \u2192 modern, fast (high-performance) web framework for creating APIs with Python, based on the OpenAPI and JSON Schema standards.</li> <li>Bidirectional Encoder Representations from Transformers \u2192 pre-trained deep learning models that provide a foundation upon which to build custom versions to address a wide range of tasks. Examples include sentiment analysis, named entity recognition, text engagement (i.e., next sentence prediction), semantic role labeling, text classification, and coreference resolution.</li> <li>Apache Tika \u2192 Software for data extraction, language identification, and content analysis. It can find and extract text and metadata from over a thousand file formats.</li> <li>OpenSearch \u2192 A distributed search engine that provides extremely fast full-text search capabilities and high-performance indexing of all data types. Interaction with the search engine occurs via REST API technology.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Faster and more informed decisions \u2192 teams have easier access to corporate knowledge, reducing analysis and decision-making time.</li> <li>Better use of information assets \u2192 implicit or distributed knowledge within corporate silos (documents, emails, databases, CRM, etc.) is made searchable and semantically linked, reducing the loss of know-how or information dispersion.</li> <li>Reduced operating costs \u2192 PaaS eliminates the need to manage proprietary infrastructure for indexing, NLP, and data linking.</li> <li>Innovation and competitive advantage \u2192 differentiate products and services with a more intelligent user experience.</li> <li>Accelerated time to market \u2192 PaaS services are ready to use and easily integrated via API, allowing for the rapid development of new knowledge-driven applications.</li> <li>Simplified scalability and management \u2192 manage provisioning, updates, load balancing, and fault tolerance.</li> <li>Access to advanced AI/NLP technologies \u2192 semantic engines based on embeddings, ontologies, graph search, and machine learning without having to implement them internally. - Continuous updates with the latest developments.</li> <li>Multi-source integration \u2192 Semantic Knowledge Search PaaS allows you to connect structured and unstructured data from multiple sources and supports standard connectors (REST API).</li> <li>Managed security and compliance \u2192 authentication, authorization, and encryption are integrated into the service.</li> </ul>"},{"location":"PaaS/#ai-slmllm","title":"AI SLM/LLM","text":"<p> AI SLM/LLM Services) </p>"},{"location":"PaaS/#services-description_32","title":"Services Description","text":"<p>These are Generative AI PaaS developed by Leonardo that provide optimized linguistic inference capabilities. They use predefined linguistic models to understand and generate natural text. They allow the use of two types of linguistic models:</p> <ul> <li>Small Language Model (SLM): small-scale linguistic models that are lighter, more efficient, and specialized in specific domains, offering fast and precise solutions for everyday linguistic needs.</li> <li>Large Language Model (LLM): linguistic models with numerous parameters for extremely high linguistic comprehension and generation capabilities, ideal for complex interactions, virtual assistants, semantic search, and automation. SLMs are suitable for performing specific, less complex applications and tasks (e.g., text autocompletion, short sentence translation, and text classification), where an LLM would be too computationally expensive.</li> </ul>"},{"location":"PaaS/#features-and-advantages_32","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Tenant isolation \u2192 each customer will have a dedicated Tenant on the PSN infrastructure with complete isolation of data, configurations, and uploaded models.</li> <li>Resource allocation \u2192 each customer will be assigned dedicated infrastructure resources (CPU, GPU, RAM, Storage) to their Tenant, sized appropriately.</li> <li>Auto-scaling \u2192 tenant resources can scale to respond to load variations.</li> <li>Cloud-native deployment \u2192 the service will be deployed in the customer's tenant in cloud-native mode on the OpenShift platform, ensuring portability, resilience, and standardization of operating procedures.</li> <li>Centralized observability \u2192 provides centralized platform monitoring services with log collection, metrics, and alerting for complete observability, audit trails, and advanced troubleshooting.</li> <li>PaaS integration \u2192 uses PSN PaaS components for storage, networking, security, and identity management, ensuring compliance with project requirements and leveraging the economies of scale of shared infrastructure.</li> </ul> <p>Both services feature a modular architecture designed to ensure scalability, flow segregation, and ease of integration into public administration processes.</p> <ul> <li>API Layer \u2192 provides access to SLM/LLM services through two main methods: REST API calls for integration with existing systems, or through a Web UI for direct, user-friendly interaction.</li> <li>Inference layer \u2192 this is the heart of the service, where SLM/LLM models reside and execute. It consists of:</li> <li>Inference engine \u2192 runs language models optimized for latency and GPU/CPU resource consumption.</li> <li>Model pool management \u2192 maintains a set of validated and pre-configured models, selectable by the customer. Only one model is active per tenant at any time.</li> <li>Platform layer \u2192 provides cross-functional support services and includes: Resource Management &amp; Scaling: Dynamic allocation of computational resources (CPU, GPU, RAM, storage), load-based auto-scaling, and service lifecycle management.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Technological accessibility \u2192 access to no-code Generative AI technology solutions.</li> <li>Reduced operating costs \u2192 no upfront investment in hardware infrastructure or proprietary models.</li> <li>Faster time to market \u2192 easier models to integrate into business solutions.</li> <li>Operational efficiency \u2192 automate repetitive tasks, reducing processing times and improving service quality.</li> <li>Flexible adoption \u2192 choose between SLM (small, specialized models) or LLM (generalist models with broader knowledge capabilities) depending on the use case.</li> <li>Risk mitigation \u2192 leverage pre-trained and validated models without the need for specialized ML skills.</li> <li>Easy integration with existing systems \u2192 orchestrate complex processes through microservices and integrated ML pipelines.</li> <li>Performance optimization \u2192 PaaS allows you to combine both advantages: use SLM for simple, targeted tasks, while LLM is used only for tasks that require broader, more generalized linguistic understanding.</li> <li>Fast and simplified model testing \u2192 ready-to-use models thanks to the playground functionality available directly in the interface. - Rapid prototyping and DevOps AI \u2192 ready-to-use environment for developing, testing, and deploying applications through standard interfaces.</li> <li>Multi-model and hybrid AI \u2192 ability to combine open source and proprietary models in the same ecosystem.</li> </ul>"},{"location":"PaaS/#ai-workflow","title":"AI workflow","text":"<p> AI workflow Service) </p>"},{"location":"PaaS/#services-description_33","title":"Services Description","text":"<p>A service that allows users to create, orchestrate, automate, and deploy visual workflows for data manipulation, analysis, and modeling, without writing code. It allows users to add and customize workflow nodes to meet their specific needs. It also supports distributed workflow execution, making it suitable for compute-intensive scenarios. Specifically, it allows users to: design AI workflows without writing complex code; run and scale analytics or machine learning processes in the cloud; integrate models, APIs, and heterogeneous data; and automate end-to-end analysis or decision-making pipelines.</p>"},{"location":"PaaS/#features-and-advantages_33","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Multiple connectors \u2192 connect to databases, files, REST APIs, cloud storage, web services, IoT systems.</li> <li>Data cleansing and transformation \u2192 drag-and-drop functions to normalize, filter, aggregate, and enrich data.</li> <li>Integrated ML models \u2192 preconfigured nodes for regression, classification, clustering, NLP, and anomaly detection algorithms.</li> <li>Automated execution \u2192 scheduling, event-based triggers, conditional flows, and parallelized jobs.</li> <li>MLOps &amp; Deployment \u2192 publish AI models as REST APIs or containers (Docker/Kubernetes).</li> <li>Collaboration &amp; Governance \u2192 user management, permissions, version control, auditing, and rollback workflows.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Analytics platform (Frontend) \u2192 drag-and-drop visual environment for creating AI/ML workflows and data pipelines.</li> <li>Business hub (Backend PaaS) \u2192 heart of the cloud service: manages users, executions, versioning, and deployment.</li> <li>Execution environment (Cluster/Container) \u2192 runs workflows on scalable nodes, on-demand or scheduled.</li> <li>Data Connectors layer \u2192 modules for accessing external data sources.</li> <li>Integration layer \u2192 interface with external languages \u200b\u200b(or ML frameworks).</li> <li>Monitoring layer \u2192 execution metrics, job status, logging, and error alerts.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced time to market \u2192 analytical workflows and predictive models can be developed, tested, and put into production in a fraction of the time, improving responsiveness compared to competitors.</li> <li>Reduced IT infrastructure costs \u2192 PaaS eliminates the need for dedicated servers, hardware maintenance, and customer-paid software updates.</li> <li>Democratization of AI and Data Science \u2192 The low-code/no-code approach also allows non-technical professionals (analysts, managers) to participate in the construction and optimization of decision-making flows.</li> <li>Greater transparency and traceability of decisions \u2192 each step of the analytical process is visible and documented in the workflow, increasing the reliability and explainability of automated decisions.</li> <li>Optimization of business performance \u2192 AI pipelines improve forecasting, resource allocation, predictive maintenance, customer analytics, and other key areas, generating direct ROI.</li> <li>End-to-end automation of AI flows \u2192 ability to schedule, orchestrate, and automate complete pipelines.</li> <li>Rapid prototyping and reusability \u2192 workflows can be cloned, reused, or shared in centralized repositories to accelerate new projects or variants.</li> <li>Full MLOps support \u2192 model lifecycle management (train, test, deploy, monitor), simplified versioning, and rollback.</li> <li>Automated updates and maintenance \u2192 patch management, version updates, and library dependencies without interrupting active workflows.</li> <li>Reduced deployment complexity \u2192 models and flows can be quickly deployed as microservices or REST APIs, eliminating the need for manual DevOps.</li> </ul>"},{"location":"PaaS/#vector-db","title":"Vector DB","text":"<p> Vector DB Service) </p>"},{"location":"PaaS/#services-description_34","title":"Services Description","text":"<p>Based on a modern, open-source vector database technology (Lance DB) optimized for AI and machine learning, Leonardo's service enables scalable, high-performance storage, indexing, and search of vector data (embeddings), without having to manage the underlying infrastructure. It offers persistent storage and efficient indexing of embeddings, enabling fast and scalable searches across large volumes of vector data. From a business perspective, it enables semantic search applications, personalized recommendations, intelligent chatbots, and augmented retrieval systems (RAG). It reduces infrastructure costs by unifying multimodal data management and simplifying AI/ML workflows. It increases development speed thanks to deployment flexibility. It offers scalability and high performance to support production-level AI workloads with complex data flows.</p>"},{"location":"PaaS/#features-and-advantages_34","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Unified repository for data and vectors \u2192 the solution allows you to store not only embeddings (vectors) generated by AI models, but also the \"original\" data (text, images, audio, video) and associated metadata, all in the same environment.</li> <li>Multimodal support \u2192 the solution is designed to work with data from different modalities: text, images, video, audio, point clouds, etc.</li> <li>Vector search \u2192 embedding search functionality: given an embedding query, find the most similar vectors.</li> <li>Advanced vector indexing \u2192 support for indexing algorithms that make searching large datasets efficient.</li> <li>Data versioning and high-performance columnar format \u2192 LanceDB uses a columnar format called \"Lance\" (open-source), optimized for ML/vector workloads. - SQL and analytics integration beyond vector \u2192 Not just similarity search; LanceDB allows SQL/analytics queries on data (metadata, additional columns) in addition to vector operations.</li> <li>Flexible deployment \u2192 serverless managed PaaS (LanceDB Cloud) for production without managing infrastructure.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Data ingestion layer \u2192 collects and prepares data from various sources (text, images, audio, video, logs, documents, corporate databases, etc.). FastAPI Framework \u2192 Modern, fast (high-performance) web framework for building APIs with Python, based on OpenAPI and JSON Schema standards.</li> <li>Vector storage layer \u2192 efficiently stores vectors and related data.</li> <li>Indexing &amp; Search engine \u2192 enables vector search by similarity (nearest neighbors) and optimized indexing.</li> <li>Query &amp; API layer \u2192 exposes database functionality to developers and applications.</li> <li>Compute &amp; Scaling layer \u2192 manages compute resources, scalability, and service performance.</li> <li>Security &amp; Compliance layer \u2192 ensures data protection and regulatory compliance.</li> <li>Monitoring, logging &amp; observability layer \u2192 provides visibility into system behavior and performance.</li> <li>Developer &amp; Management console \u2192 web interface for administrators and developers for managing datasets and indexes, viewing embeddings and search results, configuring security and access policies, monitoring costs, plans, and usage metrics.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Enhancement of unstructured information assets \u2192 VectorDB allows you to transform this content into searchable and analyzable data thanks to semantic embeddings. Improved productivity, faster decisions, and reduced search time \u2192 by enabling semantic and contextual search, no longer based on keywords. Users can query the knowledge base with natural language.</li> <li>Enabling advanced AI applications \u2192 a key component for solutions such as RAG, recommendation engines, and multimodal analysis, which facilitate integration with LLM models and generative AI tools.</li> <li>Reduced operating costs and increased efficiency \u2192 no investment in hardware or personnel for database management. Optimization of search and document analysis processes.</li> <li>Accelerated time-to-market \u2192 no need to manage infrastructure, configurations, or manual scaling, so developers can integrate semantic search quickly.</li> <li>Scalability and high performance \u2192 Cloud-native architecture with vertical and horizontal autoscaling, ANN indexes (HNSW, IVF_PQ) that enable millisecond searches even on huge datasets.</li> <li>Easy management (fully managed PaaS) \u2192 No need for provisioning, tuning, or software updates. Backup, replication, and high availability managed by the provider.</li> <li>Hybrid and multimodal query support \u2192 combines vector search + structured filters (SQL). Manages text, image, audio, and video embeddings in a single data model.</li> <li>Reliability, security, and compliance \u2192 end-to-end encryption, IAM access control, API tokens, audit logging. Secure management of sensitive data (embedding anonymization).</li> <li>Maintainability and continuous updates \u2192 automatic updates of the LanceDB engine and indexing models. No downtime for patches or upgrades.</li> </ul>"},{"location":"PaaS/#virtual-desktop-infrastructure-vdi-family","title":"Virtual Desktop Infrastructure (VDI) Family","text":"<p>Below is the list of services belonging to the Virtual Desktop Infrastructure (VDI) family:</p> <ul> <li>VDI</li> <li>VDI with GPU support</li> </ul>"},{"location":"PaaS/#vdi","title":"VDI","text":"<p> VDI Service) </p>"},{"location":"PaaS/#services-description_35","title":"Services Description","text":"<p>Powered by Citrix solution, the Virtual Desktop Infrastructure (VDI) service allows users to access and manage virtual desktops hosted on centralized servers, providing a secure and customizable work environment accessible from any internet-connected device. VDI (named or shared) with a predefined set of applications and dedicated storage space for each user.</p>"},{"location":"PaaS/#features-and-advantages_35","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Centralized remote access \u2192 users access virtual desktops or applications from any location and device.</li> <li>Optimized user experience \u2192 HDX (High Definition Experience) technology optimizes the user experience even under network conditions with latency or limited bandwidth</li> <li>Advanced security \u2192 data remains in the data center, not on the user's device, through appropriate policies. Multi-factor authentication (MFA), single sign-on (SSO), traffic encryption, data isolation.</li> <li>Centralized management \u2192 updates, patches, and policies distributed centrally from a single console (Citrix Studio/Director).</li> <li>Monitoring and diagnostics \u2192 advanced performance monitoring and troubleshooting tools (Citrix Director, Citrix Analytics).</li> </ul> <p>The main components of the service are:</p> <ul> <li>Delivery Controller \u2192 manages user authentication, load balancing, and resource assignment.</li> <li>Database \u2192 a virtual apps or virtual desktops site uses three SQL Server databases (installed on a single DB Server in an HA configuration).</li> <li>Virtual Delivery Agent (VDA) \u2192 installed on virtual desktops, allows the machine to register with the Controller, which in turn makes the virtual machine and the resources it hosts available to users.</li> <li>StoreFront \u2192 portal through which users connect to access virtual apps or desktops.</li> <li>Receiver / Citrix Workspace App \u2192 the client that runs on the user's device and allows access to the remote desktop/app.</li> <li>Studio \u2192 you can manage the virtual desktops deployment using two management consoles: Web Studio (Web BASed) and Studio (Windows client)</li> <li>Director \u2192 dashboard that allows IT support and helpdesk teams to monitor the environment, resolve issues before they become system-critical and perform end-user support activities.</li> <li>License Server \u2192 manages product licenses. It communicates with the Controller to manage licenses for each user session and with Studio to allocate license files.</li> <li>Hypervisor \u2192 hosts the VMs that make up the infrastructure and virtual desktops.</li> </ul> <p>The service offers the following advantages:</p> <ul> <li>Reduced operating costs \u2192 optimize operations through centralized management and save device costs through BYOD (Bring Your Own Device) support.</li> <li>Increased security \u2192 data protection through appropriate policies.</li> <li>Increased productivity \u2192 consistent and seamless user experience, regardless of the device used.</li> <li>Business continuity and disaster recovery \u2192 always-on desktops.</li> <li>Centralized management \u2192 patches, updates, and policies are centrally applied.</li> <li>Scalability \u2192 easily add/remove users and resources as needed.</li> <li>Cross-platform compatibility \u2192 Windows, Linux, macOS, iOS, Android, browsers.</li> </ul>"},{"location":"PaaS/#vdi-with-gpu-support","title":"VDI with GPU support","text":"<p> VDI with GPU support Service) </p>"},{"location":"PaaS/#services-description_36","title":"Services Description","text":"<p>It is a more advanced version of the previously described VDI service that supports graphics accelerator (GPU) management for additional graphics acceleration capabilities.</p>"},{"location":"PaaS/#features-and-advantages_36","title":"Features and Advantages","text":"<p>The service offers the same basic features as the previously described VDI service with the addition of GPU support capabilities. VMs can have graphics acceleration features for users who require software such as CAD/CAM (e.g., AutoCAD, SolidWorks), 3D modeling (e.g., Blender, 3ds Max), GIS (e.g., ArcGIS), Scientific rendering and visualization, and video editing (e.g., Adobe Premiere, DaVinci Resolve). Examples of additional features include HDX 3D Pro, GPU virtualization (NVIDIA vGPU, AMD MxGPU), high-performance remote access, multi-monitor and 4K support, and bandwidth and latency optimization.  </p> <p>The service offers the same components as the previously described VDI service.</p> <p>The service offers the following advantages:</p> <ul> <li>Reduced hardware costs \u2192 no need to purchase expensive graphics workstations for each user: GPU computing power is centralized in the cloud.</li> <li>Scalability and flexibility \u2192 easily increase or decrease GPU/CPU resources based on seasonal or project-specific loads. Suitable for distributed and temporary teams (e.g., consultants, freelancers, partners).</li> <li>Business continuity and disaster recovery \u2192 everything runs on a managed and resilient infrastructure. Automatic backups and failovers ensure business continuity even in the event of local failures.</li> <li>Improved productivity and remote access \u2192 users can access 3D, CAD, or data science applications from any device, with the same performance as a local machine. Ideal for remote working and global collaboration.</li> <li>GPU acceleration \u2192 support for graphics-intensive workloads (CAD, BIM, GIS, 3D rendering, simulations, AI/ML). Smooth performance thanks to technologies such as NVIDIA vGPU, AMD MxGPU, etc.</li> <li>Simplified management \u2192 managed platform that reduces IT overhead (automated updates, patches, and provisioning). Directory integration, multifactor authentication, and granular access policies.</li> <li>User experience optimization \u2192 advanced protocols reduce latency and optimize remote rendering. Adaptive streaming: Balanced graphics quality based on available bandwidth.</li> <li>Multi-cloud and hybrid-ready \u2192 deploy virtual desktops across multiple cloud providers or in private data centers. Greater flexibility in managing costs and compliance.</li> <li>Monitoring and analytics \u2192 integrated telemetry and performance monitoring tools optimize user experience and GPU resource usage. Capacity planning automation.</li> <li>Support for DevOps/CI-CD/AI \u2192 GPU VDI environments can be integrated into DevOps workflows for testing graphics applications, 3D modeling, or training ML models.</li> </ul>"},{"location":"PaaS/#collaboration-family","title":"Collaboration Family","text":"<p>Below is the list of services belonging to the Collaboration family:</p> <ul> <li>Instant Messaging</li> </ul>"},{"location":"PaaS/#instant-messaging","title":"Instant Messaging","text":"<p> Instant Messaging Service) </p>"},{"location":"PaaS/#services-description_37","title":"Services Description","text":"<p>It is a messaging and collaboration platform based on the Mattermost solution that offers secure tools for team communication, file sharing, and integration with other applications, supporting productivity in distributed work environments. It allows you to organize all team communications in one place via channels. In addition to standard messaging, channels support automation, slash commands, bot integrations, code snippets, and more. Suitable for environments with high security, privacy, and control requirements. It supports multi-factor authentication, Active Directory, LDAP, SSO, and more. The platform can be customized and extended by integrating it with the tools your team uses daily.</p>"},{"location":"PaaS/#features-and-advantages_37","title":"Features and Advantages","text":"<p>The service offers the following main features:</p> <ul> <li>Playbooks \u2192 playbooks allow you to orchestrate work across tools and teams. They are prescribed workflows that support specific digital operations scenarios.</li> <li>Audio calls \u2192 it offers native audio calls on channels.</li> <li>Integrations and customizations \u2192 support for slash commands, bots, and inbound and outbound webhooks; extensive ecosystem of plugins and integrations; extensive APIs for extending functionality or building custom applications.</li> <li>Accessibility \u2192 cross-platform clients (web, desktop, mobile); Deployable behind firewalls/in private, air-gapped environments.</li> <li>Security, Privacy, and Governance \u2192 support for: encryption (in transit, at rest); Access control (Single Sign-On MFA, granular roles and permissions); Governance, privacy, and compliance; Zero Trust policy.</li> </ul> <p>The main components of the service are:</p> <ul> <li>Backend server \u2192 can use MySQL or PostgreSQL as a database) that hosts messages, users, and files.</li> <li>Storage for file attachments, images, etc. \u2192 can be local or cloud-based (S3, MinIO, etc.).</li> <li>WebSocket channels \u2192 for real-time message transmission.</li> <li>Configurable for scalability \u2192 cluster support, high availability, deployment on Kubernetes, isolated networks.</li> </ul>"}]}